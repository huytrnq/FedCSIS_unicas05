{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def load_csv(file_path, remove_outliners=False, filter_by_group=False):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "    # Replace commas in numeric columns and convert them to floats\n",
    "    data = data.replace(',', '.', regex=True).apply(pd.to_numeric, errors='ignore')\n",
    "    # if 'Perform' in data.columns:\n",
    "    #     data.drop('Perform', axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cost_matrix = np.array([[0, 1, 2],\n",
    "                        [1, 0, 1],\n",
    "                        [2, 1, 0]])\n",
    "def calculate_custom_error(preds, gt, cost_matrix=cost_matrix):\n",
    "    \"\"\"\n",
    "    Calculate a custom error metric based on a confusion matrix and a cost matrix.\n",
    "\n",
    "    Args:\n",
    "    preds (array-like): Predicted labels.\n",
    "    gt (array-like): Ground truth (actual) labels.\n",
    "    cost_matrix (numpy.ndarray): A matrix of costs associated with misclassifications.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated error metric.\n",
    "    \"\"\"\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(gt, preds)\n",
    "    \n",
    "    # Validate dimensions of cost_matrix\n",
    "    if cm.shape != cost_matrix.shape:\n",
    "        raise ValueError(\"Cost matrix dimensions must match the confusion matrix dimensions.\")\n",
    "    \n",
    "    # Calculate weighted confusion matrix\n",
    "    weighted_cm = cm * cost_matrix\n",
    "    \n",
    "    # Calculate the custom error\n",
    "    total_samples = len(gt)\n",
    "    if total_samples == 0:\n",
    "        raise ValueError(\"The length of ground truth cannot be zero.\")\n",
    "    \n",
    "    error = np.sum(weighted_cm) / total_samples\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_wise_knn_imputation(df, group_column, n_neighbors=5):\n",
    "    # Initialize an empty DataFrame to collect the imputed groups\n",
    "    try:\n",
    "        df_copy = df.drop(columns=['I21', 'I48', 'I50', 'dI21', 'dI48', 'dI50'], axis=1)\n",
    "    except:\n",
    "        df_copy = df.copy()\n",
    "\n",
    "    # We will collect the group imputed dataframes here and concatenate them at the end\n",
    "    imputed_dfs = []\n",
    "\n",
    "    # Iterate over each group\n",
    "    for group_name, group_data in df_copy.groupby(group_column):\n",
    "        # Create an imputer object\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "        # Select numeric columns for imputation\n",
    "        numeric_cols = group_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        # Perform imputation\n",
    "        group_data.loc[:, numeric_cols] = imputer.fit_transform(group_data[numeric_cols])\n",
    "\n",
    "        # Append the imputed group data\n",
    "        imputed_dfs.append(group_data)\n",
    "\n",
    "    # Concatenate all the imputed group dataframes\n",
    "    df_imputed = pd.concat(imputed_dfs, ignore_index=False)\n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_wise_imputation(X, group_column):\n",
    "    # Iterate over each group defined by the 'group_column'\n",
    "    for group, group_data in X.groupby(group_column):\n",
    "        # Select only numeric columns for imputation, excluding the group column explicitly\n",
    "        numeric_cols = group_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if group_column in numeric_cols:\n",
    "            numeric_cols.remove(group_column)  # Ensure the group column is not in the list\n",
    "\n",
    "        for column in numeric_cols:\n",
    "            upper_quartile = group_data[column].quantile(0.75)\n",
    "            lower_quartile = group_data[column].quantile(0.25)\n",
    "            IQR = upper_quartile - lower_quartile\n",
    "            upper_whisker = upper_quartile + 1.5 * IQR\n",
    "            lower_whisker = lower_quartile - 1.5 * IQR\n",
    "            \n",
    "            # Impute outliers with the median of the group\n",
    "            median_value = group_data[column].median()\n",
    "            group_data[column] = np.where((group_data[column] > upper_whisker) | \n",
    "                                        (group_data[column] < lower_whisker), \n",
    "                                        median_value, group_data[column])\n",
    "        \n",
    "        # Assign the corrected group data back to the main DataFrame\n",
    "        X.loc[group_data.index, group_data.columns] = group_data\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_with_excessive_nans(dataframe, threshold=200):\n",
    "    \"\"\"Drop columns from a DataFrame where the number of NaN values exceeds the specified threshold.\"\"\"\n",
    "    nan_counts = dataframe.isna().sum()\n",
    "    columns_to_drop = nan_counts[nan_counts > threshold].index\n",
    "    return dataframe.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_csv('../data/training_data.csv')\n",
    "train_data = drop_columns_with_excessive_nans(train_data, threshold=200)\n",
    "\n",
    "\n",
    "# Handle categorical variables - encoding the 'Group' column\n",
    "le = LabelEncoder()\n",
    "train_data['Group'] = le.fit_transform(train_data['Group'])\n",
    "\n",
    "# Assume 'Class' is the target variable\n",
    "X = train_data.drop('Class', axis=1)  # Features\n",
    "y = train_data['Class'] # Target variable\n",
    "\n",
    "# X = feature_transformations(X)\n",
    "# X = group_wise_imputation(X, 'Group')\n",
    "X = group_wise_knn_imputation(X, 'Group', n_neighbors=5)\n",
    "X = group_wise_imputation(X, 'Group')\n",
    "X = X.drop(columns=['Perform'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=state, stratify=y)\n",
    "np.unique(y_train, return_counts=True)\n",
    "X_train_group = X_train['Group']\n",
    "X_test_group = X_test['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 52)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = SVC(kernel='linear')\n",
    "selector = RFE(estimator, n_features_to_select=50, step=1, verbose=3)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Selected features\n",
    "selected_features = selector.get_support(indices=True)\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "X_train = X_train.iloc[:, selected_features]\n",
    "X_test = X_test.iloc[:, selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Group'] = X_train_group\n",
    "X_test['Group'] = X_test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required by RandomForestClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m y_train_group \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mvalues[np\u001b[38;5;241m.\u001b[39mwhere(X_train\u001b[38;5;241m.\u001b[39mvalues[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m group_name)[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m models[group_name] \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py:1279\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     )\n\u001b[1;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1264\u001b[0m     X,\n\u001b[1;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1277\u001b[0m )\n\u001b[0;32m-> 1279\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1281\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py:1289\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1289\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1299\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py:1072\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1072\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1075\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1076\u001b[0m         )\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1079\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required by RandomForestClassifier."
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for group_name, group_data in X_train.groupby('Group'):\n",
    "    # Initialize the model\n",
    "    model = RandomForestClassifier(random_state=state, class_weight='balanced')\n",
    "    \n",
    "    y_train_group = y_train.values[np.where(X_train.values[:, 0] == group_name)[0]]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(group_data, y_train_group)\n",
    "\n",
    "    # Save the model\n",
    "    models[group_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.435\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      0.35      0.36       619\n",
      "           0       0.10      0.01      0.02       227\n",
      "           1       0.48      0.63      0.54       754\n",
      "\n",
      "    accuracy                           0.43      1600\n",
      "   macro avg       0.32      0.33      0.31      1600\n",
      "weighted avg       0.38      0.43      0.40      1600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[216  10 393]\n",
      " [ 93   2 132]\n",
      " [267   9 478]]\n",
      "Custom Error: 0.9775\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "\n",
    "for group_name, group_data in X_test.groupby('Group'):\n",
    "    # Get the model\n",
    "    model = models[group_name]\n",
    "    \n",
    "    # Get the ground truth labels\n",
    "    y_test_group = y_test.values[np.where(X_test.values[:, 0] == group_name)[0]]\n",
    "    \n",
    "    # Get the predictions\n",
    "    y_pred = model.predict(group_data)\n",
    "    y_preds.extend(y_pred)\n",
    "    \n",
    "# Calculate the custom error\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "print(\"Custom Error:\", calculate_custom_error(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group\n",
       "3     170\n",
       "7     155\n",
       "5     154\n",
       "0     118\n",
       "6     116\n",
       "8     103\n",
       "10     94\n",
       "9      82\n",
       "4      67\n",
       "2      45\n",
       "1      32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Class'] == 0]['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group\n",
       "3     705\n",
       "5     535\n",
       "7     497\n",
       "0     413\n",
       "6     387\n",
       "10    360\n",
       "8     285\n",
       "9     259\n",
       "4     129\n",
       "2     128\n",
       "1      70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Class'] == 1]['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group\n",
       "3     499\n",
       "7     367\n",
       "5     354\n",
       "0     349\n",
       "6     326\n",
       "10    299\n",
       "8     289\n",
       "9     244\n",
       "4     187\n",
       "2     124\n",
       "1      58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Class'] == -1]['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
