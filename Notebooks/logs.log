2024-05-04 14:14:24,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 14:14:24,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 14:14:24,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 14:14:24,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 14:15:23,655:INFO:PyCaret AnomalyExperiment
2024-05-04 14:15:23,655:INFO:Logging name: anomaly-default-name
2024-05-04 14:15:23,655:INFO:ML Usecase: MLUsecase.ANOMALY
2024-05-04 14:15:23,655:INFO:version 3.3.2
2024-05-04 14:15:23,655:INFO:Initializing setup()
2024-05-04 14:15:23,655:INFO:self.USI: f250
2024-05-04 14:15:23,655:INFO:self._variable_keys: {'_available_plots', 'X', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'logging_param', 'log_plots_param', 'USI', '_ml_usecase', 'n_jobs_param', 'exp_name_log', 'idx', 'data', 'gpu_param', 'seed', 'memory', 'pipeline'}
2024-05-04 14:15:23,655:INFO:Checking environment
2024-05-04 14:15:23,655:INFO:python_version: 3.11.8
2024-05-04 14:15:23,655:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 14:15:23,655:INFO:machine: arm64
2024-05-04 14:15:23,655:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 14:15:23,655:INFO:Memory: svmem(total=17179869184, available=6238797824, percent=63.7, used=8373714944, free=66781184, active=6188400640, inactive=5915672576, wired=2185314304)
2024-05-04 14:15:23,655:INFO:Physical Core: 8
2024-05-04 14:15:23,655:INFO:Logical Core: 8
2024-05-04 14:15:23,655:INFO:Checking libraries
2024-05-04 14:15:23,655:INFO:System:
2024-05-04 14:15:23,655:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 14:15:23,655:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 14:15:23,655:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 14:15:23,655:INFO:PyCaret required dependencies:
2024-05-04 14:15:24,129:INFO:                 pip: 24.0
2024-05-04 14:15:24,129:INFO:          setuptools: 69.2.0
2024-05-04 14:15:24,129:INFO:             pycaret: 3.3.2
2024-05-04 14:15:24,129:INFO:             IPython: 8.22.2
2024-05-04 14:15:24,129:INFO:          ipywidgets: 8.1.2
2024-05-04 14:15:24,129:INFO:                tqdm: 4.66.2
2024-05-04 14:15:24,129:INFO:               numpy: 1.26.4
2024-05-04 14:15:24,129:INFO:              pandas: 2.1.4
2024-05-04 14:15:24,129:INFO:              jinja2: 3.1.3
2024-05-04 14:15:24,129:INFO:               scipy: 1.11.4
2024-05-04 14:15:24,129:INFO:              joblib: 1.3.2
2024-05-04 14:15:24,129:INFO:             sklearn: 1.4.1.post1
2024-05-04 14:15:24,129:INFO:                pyod: 1.1.3
2024-05-04 14:15:24,129:INFO:            imblearn: 0.12.2
2024-05-04 14:15:24,129:INFO:   category_encoders: 2.6.3
2024-05-04 14:15:24,129:INFO:            lightgbm: 4.3.0
2024-05-04 14:15:24,129:INFO:               numba: 0.59.1
2024-05-04 14:15:24,129:INFO:            requests: 2.31.0
2024-05-04 14:15:24,129:INFO:          matplotlib: 3.7.5
2024-05-04 14:15:24,129:INFO:          scikitplot: 0.3.7
2024-05-04 14:15:24,129:INFO:         yellowbrick: 1.5
2024-05-04 14:15:24,129:INFO:              plotly: 5.19.0
2024-05-04 14:15:24,129:INFO:    plotly-resampler: Not installed
2024-05-04 14:15:24,129:INFO:             kaleido: 0.2.1
2024-05-04 14:15:24,129:INFO:           schemdraw: 0.15
2024-05-04 14:15:24,129:INFO:         statsmodels: 0.14.1
2024-05-04 14:15:24,129:INFO:              sktime: 0.26.0
2024-05-04 14:15:24,129:INFO:               tbats: 1.1.3
2024-05-04 14:15:24,129:INFO:            pmdarima: 2.0.4
2024-05-04 14:15:24,129:INFO:              psutil: 5.9.8
2024-05-04 14:15:24,129:INFO:          markupsafe: 2.1.5
2024-05-04 14:15:24,129:INFO:             pickle5: Not installed
2024-05-04 14:15:24,129:INFO:         cloudpickle: 3.0.0
2024-05-04 14:15:24,129:INFO:         deprecation: 2.1.0
2024-05-04 14:15:24,129:INFO:              xxhash: 3.4.1
2024-05-04 14:15:24,129:INFO:           wurlitzer: 3.0.3
2024-05-04 14:15:24,129:INFO:PyCaret optional dependencies:
2024-05-04 14:15:25,178:INFO:                shap: 0.44.1
2024-05-04 14:15:25,178:INFO:           interpret: 0.6.1
2024-05-04 14:15:25,178:INFO:                umap: 0.5.6
2024-05-04 14:15:25,178:INFO:     ydata_profiling: 4.7.0
2024-05-04 14:15:25,178:INFO:  explainerdashboard: 0.4.7
2024-05-04 14:15:25,178:INFO:             autoviz: Not installed
2024-05-04 14:15:25,178:INFO:           fairlearn: 0.7.0
2024-05-04 14:15:25,178:INFO:          deepchecks: Not installed
2024-05-04 14:15:25,179:INFO:             xgboost: Not installed
2024-05-04 14:15:25,179:INFO:            catboost: Not installed
2024-05-04 14:15:25,179:INFO:              kmodes: Not installed
2024-05-04 14:15:25,179:INFO:             mlxtend: 0.23.1
2024-05-04 14:15:25,179:INFO:       statsforecast: Not installed
2024-05-04 14:15:25,179:INFO:        tune_sklearn: Not installed
2024-05-04 14:15:25,179:INFO:                 ray: Not installed
2024-05-04 14:15:25,179:INFO:            hyperopt: Not installed
2024-05-04 14:15:25,179:INFO:              optuna: Not installed
2024-05-04 14:15:25,179:INFO:               skopt: Not installed
2024-05-04 14:15:25,179:INFO:              mlflow: 2.12.1
2024-05-04 14:15:25,179:INFO:              gradio: 4.29.0
2024-05-04 14:15:25,179:INFO:             fastapi: 0.111.0
2024-05-04 14:15:25,179:INFO:             uvicorn: 0.29.0
2024-05-04 14:15:25,179:INFO:              m2cgen: 0.10.0
2024-05-04 14:15:25,179:INFO:           evidently: 0.4.20
2024-05-04 14:15:25,179:INFO:               fugue: 0.8.7
2024-05-04 14:15:25,179:INFO:           streamlit: 1.33.0
2024-05-04 14:15:25,179:INFO:             prophet: Not installed
2024-05-04 14:15:25,179:INFO:None
2024-05-04 14:15:25,179:INFO:Set up data.
2024-05-04 14:15:25,181:INFO:Set up index.
2024-05-04 14:15:25,187:INFO:Assigning column types.
2024-05-04 14:15:25,189:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2024-05-04 14:15:25,610:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2024-05-04 14:15:25,611:INFO:Preparing preprocessing pipeline...
2024-05-04 14:15:25,611:INFO:Set up simple imputation.
2024-05-04 14:15:26,295:INFO:Finished creating preprocessing pipeline.
2024-05-04 14:15:26,298:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group;I1;I2;I3;I4;I5;I6;I7;I8;I9;I10;I11;I12;I13;I14;I15;I16;I17;I18;I19;I20;I21;I22;I23;I24;I25;I26;I27;I28;I29;I30;I31;I32;I33;I34;I35;I36;I37;I38;I39;I40;I41;I42;I43;I44;I45;I46;I47;I48;I49;I50;I51...;dI20;dI21;dI22;dI23;dI24;dI25;dI26;dI27;dI28;dI29;dI30;dI31;dI32;dI33;dI34;dI35;dI36;dI37;dI38;dI39;dI40;dI41;dI42;dI43;dI44;dI45;dI46;dI47;dI48;dI49;dI50;dI51;dI52;dI53;dI54;dI55;dI56;dI57;dI58;Class;Perform'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-05-04 14:15:26,298:INFO:Creating final display dataframe.
2024-05-04 14:15:27,337:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   123
1        Original data shape             (8000, 1)
2     Transformed data shape             (8000, 1)
3           Numeric features                     1
4   Rows with missing values                 44.6%
5                 Preprocess                  True
6            Imputation type                simple
7         Numeric imputation                  mean
8     Categorical imputation                  mode
9                   CPU Jobs                    -1
10                   Use GPU                 False
11            Log Experiment                 False
12           Experiment Name  anomaly-default-name
13                       USI                  f250
2024-05-04 14:15:27,340:INFO:setup() successfully completed in 3.69s...............
2024-05-04 14:15:41,933:INFO:PyCaret AnomalyExperiment
2024-05-04 14:15:41,933:INFO:Logging name: anomaly-default-name
2024-05-04 14:15:41,933:INFO:ML Usecase: MLUsecase.ANOMALY
2024-05-04 14:15:41,933:INFO:version 3.3.2
2024-05-04 14:15:41,933:INFO:Initializing setup()
2024-05-04 14:15:41,933:INFO:self.USI: 2fd6
2024-05-04 14:15:41,933:INFO:self._variable_keys: {'_available_plots', 'X', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'logging_param', 'log_plots_param', 'USI', '_ml_usecase', 'n_jobs_param', 'exp_name_log', 'idx', 'data', 'gpu_param', 'seed', 'memory', 'pipeline'}
2024-05-04 14:15:41,933:INFO:Checking environment
2024-05-04 14:15:41,933:INFO:python_version: 3.11.8
2024-05-04 14:15:41,933:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 14:15:41,933:INFO:machine: arm64
2024-05-04 14:15:41,933:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 14:15:41,933:INFO:Memory: svmem(total=17179869184, available=6274007040, percent=63.5, used=8330493952, free=71680000, active=6251708416, inactive=6071517184, wired=2078785536)
2024-05-04 14:15:41,933:INFO:Physical Core: 8
2024-05-04 14:15:41,933:INFO:Logical Core: 8
2024-05-04 14:15:41,933:INFO:Checking libraries
2024-05-04 14:15:41,933:INFO:System:
2024-05-04 14:15:41,933:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 14:15:41,933:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 14:15:41,933:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 14:15:41,933:INFO:PyCaret required dependencies:
2024-05-04 14:15:41,933:INFO:                 pip: 24.0
2024-05-04 14:15:41,933:INFO:          setuptools: 69.2.0
2024-05-04 14:15:41,933:INFO:             pycaret: 3.3.2
2024-05-04 14:15:41,933:INFO:             IPython: 8.22.2
2024-05-04 14:15:41,933:INFO:          ipywidgets: 8.1.2
2024-05-04 14:15:41,933:INFO:                tqdm: 4.66.2
2024-05-04 14:15:41,933:INFO:               numpy: 1.26.4
2024-05-04 14:15:41,933:INFO:              pandas: 2.1.4
2024-05-04 14:15:41,933:INFO:              jinja2: 3.1.3
2024-05-04 14:15:41,933:INFO:               scipy: 1.11.4
2024-05-04 14:15:41,933:INFO:              joblib: 1.3.2
2024-05-04 14:15:41,933:INFO:             sklearn: 1.4.1.post1
2024-05-04 14:15:41,934:INFO:                pyod: 1.1.3
2024-05-04 14:15:41,934:INFO:            imblearn: 0.12.2
2024-05-04 14:15:41,934:INFO:   category_encoders: 2.6.3
2024-05-04 14:15:41,934:INFO:            lightgbm: 4.3.0
2024-05-04 14:15:41,934:INFO:               numba: 0.59.1
2024-05-04 14:15:41,934:INFO:            requests: 2.31.0
2024-05-04 14:15:41,934:INFO:          matplotlib: 3.7.5
2024-05-04 14:15:41,934:INFO:          scikitplot: 0.3.7
2024-05-04 14:15:41,934:INFO:         yellowbrick: 1.5
2024-05-04 14:15:41,934:INFO:              plotly: 5.19.0
2024-05-04 14:15:41,934:INFO:    plotly-resampler: Not installed
2024-05-04 14:15:41,934:INFO:             kaleido: 0.2.1
2024-05-04 14:15:41,934:INFO:           schemdraw: 0.15
2024-05-04 14:15:41,934:INFO:         statsmodels: 0.14.1
2024-05-04 14:15:41,934:INFO:              sktime: 0.26.0
2024-05-04 14:15:41,934:INFO:               tbats: 1.1.3
2024-05-04 14:15:41,934:INFO:            pmdarima: 2.0.4
2024-05-04 14:15:41,934:INFO:              psutil: 5.9.8
2024-05-04 14:15:41,934:INFO:          markupsafe: 2.1.5
2024-05-04 14:15:41,934:INFO:             pickle5: Not installed
2024-05-04 14:15:41,934:INFO:         cloudpickle: 3.0.0
2024-05-04 14:15:41,934:INFO:         deprecation: 2.1.0
2024-05-04 14:15:41,934:INFO:              xxhash: 3.4.1
2024-05-04 14:15:41,934:INFO:           wurlitzer: 3.0.3
2024-05-04 14:15:41,934:INFO:PyCaret optional dependencies:
2024-05-04 14:15:41,934:INFO:                shap: 0.44.1
2024-05-04 14:15:41,934:INFO:           interpret: 0.6.1
2024-05-04 14:15:41,934:INFO:                umap: 0.5.6
2024-05-04 14:15:41,934:INFO:     ydata_profiling: 4.7.0
2024-05-04 14:15:41,934:INFO:  explainerdashboard: 0.4.7
2024-05-04 14:15:41,934:INFO:             autoviz: Not installed
2024-05-04 14:15:41,934:INFO:           fairlearn: 0.7.0
2024-05-04 14:15:41,934:INFO:          deepchecks: Not installed
2024-05-04 14:15:41,934:INFO:             xgboost: Not installed
2024-05-04 14:15:41,934:INFO:            catboost: Not installed
2024-05-04 14:15:41,934:INFO:              kmodes: Not installed
2024-05-04 14:15:41,934:INFO:             mlxtend: 0.23.1
2024-05-04 14:15:41,934:INFO:       statsforecast: Not installed
2024-05-04 14:15:41,934:INFO:        tune_sklearn: Not installed
2024-05-04 14:15:41,934:INFO:                 ray: Not installed
2024-05-04 14:15:41,934:INFO:            hyperopt: Not installed
2024-05-04 14:15:41,934:INFO:              optuna: Not installed
2024-05-04 14:15:41,934:INFO:               skopt: Not installed
2024-05-04 14:15:41,934:INFO:              mlflow: 2.12.1
2024-05-04 14:15:41,934:INFO:              gradio: 4.29.0
2024-05-04 14:15:41,934:INFO:             fastapi: 0.111.0
2024-05-04 14:15:41,934:INFO:             uvicorn: 0.29.0
2024-05-04 14:15:41,934:INFO:              m2cgen: 0.10.0
2024-05-04 14:15:41,934:INFO:           evidently: 0.4.20
2024-05-04 14:15:41,934:INFO:               fugue: 0.8.7
2024-05-04 14:15:41,935:INFO:           streamlit: 1.33.0
2024-05-04 14:15:41,935:INFO:             prophet: Not installed
2024-05-04 14:15:41,935:INFO:None
2024-05-04 14:15:41,935:INFO:Set up data.
2024-05-04 14:15:41,936:INFO:Set up index.
2024-05-04 14:15:41,941:INFO:Assigning column types.
2024-05-04 14:15:41,943:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2024-05-04 14:15:41,943:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2024-05-04 14:15:41,944:INFO:Preparing preprocessing pipeline...
2024-05-04 14:15:41,944:INFO:Set up simple imputation.
2024-05-04 14:15:42,639:INFO:Finished creating preprocessing pipeline.
2024-05-04 14:15:42,641:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group;I1;I2;I3;I4;I5;I6;I7;I8;I9;I10;I11;I12;I13;I14;I15;I16;I17;I18;I19;I20;I21;I22;I23;I24;I25;I26;I27;I28;I29;I30;I31;I32;I33;I34;I35;I36;I37;I38;I39;I40;I41;I42;I43;I44;I45;I46;I47;I48;I49;I50;I51...;dI20;dI21;dI22;dI23;dI24;dI25;dI26;dI27;dI28;dI29;dI30;dI31;dI32;dI33;dI34;dI35;dI36;dI37;dI38;dI39;dI40;dI41;dI42;dI43;dI44;dI45;dI46;dI47;dI48;dI49;dI50;dI51;dI52;dI53;dI54;dI55;dI56;dI57;dI58;Class;Perform'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-05-04 14:15:42,641:INFO:Creating final display dataframe.
2024-05-04 14:15:42,947:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   123
1        Original data shape             (8000, 1)
2     Transformed data shape             (8000, 1)
3           Numeric features                     1
4   Rows with missing values                 44.6%
5                 Preprocess                  True
6            Imputation type                simple
7         Numeric imputation                  mean
8     Categorical imputation                  mode
9                   CPU Jobs                    -1
10                   Use GPU                 False
11            Log Experiment                 False
12           Experiment Name  anomaly-default-name
13                       USI                  2fd6
2024-05-04 14:15:42,950:INFO:setup() successfully completed in 1.02s...............
2024-05-04 14:15:46,316:INFO:Initializing create_model()
2024-05-04 14:15:46,316:INFO:create_model(self=<pycaret.anomaly.oop.AnomalyExperiment object at 0x1045e7e90>, estimator=iforest, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2024-05-04 14:15:46,316:INFO:Checking exceptions
2024-05-04 14:15:46,652:INFO:Importing untrained model
2024-05-04 14:15:46,653:INFO:Isolation Forest Imported successfully
2024-05-04 14:15:46,654:INFO:Fitting Model
2024-05-04 14:15:46,803:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=123, verbose=0)
2024-05-04 14:15:46,803:INFO:create_models() successfully completed......................................
2024-05-04 14:15:46,805:INFO:Uploading results into container
2024-05-04 14:15:46,805:INFO:Uploading model into container now
2024-05-04 14:15:46,806:INFO:_master_model_container: 1
2024-05-04 14:15:46,806:INFO:_display_container: 1
2024-05-04 14:15:46,806:INFO:IForest(behaviour='new', bootstrap=False, contamination=0.05,
    max_features=1.0, max_samples='auto', n_estimators=100, n_jobs=-1,
    random_state=123, verbose=0)
2024-05-04 14:15:46,806:INFO:create_model() successfully completed......................................
2024-05-04 15:10:49,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 15:10:49,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 15:10:49,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 15:10:49,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 15:10:50,095:INFO:PyCaret ClassificationExperiment
2024-05-04 15:10:50,095:INFO:Logging name: clf-default-name
2024-05-04 15:10:50,095:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:10:50,095:INFO:version 3.3.2
2024-05-04 15:10:50,095:INFO:Initializing setup()
2024-05-04 15:10:50,095:INFO:self.USI: 9562
2024-05-04 15:10:50,095:INFO:self._variable_keys: {'_available_plots', 'USI', 'X_train', 'n_jobs_param', 'gpu_n_jobs_param', 'pipeline', 'idx', 'logging_param', 'target_param', 'seed', 'html_param', 'data', 'y_train', 'X_test', 'y_test', 'X', 'is_multiclass', '_ml_usecase', 'exp_id', 'fold_shuffle_param', 'fix_imbalance', 'fold_generator', 'exp_name_log', 'memory', 'gpu_param', 'y', 'fold_groups_param', 'log_plots_param'}
2024-05-04 15:10:50,095:INFO:Checking environment
2024-05-04 15:10:50,096:INFO:python_version: 3.11.8
2024-05-04 15:10:50,096:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:10:50,096:INFO:machine: arm64
2024-05-04 15:10:50,096:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:10:50,096:INFO:Memory: svmem(total=17179869184, available=6435848192, percent=62.5, used=8501673984, free=46710784, active=6409535488, inactive=6276874240, wired=2092138496)
2024-05-04 15:10:50,096:INFO:Physical Core: 8
2024-05-04 15:10:50,096:INFO:Logical Core: 8
2024-05-04 15:10:50,096:INFO:Checking libraries
2024-05-04 15:10:50,096:INFO:System:
2024-05-04 15:10:50,096:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:10:50,096:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:10:50,096:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:10:50,096:INFO:PyCaret required dependencies:
2024-05-04 15:10:50,600:INFO:                 pip: 24.0
2024-05-04 15:10:50,600:INFO:          setuptools: 69.2.0
2024-05-04 15:10:50,600:INFO:             pycaret: 3.3.2
2024-05-04 15:10:50,600:INFO:             IPython: 8.22.2
2024-05-04 15:10:50,600:INFO:          ipywidgets: 8.1.2
2024-05-04 15:10:50,600:INFO:                tqdm: 4.66.2
2024-05-04 15:10:50,600:INFO:               numpy: 1.26.4
2024-05-04 15:10:50,600:INFO:              pandas: 2.1.4
2024-05-04 15:10:50,600:INFO:              jinja2: 3.1.3
2024-05-04 15:10:50,600:INFO:               scipy: 1.11.4
2024-05-04 15:10:50,600:INFO:              joblib: 1.3.2
2024-05-04 15:10:50,600:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:10:50,600:INFO:                pyod: 1.1.3
2024-05-04 15:10:50,600:INFO:            imblearn: 0.12.2
2024-05-04 15:10:50,600:INFO:   category_encoders: 2.6.3
2024-05-04 15:10:50,600:INFO:            lightgbm: 4.3.0
2024-05-04 15:10:50,600:INFO:               numba: 0.59.1
2024-05-04 15:10:50,600:INFO:            requests: 2.31.0
2024-05-04 15:10:50,600:INFO:          matplotlib: 3.7.5
2024-05-04 15:10:50,600:INFO:          scikitplot: 0.3.7
2024-05-04 15:10:50,600:INFO:         yellowbrick: 1.5
2024-05-04 15:10:50,600:INFO:              plotly: 5.19.0
2024-05-04 15:10:50,600:INFO:    plotly-resampler: Not installed
2024-05-04 15:10:50,600:INFO:             kaleido: 0.2.1
2024-05-04 15:10:50,600:INFO:           schemdraw: 0.15
2024-05-04 15:10:50,600:INFO:         statsmodels: 0.14.1
2024-05-04 15:10:50,600:INFO:              sktime: 0.26.0
2024-05-04 15:10:50,600:INFO:               tbats: 1.1.3
2024-05-04 15:10:50,600:INFO:            pmdarima: 2.0.4
2024-05-04 15:10:50,600:INFO:              psutil: 5.9.8
2024-05-04 15:10:50,600:INFO:          markupsafe: 2.1.5
2024-05-04 15:10:50,600:INFO:             pickle5: Not installed
2024-05-04 15:10:50,600:INFO:         cloudpickle: 3.0.0
2024-05-04 15:10:50,600:INFO:         deprecation: 2.1.0
2024-05-04 15:10:50,600:INFO:              xxhash: 3.4.1
2024-05-04 15:10:50,600:INFO:           wurlitzer: 3.0.3
2024-05-04 15:10:50,600:INFO:PyCaret optional dependencies:
2024-05-04 15:10:51,545:INFO:                shap: 0.44.1
2024-05-04 15:10:51,545:INFO:           interpret: 0.6.1
2024-05-04 15:10:51,545:INFO:                umap: 0.5.6
2024-05-04 15:10:51,545:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:10:51,545:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:10:51,545:INFO:             autoviz: Not installed
2024-05-04 15:10:51,545:INFO:           fairlearn: 0.7.0
2024-05-04 15:10:51,545:INFO:          deepchecks: Not installed
2024-05-04 15:10:51,545:INFO:             xgboost: Not installed
2024-05-04 15:10:51,545:INFO:            catboost: Not installed
2024-05-04 15:10:51,545:INFO:              kmodes: Not installed
2024-05-04 15:10:51,545:INFO:             mlxtend: 0.23.1
2024-05-04 15:10:51,545:INFO:       statsforecast: Not installed
2024-05-04 15:10:51,545:INFO:        tune_sklearn: Not installed
2024-05-04 15:10:51,545:INFO:                 ray: Not installed
2024-05-04 15:10:51,545:INFO:            hyperopt: Not installed
2024-05-04 15:10:51,545:INFO:              optuna: Not installed
2024-05-04 15:10:51,545:INFO:               skopt: Not installed
2024-05-04 15:10:51,545:INFO:              mlflow: 2.12.1
2024-05-04 15:10:51,545:INFO:              gradio: 4.29.0
2024-05-04 15:10:51,545:INFO:             fastapi: 0.111.0
2024-05-04 15:10:51,545:INFO:             uvicorn: 0.29.0
2024-05-04 15:10:51,545:INFO:              m2cgen: 0.10.0
2024-05-04 15:10:51,545:INFO:           evidently: 0.4.20
2024-05-04 15:10:51,545:INFO:               fugue: 0.8.7
2024-05-04 15:10:51,545:INFO:           streamlit: 1.33.0
2024-05-04 15:10:51,545:INFO:             prophet: Not installed
2024-05-04 15:10:51,545:INFO:None
2024-05-04 15:10:51,545:INFO:Set up data.
2024-05-04 15:10:52,027:INFO:Set up folding strategy.
2024-05-04 15:10:52,027:INFO:Set up train/test split.
2024-05-04 15:10:52,175:INFO:Set up index.
2024-05-04 15:10:52,176:INFO:Assigning column types.
2024-05-04 15:10:52,182:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 15:10:52,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:10:52,204:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:10:52,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:10:52,240:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:10:52,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,252:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 15:10:52,272:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:10:52,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,303:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:10:52,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,315:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-04 15:10:52,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:10:52,379:INFO:Preparing preprocessing pipeline...
2024-05-04 15:10:52,381:INFO:Set up label encoding.
2024-05-04 15:10:52,381:INFO:Set up simple imputation.
2024-05-04 15:10:52,393:INFO:Set up encoding of categorical features.
2024-05-04 15:10:56,395:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:278: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2024-05-04 15:10:56,398:INFO:Finished creating preprocessing pipeline.
2024-05-04 15:10:56,402:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-04 15:10:56,402:INFO:Creating final display dataframe.
2024-05-04 15:10:59,074:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:111: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2024-05-04 15:10:59,594:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:289: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-04 15:11:02,238:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:289: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-04 15:11:03,264:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target              Class
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape        (8000, 118)
5        Transformed data shape        (8000, 128)
6   Transformed train set shape        (5600, 128)
7    Transformed test set shape        (2400, 128)
8          Categorical features                117
9      Rows with missing values              35.1%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16               Fold Generator    StratifiedKFold
17                  Fold Number                 10
18                     CPU Jobs                 -1
19                      Use GPU              False
20               Log Experiment              False
21              Experiment Name   clf-default-name
22                          USI               9562
2024-05-04 15:11:03,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:03,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:03,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:03,334:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:03,335:INFO:setup() successfully completed in 13.24s...............
2024-05-04 15:11:33,262:INFO:PyCaret ClassificationExperiment
2024-05-04 15:11:33,262:INFO:Logging name: clf-default-name
2024-05-04 15:11:33,262:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:11:33,262:INFO:version 3.3.2
2024-05-04 15:11:33,262:INFO:Initializing setup()
2024-05-04 15:11:33,262:INFO:self.USI: e331
2024-05-04 15:11:33,262:INFO:self._variable_keys: {'_available_plots', 'USI', 'X_train', 'n_jobs_param', 'gpu_n_jobs_param', 'pipeline', 'idx', 'logging_param', 'target_param', 'seed', 'html_param', 'data', 'y_train', 'X_test', 'y_test', 'X', 'is_multiclass', '_ml_usecase', 'exp_id', 'fold_shuffle_param', 'fix_imbalance', 'fold_generator', 'exp_name_log', 'memory', 'gpu_param', 'y', 'fold_groups_param', 'log_plots_param'}
2024-05-04 15:11:33,262:INFO:Checking environment
2024-05-04 15:11:33,262:INFO:python_version: 3.11.8
2024-05-04 15:11:33,262:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:11:33,262:INFO:machine: arm64
2024-05-04 15:11:33,262:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:11:33,262:INFO:Memory: svmem(total=17179869184, available=6165708800, percent=64.1, used=8175779840, free=135299072, active=6149685248, inactive=5950816256, wired=2026094592)
2024-05-04 15:11:33,262:INFO:Physical Core: 8
2024-05-04 15:11:33,262:INFO:Logical Core: 8
2024-05-04 15:11:33,262:INFO:Checking libraries
2024-05-04 15:11:33,262:INFO:System:
2024-05-04 15:11:33,262:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:11:33,262:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:11:33,263:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:11:33,263:INFO:PyCaret required dependencies:
2024-05-04 15:11:33,263:INFO:                 pip: 24.0
2024-05-04 15:11:33,263:INFO:          setuptools: 69.2.0
2024-05-04 15:11:33,263:INFO:             pycaret: 3.3.2
2024-05-04 15:11:33,263:INFO:             IPython: 8.22.2
2024-05-04 15:11:33,263:INFO:          ipywidgets: 8.1.2
2024-05-04 15:11:33,263:INFO:                tqdm: 4.66.2
2024-05-04 15:11:33,263:INFO:               numpy: 1.26.4
2024-05-04 15:11:33,263:INFO:              pandas: 2.1.4
2024-05-04 15:11:33,263:INFO:              jinja2: 3.1.3
2024-05-04 15:11:33,263:INFO:               scipy: 1.11.4
2024-05-04 15:11:33,263:INFO:              joblib: 1.3.2
2024-05-04 15:11:33,263:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:11:33,263:INFO:                pyod: 1.1.3
2024-05-04 15:11:33,263:INFO:            imblearn: 0.12.2
2024-05-04 15:11:33,263:INFO:   category_encoders: 2.6.3
2024-05-04 15:11:33,263:INFO:            lightgbm: 4.3.0
2024-05-04 15:11:33,263:INFO:               numba: 0.59.1
2024-05-04 15:11:33,263:INFO:            requests: 2.31.0
2024-05-04 15:11:33,263:INFO:          matplotlib: 3.7.5
2024-05-04 15:11:33,263:INFO:          scikitplot: 0.3.7
2024-05-04 15:11:33,263:INFO:         yellowbrick: 1.5
2024-05-04 15:11:33,263:INFO:              plotly: 5.19.0
2024-05-04 15:11:33,263:INFO:    plotly-resampler: Not installed
2024-05-04 15:11:33,263:INFO:             kaleido: 0.2.1
2024-05-04 15:11:33,263:INFO:           schemdraw: 0.15
2024-05-04 15:11:33,263:INFO:         statsmodels: 0.14.1
2024-05-04 15:11:33,263:INFO:              sktime: 0.26.0
2024-05-04 15:11:33,263:INFO:               tbats: 1.1.3
2024-05-04 15:11:33,263:INFO:            pmdarima: 2.0.4
2024-05-04 15:11:33,263:INFO:              psutil: 5.9.8
2024-05-04 15:11:33,263:INFO:          markupsafe: 2.1.5
2024-05-04 15:11:33,263:INFO:             pickle5: Not installed
2024-05-04 15:11:33,263:INFO:         cloudpickle: 3.0.0
2024-05-04 15:11:33,263:INFO:         deprecation: 2.1.0
2024-05-04 15:11:33,263:INFO:              xxhash: 3.4.1
2024-05-04 15:11:33,263:INFO:           wurlitzer: 3.0.3
2024-05-04 15:11:33,263:INFO:PyCaret optional dependencies:
2024-05-04 15:11:33,264:INFO:                shap: 0.44.1
2024-05-04 15:11:33,264:INFO:           interpret: 0.6.1
2024-05-04 15:11:33,264:INFO:                umap: 0.5.6
2024-05-04 15:11:33,264:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:11:33,264:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:11:33,264:INFO:             autoviz: Not installed
2024-05-04 15:11:33,264:INFO:           fairlearn: 0.7.0
2024-05-04 15:11:33,264:INFO:          deepchecks: Not installed
2024-05-04 15:11:33,264:INFO:             xgboost: Not installed
2024-05-04 15:11:33,264:INFO:            catboost: Not installed
2024-05-04 15:11:33,264:INFO:              kmodes: Not installed
2024-05-04 15:11:33,264:INFO:             mlxtend: 0.23.1
2024-05-04 15:11:33,264:INFO:       statsforecast: Not installed
2024-05-04 15:11:33,264:INFO:        tune_sklearn: Not installed
2024-05-04 15:11:33,264:INFO:                 ray: Not installed
2024-05-04 15:11:33,264:INFO:            hyperopt: Not installed
2024-05-04 15:11:33,264:INFO:              optuna: Not installed
2024-05-04 15:11:33,264:INFO:               skopt: Not installed
2024-05-04 15:11:33,264:INFO:              mlflow: 2.12.1
2024-05-04 15:11:33,264:INFO:              gradio: 4.29.0
2024-05-04 15:11:33,264:INFO:             fastapi: 0.111.0
2024-05-04 15:11:33,264:INFO:             uvicorn: 0.29.0
2024-05-04 15:11:33,264:INFO:              m2cgen: 0.10.0
2024-05-04 15:11:33,264:INFO:           evidently: 0.4.20
2024-05-04 15:11:33,264:INFO:               fugue: 0.8.7
2024-05-04 15:11:33,264:INFO:           streamlit: 1.33.0
2024-05-04 15:11:33,264:INFO:             prophet: Not installed
2024-05-04 15:11:33,264:INFO:None
2024-05-04 15:11:33,264:INFO:Set up data.
2024-05-04 15:11:33,726:INFO:Set up folding strategy.
2024-05-04 15:11:33,726:INFO:Set up train/test split.
2024-05-04 15:11:33,861:INFO:Set up index.
2024-05-04 15:11:33,862:INFO:Assigning column types.
2024-05-04 15:11:33,866:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 15:11:33,884:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:11:33,885:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:11:33,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:33,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:33,915:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:11:33,915:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:11:33,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:33,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:33,927:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 15:11:33,946:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:11:33,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:33,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:33,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:11:33,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:33,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:33,988:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-04 15:11:34,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:34,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:34,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:34,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:34,049:INFO:Preparing preprocessing pipeline...
2024-05-04 15:11:34,050:INFO:Set up label encoding.
2024-05-04 15:11:34,051:INFO:Set up simple imputation.
2024-05-04 15:11:34,061:INFO:Set up encoding of categorical features.
2024-05-04 15:11:36,620:INFO:Finished creating preprocessing pipeline.
2024-05-04 15:11:36,624:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-04 15:11:36,624:INFO:Creating final display dataframe.
2024-05-04 15:11:43,175:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target              Class
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape        (8000, 118)
5        Transformed data shape        (8000, 128)
6   Transformed train set shape        (5600, 128)
7    Transformed test set shape        (2400, 128)
8          Categorical features                117
9      Rows with missing values              35.1%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16               Fold Generator    StratifiedKFold
17                  Fold Number                 10
18                     CPU Jobs                 -1
19                      Use GPU              False
20               Log Experiment              False
21              Experiment Name   clf-default-name
22                          USI               e331
2024-05-04 15:11:43,208:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:43,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:43,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:43,239:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:11:43,240:INFO:setup() successfully completed in 9.98s...............
2024-05-04 15:12:01,508:INFO:Initializing compare_models()
2024-05-04 15:12:01,509:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15c8f6550>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x15c8f6550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-04 15:12:01,509:INFO:Checking exceptions
2024-05-04 15:12:01,516:INFO:Preparing display monitor
2024-05-04 15:12:01,567:INFO:Initializing Logistic Regression
2024-05-04 15:12:01,567:INFO:Total runtime is 5.102157592773437e-06 minutes
2024-05-04 15:12:01,568:INFO:SubProcess create_model() called ==================================
2024-05-04 15:12:01,569:INFO:Initializing create_model()
2024-05-04 15:12:01,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15c8f6550>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1683cefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:12:01,569:INFO:Checking exceptions
2024-05-04 15:12:01,569:INFO:Importing libraries
2024-05-04 15:12:01,569:INFO:Copying training dataset
2024-05-04 15:12:01,581:INFO:Defining folds
2024-05-04 15:12:01,581:INFO:Declaring metric variables
2024-05-04 15:12:01,583:INFO:Importing untrained model
2024-05-04 15:12:01,584:INFO:Logistic Regression Imported successfully
2024-05-04 15:12:01,587:INFO:Starting cross validation
2024-05-04 15:12:01,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:12:06,214:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:06,218:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:06,320:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:06,322:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:06,324:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:06,326:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:06,676:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:06,680:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:06,717:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:06,720:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:06,791:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:06,793:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:06,847:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:06,850:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:07,011:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:07,013:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:07,989:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:07,991:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:08,138:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:12:08,140:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:08,147:INFO:Calculating mean and std
2024-05-04 15:12:08,149:INFO:Creating metrics dataframe
2024-05-04 15:12:08,152:INFO:Uploading results into container
2024-05-04 15:12:08,153:INFO:Uploading model into container now
2024-05-04 15:12:08,153:INFO:_master_model_container: 1
2024-05-04 15:12:08,153:INFO:_display_container: 2
2024-05-04 15:12:08,154:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-04 15:12:08,154:INFO:create_model() successfully completed......................................
2024-05-04 15:12:08,291:INFO:SubProcess create_model() end ==================================
2024-05-04 15:12:08,291:INFO:Creating metrics dataframe
2024-05-04 15:12:08,294:INFO:Initializing K Neighbors Classifier
2024-05-04 15:12:08,294:INFO:Total runtime is 0.11212371587753296 minutes
2024-05-04 15:12:08,295:INFO:SubProcess create_model() called ==================================
2024-05-04 15:12:08,295:INFO:Initializing create_model()
2024-05-04 15:12:08,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15c8f6550>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1683cefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:12:08,295:INFO:Checking exceptions
2024-05-04 15:12:08,295:INFO:Importing libraries
2024-05-04 15:12:08,296:INFO:Copying training dataset
2024-05-04 15:12:08,304:INFO:Defining folds
2024-05-04 15:12:08,304:INFO:Declaring metric variables
2024-05-04 15:12:08,306:INFO:Importing untrained model
2024-05-04 15:12:08,307:INFO:K Neighbors Classifier Imported successfully
2024-05-04 15:12:08,310:INFO:Starting cross validation
2024-05-04 15:12:08,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:12:10,356:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:10,357:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:10,562:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:10,688:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:10,847:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:10,858:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:11,079:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:11,369:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:11,945:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:12,001:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:12,006:INFO:Calculating mean and std
2024-05-04 15:12:12,007:INFO:Creating metrics dataframe
2024-05-04 15:12:12,009:INFO:Uploading results into container
2024-05-04 15:12:12,009:INFO:Uploading model into container now
2024-05-04 15:12:12,010:INFO:_master_model_container: 2
2024-05-04 15:12:12,010:INFO:_display_container: 2
2024-05-04 15:12:12,010:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-04 15:12:12,010:INFO:create_model() successfully completed......................................
2024-05-04 15:12:12,133:INFO:SubProcess create_model() end ==================================
2024-05-04 15:12:12,133:INFO:Creating metrics dataframe
2024-05-04 15:12:12,137:INFO:Initializing Naive Bayes
2024-05-04 15:12:12,137:INFO:Total runtime is 0.17616948286692302 minutes
2024-05-04 15:12:12,138:INFO:SubProcess create_model() called ==================================
2024-05-04 15:12:12,139:INFO:Initializing create_model()
2024-05-04 15:12:12,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15c8f6550>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1683cefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:12:12,139:INFO:Checking exceptions
2024-05-04 15:12:12,139:INFO:Importing libraries
2024-05-04 15:12:12,139:INFO:Copying training dataset
2024-05-04 15:12:12,148:INFO:Defining folds
2024-05-04 15:12:12,148:INFO:Declaring metric variables
2024-05-04 15:12:12,150:INFO:Importing untrained model
2024-05-04 15:12:12,151:INFO:Naive Bayes Imported successfully
2024-05-04 15:12:12,154:INFO:Starting cross validation
2024-05-04 15:12:12,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:12:14,980:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:15,042:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:15,186:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:15,277:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:15,332:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:15,493:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:15,687:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:15,721:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:16,575:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:16,713:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:16,727:INFO:Calculating mean and std
2024-05-04 15:12:16,728:INFO:Creating metrics dataframe
2024-05-04 15:12:16,729:INFO:Uploading results into container
2024-05-04 15:12:16,730:INFO:Uploading model into container now
2024-05-04 15:12:16,730:INFO:_master_model_container: 3
2024-05-04 15:12:16,730:INFO:_display_container: 2
2024-05-04 15:12:16,730:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-04 15:12:16,730:INFO:create_model() successfully completed......................................
2024-05-04 15:12:16,855:INFO:SubProcess create_model() end ==================================
2024-05-04 15:12:16,855:INFO:Creating metrics dataframe
2024-05-04 15:12:16,858:INFO:Initializing Decision Tree Classifier
2024-05-04 15:12:16,858:INFO:Total runtime is 0.25485973358154296 minutes
2024-05-04 15:12:16,860:INFO:SubProcess create_model() called ==================================
2024-05-04 15:12:16,860:INFO:Initializing create_model()
2024-05-04 15:12:16,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x15c8f6550>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1683cefd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:12:16,860:INFO:Checking exceptions
2024-05-04 15:12:16,860:INFO:Importing libraries
2024-05-04 15:12:16,860:INFO:Copying training dataset
2024-05-04 15:12:16,870:INFO:Defining folds
2024-05-04 15:12:16,870:INFO:Declaring metric variables
2024-05-04 15:12:16,873:INFO:Importing untrained model
2024-05-04 15:12:16,875:INFO:Decision Tree Classifier Imported successfully
2024-05-04 15:12:16,878:INFO:Starting cross validation
2024-05-04 15:12:16,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:12:18,906:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:19,076:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:19,324:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:19,399:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:19,404:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:19,522:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:19,572:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:12:19,660:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:07,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 15:14:07,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 15:14:07,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 15:14:07,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 15:14:08,470:INFO:PyCaret ClassificationExperiment
2024-05-04 15:14:08,470:INFO:Logging name: clf-default-name
2024-05-04 15:14:08,470:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:14:08,470:INFO:version 3.3.2
2024-05-04 15:14:08,470:INFO:Initializing setup()
2024-05-04 15:14:08,470:INFO:self.USI: 3ab6
2024-05-04 15:14:08,470:INFO:self._variable_keys: {'target_param', 'y', 'y_test', 'logging_param', 'gpu_n_jobs_param', 'fix_imbalance', 'data', 'html_param', 'exp_name_log', 'memory', 'idx', 'pipeline', 'X', 'gpu_param', 'X_train', 'is_multiclass', 'n_jobs_param', 'X_test', 'USI', 'exp_id', 'log_plots_param', 'y_train', 'fold_groups_param', '_ml_usecase', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'seed'}
2024-05-04 15:14:08,470:INFO:Checking environment
2024-05-04 15:14:08,470:INFO:python_version: 3.11.8
2024-05-04 15:14:08,470:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:14:08,470:INFO:machine: arm64
2024-05-04 15:14:08,470:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:14:08,470:INFO:Memory: svmem(total=17179869184, available=6507200512, percent=62.1, used=7354449920, free=1214709760, active=5297258496, inactive=4661002240, wired=2057191424)
2024-05-04 15:14:08,470:INFO:Physical Core: 8
2024-05-04 15:14:08,470:INFO:Logical Core: 8
2024-05-04 15:14:08,470:INFO:Checking libraries
2024-05-04 15:14:08,470:INFO:System:
2024-05-04 15:14:08,470:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:14:08,470:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:14:08,470:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:14:08,470:INFO:PyCaret required dependencies:
2024-05-04 15:14:08,881:INFO:                 pip: 24.0
2024-05-04 15:14:08,881:INFO:          setuptools: 69.2.0
2024-05-04 15:14:08,881:INFO:             pycaret: 3.3.2
2024-05-04 15:14:08,881:INFO:             IPython: 8.22.2
2024-05-04 15:14:08,881:INFO:          ipywidgets: 8.1.2
2024-05-04 15:14:08,881:INFO:                tqdm: 4.66.2
2024-05-04 15:14:08,882:INFO:               numpy: 1.26.4
2024-05-04 15:14:08,882:INFO:              pandas: 2.1.4
2024-05-04 15:14:08,882:INFO:              jinja2: 3.1.3
2024-05-04 15:14:08,882:INFO:               scipy: 1.11.4
2024-05-04 15:14:08,882:INFO:              joblib: 1.3.2
2024-05-04 15:14:08,882:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:14:08,882:INFO:                pyod: 1.1.3
2024-05-04 15:14:08,882:INFO:            imblearn: 0.12.2
2024-05-04 15:14:08,882:INFO:   category_encoders: 2.6.3
2024-05-04 15:14:08,882:INFO:            lightgbm: 4.3.0
2024-05-04 15:14:08,882:INFO:               numba: 0.59.1
2024-05-04 15:14:08,882:INFO:            requests: 2.31.0
2024-05-04 15:14:08,882:INFO:          matplotlib: 3.7.5
2024-05-04 15:14:08,882:INFO:          scikitplot: 0.3.7
2024-05-04 15:14:08,882:INFO:         yellowbrick: 1.5
2024-05-04 15:14:08,882:INFO:              plotly: 5.19.0
2024-05-04 15:14:08,882:INFO:    plotly-resampler: Not installed
2024-05-04 15:14:08,882:INFO:             kaleido: 0.2.1
2024-05-04 15:14:08,882:INFO:           schemdraw: 0.15
2024-05-04 15:14:08,882:INFO:         statsmodels: 0.14.1
2024-05-04 15:14:08,882:INFO:              sktime: 0.26.0
2024-05-04 15:14:08,882:INFO:               tbats: 1.1.3
2024-05-04 15:14:08,882:INFO:            pmdarima: 2.0.4
2024-05-04 15:14:08,882:INFO:              psutil: 5.9.8
2024-05-04 15:14:08,882:INFO:          markupsafe: 2.1.5
2024-05-04 15:14:08,882:INFO:             pickle5: Not installed
2024-05-04 15:14:08,882:INFO:         cloudpickle: 3.0.0
2024-05-04 15:14:08,882:INFO:         deprecation: 2.1.0
2024-05-04 15:14:08,882:INFO:              xxhash: 3.4.1
2024-05-04 15:14:08,882:INFO:           wurlitzer: 3.0.3
2024-05-04 15:14:08,882:INFO:PyCaret optional dependencies:
2024-05-04 15:14:09,863:INFO:                shap: 0.44.1
2024-05-04 15:14:09,863:INFO:           interpret: 0.6.1
2024-05-04 15:14:09,863:INFO:                umap: 0.5.6
2024-05-04 15:14:09,863:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:14:09,863:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:14:09,863:INFO:             autoviz: Not installed
2024-05-04 15:14:09,863:INFO:           fairlearn: 0.7.0
2024-05-04 15:14:09,863:INFO:          deepchecks: Not installed
2024-05-04 15:14:09,863:INFO:             xgboost: Not installed
2024-05-04 15:14:09,863:INFO:            catboost: Not installed
2024-05-04 15:14:09,863:INFO:              kmodes: Not installed
2024-05-04 15:14:09,863:INFO:             mlxtend: 0.23.1
2024-05-04 15:14:09,863:INFO:       statsforecast: Not installed
2024-05-04 15:14:09,863:INFO:        tune_sklearn: Not installed
2024-05-04 15:14:09,863:INFO:                 ray: Not installed
2024-05-04 15:14:09,863:INFO:            hyperopt: Not installed
2024-05-04 15:14:09,864:INFO:              optuna: Not installed
2024-05-04 15:14:09,864:INFO:               skopt: Not installed
2024-05-04 15:14:09,864:INFO:              mlflow: 2.12.1
2024-05-04 15:14:09,864:INFO:              gradio: 4.29.0
2024-05-04 15:14:09,864:INFO:             fastapi: 0.111.0
2024-05-04 15:14:09,864:INFO:             uvicorn: 0.29.0
2024-05-04 15:14:09,864:INFO:              m2cgen: 0.10.0
2024-05-04 15:14:09,864:INFO:           evidently: 0.4.20
2024-05-04 15:14:09,864:INFO:               fugue: 0.8.7
2024-05-04 15:14:09,864:INFO:           streamlit: 1.33.0
2024-05-04 15:14:09,864:INFO:             prophet: Not installed
2024-05-04 15:14:09,864:INFO:None
2024-05-04 15:14:09,864:INFO:Set up data.
2024-05-04 15:14:10,328:INFO:Set up folding strategy.
2024-05-04 15:14:10,328:INFO:Set up train/test split.
2024-05-04 15:14:10,492:INFO:Set up index.
2024-05-04 15:14:10,493:INFO:Assigning column types.
2024-05-04 15:14:10,497:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 15:14:10,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:14:10,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:14:10,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,551:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:14:10,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:14:10,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,563:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 15:14:10,582:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:14:10,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,612:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:14:10,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,624:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-04 15:14:10,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,686:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:10,686:INFO:Preparing preprocessing pipeline...
2024-05-04 15:14:10,687:INFO:Set up label encoding.
2024-05-04 15:14:10,687:INFO:Set up simple imputation.
2024-05-04 15:14:10,697:INFO:Set up encoding of categorical features.
2024-05-04 15:14:12,781:INFO:Finished creating preprocessing pipeline.
2024-05-04 15:14:12,785:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-04 15:14:12,785:INFO:Creating final display dataframe.
2024-05-04 15:14:15,093:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target              Class
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape        (8000, 118)
5        Transformed data shape        (8000, 128)
6   Transformed train set shape        (5600, 128)
7    Transformed test set shape        (2400, 128)
8          Categorical features                117
9      Rows with missing values              35.1%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16               Fold Generator    StratifiedKFold
17                  Fold Number                 10
18                     CPU Jobs                 -1
19                      Use GPU              False
20               Log Experiment              False
21              Experiment Name   clf-default-name
22                          USI               3ab6
2024-05-04 15:14:15,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:15,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:15,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:15,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:15,159:INFO:setup() successfully completed in 6.69s...............
2024-05-04 15:14:24,841:INFO:PyCaret ClassificationExperiment
2024-05-04 15:14:24,841:INFO:Logging name: clf-default-name
2024-05-04 15:14:24,841:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:14:24,841:INFO:version 3.3.2
2024-05-04 15:14:24,841:INFO:Initializing setup()
2024-05-04 15:14:24,841:INFO:self.USI: 8b4b
2024-05-04 15:14:24,841:INFO:self._variable_keys: {'target_param', 'y', 'y_test', 'logging_param', 'gpu_n_jobs_param', 'fix_imbalance', 'data', 'html_param', 'exp_name_log', 'memory', 'idx', 'pipeline', 'X', 'gpu_param', 'X_train', 'is_multiclass', 'n_jobs_param', 'X_test', 'USI', 'exp_id', 'log_plots_param', 'y_train', 'fold_groups_param', '_ml_usecase', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'seed'}
2024-05-04 15:14:24,841:INFO:Checking environment
2024-05-04 15:14:24,841:INFO:python_version: 3.11.8
2024-05-04 15:14:24,841:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:14:24,841:INFO:machine: arm64
2024-05-04 15:14:24,841:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:14:24,841:INFO:Memory: svmem(total=17179869184, available=6206865408, percent=63.9, used=7661076480, free=641581056, active=5535809536, inactive=4897210368, wired=2125266944)
2024-05-04 15:14:24,841:INFO:Physical Core: 8
2024-05-04 15:14:24,841:INFO:Logical Core: 8
2024-05-04 15:14:24,841:INFO:Checking libraries
2024-05-04 15:14:24,841:INFO:System:
2024-05-04 15:14:24,841:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:14:24,841:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:14:24,841:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:14:24,841:INFO:PyCaret required dependencies:
2024-05-04 15:14:24,841:INFO:                 pip: 24.0
2024-05-04 15:14:24,842:INFO:          setuptools: 69.2.0
2024-05-04 15:14:24,842:INFO:             pycaret: 3.3.2
2024-05-04 15:14:24,842:INFO:             IPython: 8.22.2
2024-05-04 15:14:24,842:INFO:          ipywidgets: 8.1.2
2024-05-04 15:14:24,842:INFO:                tqdm: 4.66.2
2024-05-04 15:14:24,842:INFO:               numpy: 1.26.4
2024-05-04 15:14:24,842:INFO:              pandas: 2.1.4
2024-05-04 15:14:24,842:INFO:              jinja2: 3.1.3
2024-05-04 15:14:24,842:INFO:               scipy: 1.11.4
2024-05-04 15:14:24,842:INFO:              joblib: 1.3.2
2024-05-04 15:14:24,842:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:14:24,842:INFO:                pyod: 1.1.3
2024-05-04 15:14:24,842:INFO:            imblearn: 0.12.2
2024-05-04 15:14:24,842:INFO:   category_encoders: 2.6.3
2024-05-04 15:14:24,842:INFO:            lightgbm: 4.3.0
2024-05-04 15:14:24,842:INFO:               numba: 0.59.1
2024-05-04 15:14:24,842:INFO:            requests: 2.31.0
2024-05-04 15:14:24,842:INFO:          matplotlib: 3.7.5
2024-05-04 15:14:24,842:INFO:          scikitplot: 0.3.7
2024-05-04 15:14:24,842:INFO:         yellowbrick: 1.5
2024-05-04 15:14:24,842:INFO:              plotly: 5.19.0
2024-05-04 15:14:24,842:INFO:    plotly-resampler: Not installed
2024-05-04 15:14:24,842:INFO:             kaleido: 0.2.1
2024-05-04 15:14:24,842:INFO:           schemdraw: 0.15
2024-05-04 15:14:24,842:INFO:         statsmodels: 0.14.1
2024-05-04 15:14:24,842:INFO:              sktime: 0.26.0
2024-05-04 15:14:24,842:INFO:               tbats: 1.1.3
2024-05-04 15:14:24,842:INFO:            pmdarima: 2.0.4
2024-05-04 15:14:24,842:INFO:              psutil: 5.9.8
2024-05-04 15:14:24,842:INFO:          markupsafe: 2.1.5
2024-05-04 15:14:24,842:INFO:             pickle5: Not installed
2024-05-04 15:14:24,842:INFO:         cloudpickle: 3.0.0
2024-05-04 15:14:24,842:INFO:         deprecation: 2.1.0
2024-05-04 15:14:24,842:INFO:              xxhash: 3.4.1
2024-05-04 15:14:24,842:INFO:           wurlitzer: 3.0.3
2024-05-04 15:14:24,842:INFO:PyCaret optional dependencies:
2024-05-04 15:14:24,842:INFO:                shap: 0.44.1
2024-05-04 15:14:24,842:INFO:           interpret: 0.6.1
2024-05-04 15:14:24,842:INFO:                umap: 0.5.6
2024-05-04 15:14:24,842:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:14:24,842:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:14:24,842:INFO:             autoviz: Not installed
2024-05-04 15:14:24,842:INFO:           fairlearn: 0.7.0
2024-05-04 15:14:24,843:INFO:          deepchecks: Not installed
2024-05-04 15:14:24,843:INFO:             xgboost: Not installed
2024-05-04 15:14:24,843:INFO:            catboost: Not installed
2024-05-04 15:14:24,843:INFO:              kmodes: Not installed
2024-05-04 15:14:24,843:INFO:             mlxtend: 0.23.1
2024-05-04 15:14:24,843:INFO:       statsforecast: Not installed
2024-05-04 15:14:24,843:INFO:        tune_sklearn: Not installed
2024-05-04 15:14:24,843:INFO:                 ray: Not installed
2024-05-04 15:14:24,843:INFO:            hyperopt: Not installed
2024-05-04 15:14:24,843:INFO:              optuna: Not installed
2024-05-04 15:14:24,843:INFO:               skopt: Not installed
2024-05-04 15:14:24,843:INFO:              mlflow: 2.12.1
2024-05-04 15:14:24,843:INFO:              gradio: 4.29.0
2024-05-04 15:14:24,843:INFO:             fastapi: 0.111.0
2024-05-04 15:14:24,843:INFO:             uvicorn: 0.29.0
2024-05-04 15:14:24,843:INFO:              m2cgen: 0.10.0
2024-05-04 15:14:24,843:INFO:           evidently: 0.4.20
2024-05-04 15:14:24,843:INFO:               fugue: 0.8.7
2024-05-04 15:14:24,843:INFO:           streamlit: 1.33.0
2024-05-04 15:14:24,843:INFO:             prophet: Not installed
2024-05-04 15:14:24,843:INFO:None
2024-05-04 15:14:24,843:INFO:Set up data.
2024-05-04 15:14:25,301:INFO:Set up folding strategy.
2024-05-04 15:14:25,301:INFO:Set up train/test split.
2024-05-04 15:14:25,490:INFO:Set up index.
2024-05-04 15:14:25,491:INFO:Assigning column types.
2024-05-04 15:14:25,495:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 15:14:25,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:14:25,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:14:25,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,550:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:14:25,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:14:25,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,564:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 15:14:25,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:14:25,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:14:25,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,632:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-04 15:14:25,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:25,700:INFO:Preparing preprocessing pipeline...
2024-05-04 15:14:25,701:INFO:Set up label encoding.
2024-05-04 15:14:25,701:INFO:Set up simple imputation.
2024-05-04 15:14:25,714:INFO:Set up encoding of categorical features.
2024-05-04 15:14:28,131:INFO:Finished creating preprocessing pipeline.
2024-05-04 15:14:28,135:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-04 15:14:28,135:INFO:Creating final display dataframe.
2024-05-04 15:14:30,395:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target              Class
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape        (8000, 118)
5        Transformed data shape        (8000, 128)
6   Transformed train set shape        (5600, 128)
7    Transformed test set shape        (2400, 128)
8          Categorical features                117
9      Rows with missing values              35.1%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16               Fold Generator    StratifiedKFold
17                  Fold Number                 10
18                     CPU Jobs                 -1
19                      Use GPU              False
20               Log Experiment              False
21              Experiment Name   clf-default-name
22                          USI               8b4b
2024-05-04 15:14:30,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:30,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:30,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:30,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:14:30,461:INFO:setup() successfully completed in 5.62s...............
2024-05-04 15:14:38,360:INFO:Initializing compare_models()
2024-05-04 15:14:38,360:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-04 15:14:38,360:INFO:Checking exceptions
2024-05-04 15:14:38,370:INFO:Preparing display monitor
2024-05-04 15:14:38,418:INFO:Initializing Logistic Regression
2024-05-04 15:14:38,418:INFO:Total runtime is 4.553794860839844e-06 minutes
2024-05-04 15:14:38,419:INFO:SubProcess create_model() called ==================================
2024-05-04 15:14:38,420:INFO:Initializing create_model()
2024-05-04 15:14:38,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:14:38,420:INFO:Checking exceptions
2024-05-04 15:14:38,420:INFO:Importing libraries
2024-05-04 15:14:38,420:INFO:Copying training dataset
2024-05-04 15:14:38,430:INFO:Defining folds
2024-05-04 15:14:38,431:INFO:Declaring metric variables
2024-05-04 15:14:38,433:INFO:Importing untrained model
2024-05-04 15:14:38,434:INFO:Logistic Regression Imported successfully
2024-05-04 15:14:38,438:INFO:Starting cross validation
2024-05-04 15:14:38,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:14:42,362:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:42,367:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:42,600:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:42,602:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:42,827:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:42,830:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:42,839:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:42,842:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:43,108:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:43,111:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:43,176:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:43,179:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:43,347:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:43,349:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:43,450:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:43,453:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:44,166:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:44,168:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:44,321:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:44,323:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:44,337:INFO:Calculating mean and std
2024-05-04 15:14:44,339:INFO:Creating metrics dataframe
2024-05-04 15:14:44,342:INFO:Uploading results into container
2024-05-04 15:14:44,343:INFO:Uploading model into container now
2024-05-04 15:14:44,343:INFO:_master_model_container: 1
2024-05-04 15:14:44,343:INFO:_display_container: 2
2024-05-04 15:14:44,343:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-04 15:14:44,343:INFO:create_model() successfully completed......................................
2024-05-04 15:14:44,460:INFO:SubProcess create_model() end ==================================
2024-05-04 15:14:44,460:INFO:Creating metrics dataframe
2024-05-04 15:14:44,463:INFO:Initializing K Neighbors Classifier
2024-05-04 15:14:44,463:INFO:Total runtime is 0.10076638460159301 minutes
2024-05-04 15:14:44,465:INFO:SubProcess create_model() called ==================================
2024-05-04 15:14:44,465:INFO:Initializing create_model()
2024-05-04 15:14:44,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:14:44,465:INFO:Checking exceptions
2024-05-04 15:14:44,465:INFO:Importing libraries
2024-05-04 15:14:44,465:INFO:Copying training dataset
2024-05-04 15:14:44,479:INFO:Defining folds
2024-05-04 15:14:44,479:INFO:Declaring metric variables
2024-05-04 15:14:44,481:INFO:Importing untrained model
2024-05-04 15:14:44,483:INFO:K Neighbors Classifier Imported successfully
2024-05-04 15:14:44,485:INFO:Starting cross validation
2024-05-04 15:14:44,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:14:46,319:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:46,517:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:46,556:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:46,725:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:46,797:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:46,934:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:47,025:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:47,177:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:47,806:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:47,989:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:47,994:INFO:Calculating mean and std
2024-05-04 15:14:47,994:INFO:Creating metrics dataframe
2024-05-04 15:14:47,995:INFO:Uploading results into container
2024-05-04 15:14:47,995:INFO:Uploading model into container now
2024-05-04 15:14:47,996:INFO:_master_model_container: 2
2024-05-04 15:14:47,996:INFO:_display_container: 2
2024-05-04 15:14:47,996:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-04 15:14:47,996:INFO:create_model() successfully completed......................................
2024-05-04 15:14:48,071:INFO:SubProcess create_model() end ==================================
2024-05-04 15:14:48,071:INFO:Creating metrics dataframe
2024-05-04 15:14:48,075:INFO:Initializing Naive Bayes
2024-05-04 15:14:48,075:INFO:Total runtime is 0.16095395088195802 minutes
2024-05-04 15:14:48,076:INFO:SubProcess create_model() called ==================================
2024-05-04 15:14:48,076:INFO:Initializing create_model()
2024-05-04 15:14:48,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:14:48,076:INFO:Checking exceptions
2024-05-04 15:14:48,076:INFO:Importing libraries
2024-05-04 15:14:48,076:INFO:Copying training dataset
2024-05-04 15:14:48,086:INFO:Defining folds
2024-05-04 15:14:48,087:INFO:Declaring metric variables
2024-05-04 15:14:48,088:INFO:Importing untrained model
2024-05-04 15:14:48,090:INFO:Naive Bayes Imported successfully
2024-05-04 15:14:48,094:INFO:Starting cross validation
2024-05-04 15:14:48,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:14:49,862:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:50,072:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:50,078:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:50,257:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:50,275:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:50,401:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:50,523:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:50,729:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:51,331:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:51,463:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:51,477:INFO:Calculating mean and std
2024-05-04 15:14:51,477:INFO:Creating metrics dataframe
2024-05-04 15:14:51,478:INFO:Uploading results into container
2024-05-04 15:14:51,478:INFO:Uploading model into container now
2024-05-04 15:14:51,479:INFO:_master_model_container: 3
2024-05-04 15:14:51,479:INFO:_display_container: 2
2024-05-04 15:14:51,479:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-04 15:14:51,479:INFO:create_model() successfully completed......................................
2024-05-04 15:14:51,554:INFO:SubProcess create_model() end ==================================
2024-05-04 15:14:51,554:INFO:Creating metrics dataframe
2024-05-04 15:14:51,557:INFO:Initializing Decision Tree Classifier
2024-05-04 15:14:51,557:INFO:Total runtime is 0.21899574995040894 minutes
2024-05-04 15:14:51,558:INFO:SubProcess create_model() called ==================================
2024-05-04 15:14:51,559:INFO:Initializing create_model()
2024-05-04 15:14:51,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:14:51,559:INFO:Checking exceptions
2024-05-04 15:14:51,559:INFO:Importing libraries
2024-05-04 15:14:51,559:INFO:Copying training dataset
2024-05-04 15:14:51,567:INFO:Defining folds
2024-05-04 15:14:51,567:INFO:Declaring metric variables
2024-05-04 15:14:51,568:INFO:Importing untrained model
2024-05-04 15:14:51,570:INFO:Decision Tree Classifier Imported successfully
2024-05-04 15:14:51,572:INFO:Starting cross validation
2024-05-04 15:14:51,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:14:53,495:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:53,526:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:53,599:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:53,668:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:53,754:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:53,836:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:54,051:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:54,181:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:54,930:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:55,022:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:55,025:INFO:Calculating mean and std
2024-05-04 15:14:55,026:INFO:Creating metrics dataframe
2024-05-04 15:14:55,027:INFO:Uploading results into container
2024-05-04 15:14:55,027:INFO:Uploading model into container now
2024-05-04 15:14:55,027:INFO:_master_model_container: 4
2024-05-04 15:14:55,027:INFO:_display_container: 2
2024-05-04 15:14:55,028:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-05-04 15:14:55,028:INFO:create_model() successfully completed......................................
2024-05-04 15:14:55,103:INFO:SubProcess create_model() end ==================================
2024-05-04 15:14:55,103:INFO:Creating metrics dataframe
2024-05-04 15:14:55,106:INFO:Initializing SVM - Linear Kernel
2024-05-04 15:14:55,106:INFO:Total runtime is 0.27814838488896687 minutes
2024-05-04 15:14:55,108:INFO:SubProcess create_model() called ==================================
2024-05-04 15:14:55,108:INFO:Initializing create_model()
2024-05-04 15:14:55,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:14:55,108:INFO:Checking exceptions
2024-05-04 15:14:55,108:INFO:Importing libraries
2024-05-04 15:14:55,108:INFO:Copying training dataset
2024-05-04 15:14:55,116:INFO:Defining folds
2024-05-04 15:14:55,116:INFO:Declaring metric variables
2024-05-04 15:14:55,117:INFO:Importing untrained model
2024-05-04 15:14:55,119:INFO:SVM - Linear Kernel Imported successfully
2024-05-04 15:14:55,121:INFO:Starting cross validation
2024-05-04 15:14:55,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:14:57,106:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:57,108:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:57,421:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:57,423:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:57,588:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:57,590:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:57,604:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:57,611:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:57,615:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:57,617:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:57,733:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:57,735:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:57,911:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:57,913:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:58,052:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:58,054:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:58,756:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:58,757:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:58,955:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:14:58,956:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:14:58,970:INFO:Calculating mean and std
2024-05-04 15:14:58,971:INFO:Creating metrics dataframe
2024-05-04 15:14:58,972:INFO:Uploading results into container
2024-05-04 15:14:58,972:INFO:Uploading model into container now
2024-05-04 15:14:58,972:INFO:_master_model_container: 5
2024-05-04 15:14:58,972:INFO:_display_container: 2
2024-05-04 15:14:58,972:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-04 15:14:58,973:INFO:create_model() successfully completed......................................
2024-05-04 15:14:59,048:INFO:SubProcess create_model() end ==================================
2024-05-04 15:14:59,048:INFO:Creating metrics dataframe
2024-05-04 15:14:59,051:INFO:Initializing Ridge Classifier
2024-05-04 15:14:59,051:INFO:Total runtime is 0.3438970367113749 minutes
2024-05-04 15:14:59,053:INFO:SubProcess create_model() called ==================================
2024-05-04 15:14:59,053:INFO:Initializing create_model()
2024-05-04 15:14:59,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:14:59,053:INFO:Checking exceptions
2024-05-04 15:14:59,053:INFO:Importing libraries
2024-05-04 15:14:59,053:INFO:Copying training dataset
2024-05-04 15:14:59,062:INFO:Defining folds
2024-05-04 15:14:59,062:INFO:Declaring metric variables
2024-05-04 15:14:59,063:INFO:Importing untrained model
2024-05-04 15:14:59,065:INFO:Ridge Classifier Imported successfully
2024-05-04 15:14:59,067:INFO:Starting cross validation
2024-05-04 15:14:59,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:00,804:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:00,807:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:01,100:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:01,101:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:01,193:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:01,195:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:01,312:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:01,314:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:01,449:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:01,450:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:01,474:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:01,476:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:01,655:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:01,657:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:01,760:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:01,762:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:02,367:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:02,369:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:02,588:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:02,590:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:02,598:INFO:Calculating mean and std
2024-05-04 15:15:02,598:INFO:Creating metrics dataframe
2024-05-04 15:15:02,600:INFO:Uploading results into container
2024-05-04 15:15:02,600:INFO:Uploading model into container now
2024-05-04 15:15:02,600:INFO:_master_model_container: 6
2024-05-04 15:15:02,600:INFO:_display_container: 2
2024-05-04 15:15:02,600:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-05-04 15:15:02,600:INFO:create_model() successfully completed......................................
2024-05-04 15:15:02,675:INFO:SubProcess create_model() end ==================================
2024-05-04 15:15:02,675:INFO:Creating metrics dataframe
2024-05-04 15:15:02,679:INFO:Initializing Random Forest Classifier
2024-05-04 15:15:02,679:INFO:Total runtime is 0.40435228745142615 minutes
2024-05-04 15:15:02,680:INFO:SubProcess create_model() called ==================================
2024-05-04 15:15:02,680:INFO:Initializing create_model()
2024-05-04 15:15:02,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:02,680:INFO:Checking exceptions
2024-05-04 15:15:02,680:INFO:Importing libraries
2024-05-04 15:15:02,680:INFO:Copying training dataset
2024-05-04 15:15:02,689:INFO:Defining folds
2024-05-04 15:15:02,689:INFO:Declaring metric variables
2024-05-04 15:15:02,690:INFO:Importing untrained model
2024-05-04 15:15:02,691:INFO:Random Forest Classifier Imported successfully
2024-05-04 15:15:02,694:INFO:Starting cross validation
2024-05-04 15:15:02,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:04,895:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:04,921:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:05,122:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:05,180:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:05,191:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:05,235:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:05,316:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:05,451:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:06,405:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:06,528:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:06,543:INFO:Calculating mean and std
2024-05-04 15:15:06,543:INFO:Creating metrics dataframe
2024-05-04 15:15:06,544:INFO:Uploading results into container
2024-05-04 15:15:06,545:INFO:Uploading model into container now
2024-05-04 15:15:06,545:INFO:_master_model_container: 7
2024-05-04 15:15:06,545:INFO:_display_container: 2
2024-05-04 15:15:06,545:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-05-04 15:15:06,545:INFO:create_model() successfully completed......................................
2024-05-04 15:15:06,620:INFO:SubProcess create_model() end ==================================
2024-05-04 15:15:06,620:INFO:Creating metrics dataframe
2024-05-04 15:15:06,624:INFO:Initializing Quadratic Discriminant Analysis
2024-05-04 15:15:06,624:INFO:Total runtime is 0.4701072335243225 minutes
2024-05-04 15:15:06,625:INFO:SubProcess create_model() called ==================================
2024-05-04 15:15:06,625:INFO:Initializing create_model()
2024-05-04 15:15:06,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:06,625:INFO:Checking exceptions
2024-05-04 15:15:06,625:INFO:Importing libraries
2024-05-04 15:15:06,625:INFO:Copying training dataset
2024-05-04 15:15:06,634:INFO:Defining folds
2024-05-04 15:15:06,634:INFO:Declaring metric variables
2024-05-04 15:15:06,636:INFO:Importing untrained model
2024-05-04 15:15:06,637:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-04 15:15:06,639:INFO:Starting cross validation
2024-05-04 15:15:06,643:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:08,327:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:08,441:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:08,553:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:08,557:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:08,667:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:08,723:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:08,727:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:08,846:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:08,877:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:08,879:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:08,930:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:09,027:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:09,030:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:09,111:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:09,128:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:09,130:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:09,222:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:09,291:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:09,375:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:09,377:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:09,419:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:09,580:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:09,582:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:10,152:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:10,298:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:10,300:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:10,445:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:15:10,578:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:10,592:INFO:Calculating mean and std
2024-05-04 15:15:10,593:INFO:Creating metrics dataframe
2024-05-04 15:15:10,594:INFO:Uploading results into container
2024-05-04 15:15:10,594:INFO:Uploading model into container now
2024-05-04 15:15:10,594:INFO:_master_model_container: 8
2024-05-04 15:15:10,594:INFO:_display_container: 2
2024-05-04 15:15:10,595:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-04 15:15:10,595:INFO:create_model() successfully completed......................................
2024-05-04 15:15:10,670:INFO:SubProcess create_model() end ==================================
2024-05-04 15:15:10,670:INFO:Creating metrics dataframe
2024-05-04 15:15:10,674:INFO:Initializing Ada Boost Classifier
2024-05-04 15:15:10,674:INFO:Total runtime is 0.5376104672749837 minutes
2024-05-04 15:15:10,675:INFO:SubProcess create_model() called ==================================
2024-05-04 15:15:10,676:INFO:Initializing create_model()
2024-05-04 15:15:10,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:10,676:INFO:Checking exceptions
2024-05-04 15:15:10,676:INFO:Importing libraries
2024-05-04 15:15:10,676:INFO:Copying training dataset
2024-05-04 15:15:10,684:INFO:Defining folds
2024-05-04 15:15:10,684:INFO:Declaring metric variables
2024-05-04 15:15:10,685:INFO:Importing untrained model
2024-05-04 15:15:10,686:INFO:Ada Boost Classifier Imported successfully
2024-05-04 15:15:10,689:INFO:Starting cross validation
2024-05-04 15:15:10,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:12,327:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:12,579:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:12,617:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:12,811:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:12,848:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:12,902:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:12,911:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:13,063:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:13,110:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:13,112:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:13,165:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:13,167:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:13,203:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:13,320:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:13,329:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:13,334:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:13,336:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:13,354:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:13,528:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:13,530:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:13,624:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:13,626:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:13,792:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:13,798:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:14,430:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:14,536:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:15:14,807:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:14,809:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:14,904:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:14,905:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:14,921:INFO:Calculating mean and std
2024-05-04 15:15:14,921:INFO:Creating metrics dataframe
2024-05-04 15:15:14,923:INFO:Uploading results into container
2024-05-04 15:15:14,923:INFO:Uploading model into container now
2024-05-04 15:15:14,923:INFO:_master_model_container: 9
2024-05-04 15:15:14,923:INFO:_display_container: 2
2024-05-04 15:15:14,923:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-05-04 15:15:14,923:INFO:create_model() successfully completed......................................
2024-05-04 15:15:15,004:INFO:SubProcess create_model() end ==================================
2024-05-04 15:15:15,004:INFO:Creating metrics dataframe
2024-05-04 15:15:15,008:INFO:Initializing Gradient Boosting Classifier
2024-05-04 15:15:15,008:INFO:Total runtime is 0.6098497827847799 minutes
2024-05-04 15:15:15,010:INFO:SubProcess create_model() called ==================================
2024-05-04 15:15:15,010:INFO:Initializing create_model()
2024-05-04 15:15:15,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:15,010:INFO:Checking exceptions
2024-05-04 15:15:15,010:INFO:Importing libraries
2024-05-04 15:15:15,010:INFO:Copying training dataset
2024-05-04 15:15:15,018:INFO:Defining folds
2024-05-04 15:15:15,018:INFO:Declaring metric variables
2024-05-04 15:15:15,019:INFO:Importing untrained model
2024-05-04 15:15:15,020:INFO:Gradient Boosting Classifier Imported successfully
2024-05-04 15:15:15,023:INFO:Starting cross validation
2024-05-04 15:15:15,027:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:18,874:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:18,877:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:19,000:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:19,002:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:19,020:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:19,022:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:19,174:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:19,176:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:19,266:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:19,267:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:19,332:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:19,334:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:19,458:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:19,459:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:19,578:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:19,580:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:21,844:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:21,846:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:21,868:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:21,870:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:21,885:INFO:Calculating mean and std
2024-05-04 15:15:21,885:INFO:Creating metrics dataframe
2024-05-04 15:15:21,886:INFO:Uploading results into container
2024-05-04 15:15:21,887:INFO:Uploading model into container now
2024-05-04 15:15:21,887:INFO:_master_model_container: 10
2024-05-04 15:15:21,887:INFO:_display_container: 2
2024-05-04 15:15:21,887:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-04 15:15:21,887:INFO:create_model() successfully completed......................................
2024-05-04 15:15:21,962:INFO:SubProcess create_model() end ==================================
2024-05-04 15:15:21,962:INFO:Creating metrics dataframe
2024-05-04 15:15:21,967:INFO:Initializing Linear Discriminant Analysis
2024-05-04 15:15:21,967:INFO:Total runtime is 0.7258270661036174 minutes
2024-05-04 15:15:21,969:INFO:SubProcess create_model() called ==================================
2024-05-04 15:15:21,969:INFO:Initializing create_model()
2024-05-04 15:15:21,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:21,969:INFO:Checking exceptions
2024-05-04 15:15:21,969:INFO:Importing libraries
2024-05-04 15:15:21,969:INFO:Copying training dataset
2024-05-04 15:15:21,977:INFO:Defining folds
2024-05-04 15:15:21,977:INFO:Declaring metric variables
2024-05-04 15:15:21,979:INFO:Importing untrained model
2024-05-04 15:15:21,980:INFO:Linear Discriminant Analysis Imported successfully
2024-05-04 15:15:21,983:INFO:Starting cross validation
2024-05-04 15:15:21,987:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:23,874:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:23,876:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:23,924:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:23,926:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:24,120:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:24,121:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:24,347:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:24,349:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:24,377:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:24,379:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:24,403:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:24,405:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:24,566:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:24,568:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:24,699:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:24,701:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:25,427:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:25,428:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:25,525:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:15:25,527:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:25,538:INFO:Calculating mean and std
2024-05-04 15:15:25,539:INFO:Creating metrics dataframe
2024-05-04 15:15:25,540:INFO:Uploading results into container
2024-05-04 15:15:25,540:INFO:Uploading model into container now
2024-05-04 15:15:25,540:INFO:_master_model_container: 11
2024-05-04 15:15:25,540:INFO:_display_container: 2
2024-05-04 15:15:25,540:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-04 15:15:25,540:INFO:create_model() successfully completed......................................
2024-05-04 15:15:25,616:INFO:SubProcess create_model() end ==================================
2024-05-04 15:15:25,616:INFO:Creating metrics dataframe
2024-05-04 15:15:25,620:INFO:Initializing Extra Trees Classifier
2024-05-04 15:15:25,620:INFO:Total runtime is 0.7867132504781087 minutes
2024-05-04 15:15:25,622:INFO:SubProcess create_model() called ==================================
2024-05-04 15:15:25,622:INFO:Initializing create_model()
2024-05-04 15:15:25,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:25,622:INFO:Checking exceptions
2024-05-04 15:15:25,622:INFO:Importing libraries
2024-05-04 15:15:25,622:INFO:Copying training dataset
2024-05-04 15:15:25,630:INFO:Defining folds
2024-05-04 15:15:25,630:INFO:Declaring metric variables
2024-05-04 15:15:25,632:INFO:Importing untrained model
2024-05-04 15:15:25,633:INFO:Extra Trees Classifier Imported successfully
2024-05-04 15:15:25,635:INFO:Starting cross validation
2024-05-04 15:15:25,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:27,743:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:27,808:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:27,845:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:27,937:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:28,028:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:28,094:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:28,311:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:28,442:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:29,277:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:29,351:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:29,358:INFO:Calculating mean and std
2024-05-04 15:15:29,359:INFO:Creating metrics dataframe
2024-05-04 15:15:29,360:INFO:Uploading results into container
2024-05-04 15:15:29,360:INFO:Uploading model into container now
2024-05-04 15:15:29,361:INFO:_master_model_container: 12
2024-05-04 15:15:29,361:INFO:_display_container: 2
2024-05-04 15:15:29,361:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-05-04 15:15:29,361:INFO:create_model() successfully completed......................................
2024-05-04 15:15:29,436:INFO:SubProcess create_model() end ==================================
2024-05-04 15:15:29,436:INFO:Creating metrics dataframe
2024-05-04 15:15:29,441:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 15:15:29,441:INFO:Total runtime is 0.8503865003585815 minutes
2024-05-04 15:15:29,442:INFO:SubProcess create_model() called ==================================
2024-05-04 15:15:29,442:INFO:Initializing create_model()
2024-05-04 15:15:29,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:29,442:INFO:Checking exceptions
2024-05-04 15:15:29,442:INFO:Importing libraries
2024-05-04 15:15:29,442:INFO:Copying training dataset
2024-05-04 15:15:29,451:INFO:Defining folds
2024-05-04 15:15:29,451:INFO:Declaring metric variables
2024-05-04 15:15:29,452:INFO:Importing untrained model
2024-05-04 15:15:29,453:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:15:29,456:INFO:Starting cross validation
2024-05-04 15:15:29,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:31,663:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 15:15:31,669:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 15:15:31,669:INFO:Initializing create_model()
2024-05-04 15:15:31,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:31,669:INFO:Checking exceptions
2024-05-04 15:15:31,669:INFO:Importing libraries
2024-05-04 15:15:31,669:INFO:Copying training dataset
2024-05-04 15:15:31,677:INFO:Defining folds
2024-05-04 15:15:31,677:INFO:Declaring metric variables
2024-05-04 15:15:31,679:INFO:Importing untrained model
2024-05-04 15:15:31,681:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:15:31,683:INFO:Starting cross validation
2024-05-04 15:15:31,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:36,217:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 15:15:36,218:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 15:15:36,218:INFO:Initializing Dummy Classifier
2024-05-04 15:15:36,218:INFO:Total runtime is 0.963347049554189 minutes
2024-05-04 15:15:36,221:INFO:SubProcess create_model() called ==================================
2024-05-04 15:15:36,221:INFO:Initializing create_model()
2024-05-04 15:15:36,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31585f190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:36,221:INFO:Checking exceptions
2024-05-04 15:15:36,221:INFO:Importing libraries
2024-05-04 15:15:36,221:INFO:Copying training dataset
2024-05-04 15:15:36,231:INFO:Defining folds
2024-05-04 15:15:36,231:INFO:Declaring metric variables
2024-05-04 15:15:36,232:INFO:Importing untrained model
2024-05-04 15:15:36,233:INFO:Dummy Classifier Imported successfully
2024-05-04 15:15:36,236:INFO:Starting cross validation
2024-05-04 15:15:36,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:15:39,702:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:39,843:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:39,854:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:40,017:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:40,179:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:40,203:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:40,288:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:40,401:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:41,315:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:41,343:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:15:41,352:INFO:Calculating mean and std
2024-05-04 15:15:41,353:INFO:Creating metrics dataframe
2024-05-04 15:15:41,356:INFO:Uploading results into container
2024-05-04 15:15:41,356:INFO:Uploading model into container now
2024-05-04 15:15:41,356:INFO:_master_model_container: 13
2024-05-04 15:15:41,356:INFO:_display_container: 2
2024-05-04 15:15:41,356:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-05-04 15:15:41,356:INFO:create_model() successfully completed......................................
2024-05-04 15:15:41,445:INFO:SubProcess create_model() end ==================================
2024-05-04 15:15:41,445:INFO:Creating metrics dataframe
2024-05-04 15:15:41,450:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 15:15:41,453:INFO:Initializing create_model()
2024-05-04 15:15:41,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:15:41,453:INFO:Checking exceptions
2024-05-04 15:15:41,454:INFO:Importing libraries
2024-05-04 15:15:41,454:INFO:Copying training dataset
2024-05-04 15:15:41,463:INFO:Defining folds
2024-05-04 15:15:41,463:INFO:Declaring metric variables
2024-05-04 15:15:41,463:INFO:Importing untrained model
2024-05-04 15:15:41,463:INFO:Declaring custom model
2024-05-04 15:15:41,463:INFO:Ridge Classifier Imported successfully
2024-05-04 15:15:41,467:INFO:Cross validation set to False
2024-05-04 15:15:41,467:INFO:Fitting Model
2024-05-04 15:15:42,652:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-05-04 15:15:42,652:INFO:create_model() successfully completed......................................
2024-05-04 15:15:42,768:INFO:_master_model_container: 13
2024-05-04 15:15:42,768:INFO:_display_container: 2
2024-05-04 15:15:42,768:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-05-04 15:15:42,771:INFO:compare_models() successfully completed......................................
2024-05-04 15:16:01,722:INFO:Initializing plot_model()
2024-05-04 15:16:01,723:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 15:16:01,723:INFO:Checking exceptions
2024-05-04 15:16:01,730:INFO:Preloading libraries
2024-05-04 15:16:01,730:INFO:Copying training dataset
2024-05-04 15:16:01,730:INFO:Plot type: confusion_matrix
2024-05-04 15:16:04,088:INFO:Fitting Model
2024-05-04 15:16:04,092:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-05-04 15:16:04,092:INFO:Scoring test/hold-out set
2024-05-04 15:16:04,152:INFO:Visual Rendered Successfully
2024-05-04 15:16:04,232:INFO:plot_model() successfully completed......................................
2024-05-04 15:16:15,244:INFO:Initializing plot_model()
2024-05-04 15:16:15,244:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 15:16:15,245:INFO:Checking exceptions
2024-05-04 15:16:24,153:INFO:Initializing plot_model()
2024-05-04 15:16:24,153:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 15:16:24,153:INFO:Checking exceptions
2024-05-04 15:16:24,162:INFO:Preloading libraries
2024-05-04 15:16:24,163:INFO:Copying training dataset
2024-05-04 15:16:24,163:INFO:Plot type: confusion_matrix
2024-05-04 15:16:26,610:INFO:Fitting Model
2024-05-04 15:16:26,611:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-05-04 15:16:26,611:INFO:Scoring test/hold-out set
2024-05-04 15:16:26,665:INFO:Visual Rendered Successfully
2024-05-04 15:16:26,760:INFO:plot_model() successfully completed......................................
2024-05-04 15:17:02,196:INFO:Initializing plot_model()
2024-05-04 15:17:02,197:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 15:17:02,197:INFO:Checking exceptions
2024-05-04 15:17:07,335:INFO:Initializing plot_model()
2024-05-04 15:17:07,336:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=aoc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 15:17:07,336:INFO:Checking exceptions
2024-05-04 15:17:13,102:INFO:Initializing plot_model()
2024-05-04 15:17:13,102:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=acc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 15:17:13,102:INFO:Checking exceptions
2024-05-04 15:17:35,778:INFO:Initializing plot_model()
2024-05-04 15:17:35,779:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 15:17:35,779:INFO:Checking exceptions
2024-05-04 15:17:38,006:INFO:Initializing plot_model()
2024-05-04 15:17:38,006:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 15:17:38,006:INFO:Checking exceptions
2024-05-04 15:17:38,012:INFO:Preloading libraries
2024-05-04 15:17:38,013:INFO:Copying training dataset
2024-05-04 15:17:38,013:INFO:Plot type: feature
2024-05-04 15:17:39,813:INFO:Visual Rendered Successfully
2024-05-04 15:17:39,907:INFO:plot_model() successfully completed......................................
2024-05-04 15:22:13,131:INFO:Initializing evaluate_model()
2024-05-04 15:22:13,131:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-04 15:22:13,147:INFO:Initializing plot_model()
2024-05-04 15:22:13,147:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:13,147:INFO:Checking exceptions
2024-05-04 15:22:13,150:INFO:Preloading libraries
2024-05-04 15:22:13,151:INFO:Copying training dataset
2024-05-04 15:22:13,151:INFO:Plot type: pipeline
2024-05-04 15:22:13,229:INFO:Visual Rendered Successfully
2024-05-04 15:22:13,337:INFO:plot_model() successfully completed......................................
2024-05-04 15:22:20,267:INFO:Initializing plot_model()
2024-05-04 15:22:20,268:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:20,268:INFO:Checking exceptions
2024-05-04 15:22:20,276:INFO:Preloading libraries
2024-05-04 15:22:20,277:INFO:Copying training dataset
2024-05-04 15:22:20,277:INFO:Plot type: parameter
2024-05-04 15:22:20,280:INFO:Visual Rendered Successfully
2024-05-04 15:22:20,376:INFO:plot_model() successfully completed......................................
2024-05-04 15:22:22,645:INFO:Initializing plot_model()
2024-05-04 15:22:22,646:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:22,646:INFO:Checking exceptions
2024-05-04 15:22:24,057:INFO:Initializing plot_model()
2024-05-04 15:22:24,058:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:24,058:INFO:Checking exceptions
2024-05-04 15:22:24,066:INFO:Preloading libraries
2024-05-04 15:22:24,066:INFO:Copying training dataset
2024-05-04 15:22:24,066:INFO:Plot type: confusion_matrix
2024-05-04 15:22:26,363:INFO:Fitting Model
2024-05-04 15:22:26,363:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-05-04 15:22:26,363:INFO:Scoring test/hold-out set
2024-05-04 15:22:26,415:INFO:Visual Rendered Successfully
2024-05-04 15:22:26,511:INFO:plot_model() successfully completed......................................
2024-05-04 15:22:26,519:INFO:Initializing plot_model()
2024-05-04 15:22:26,519:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=error, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:26,519:INFO:Checking exceptions
2024-05-04 15:22:26,525:INFO:Preloading libraries
2024-05-04 15:22:26,525:INFO:Copying training dataset
2024-05-04 15:22:26,525:INFO:Plot type: error
2024-05-04 15:22:28,790:INFO:Fitting Model
2024-05-04 15:22:28,790:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-05-04 15:22:28,790:INFO:Scoring test/hold-out set
2024-05-04 15:22:28,866:INFO:Visual Rendered Successfully
2024-05-04 15:22:28,961:INFO:plot_model() successfully completed......................................
2024-05-04 15:22:29,304:INFO:Initializing plot_model()
2024-05-04 15:22:29,304:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:29,304:INFO:Checking exceptions
2024-05-04 15:22:29,311:INFO:Preloading libraries
2024-05-04 15:22:29,311:INFO:Copying training dataset
2024-05-04 15:22:29,311:INFO:Plot type: confusion_matrix
2024-05-04 15:22:31,534:INFO:Fitting Model
2024-05-04 15:22:31,534:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-05-04 15:22:31,534:INFO:Scoring test/hold-out set
2024-05-04 15:22:31,588:INFO:Visual Rendered Successfully
2024-05-04 15:22:31,683:INFO:plot_model() successfully completed......................................
2024-05-04 15:22:32,923:INFO:Initializing plot_model()
2024-05-04 15:22:32,923:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=threshold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:32,924:INFO:Checking exceptions
2024-05-04 15:22:35,027:INFO:Initializing plot_model()
2024-05-04 15:22:35,028:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:35,028:INFO:Checking exceptions
2024-05-04 15:22:35,036:INFO:Preloading libraries
2024-05-04 15:22:35,037:INFO:Copying training dataset
2024-05-04 15:22:35,037:INFO:Plot type: pr
2024-05-04 15:22:37,222:INFO:Fitting Model
2024-05-04 15:22:37,371:INFO:Scoring test/hold-out set
2024-05-04 15:22:37,480:INFO:Visual Rendered Successfully
2024-05-04 15:22:37,589:INFO:plot_model() successfully completed......................................
2024-05-04 15:22:41,683:INFO:Initializing plot_model()
2024-05-04 15:22:41,684:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:41,684:INFO:Checking exceptions
2024-05-04 15:22:43,517:INFO:Initializing plot_model()
2024-05-04 15:22:43,518:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 15:22:43,518:INFO:Checking exceptions
2024-05-04 15:22:43,526:INFO:Preloading libraries
2024-05-04 15:22:43,527:INFO:Copying training dataset
2024-05-04 15:22:43,527:INFO:Plot type: learning
2024-05-04 15:22:45,714:INFO:Fitting Model
2024-05-04 15:22:47,082:INFO:Visual Rendered Successfully
2024-05-04 15:22:47,185:INFO:plot_model() successfully completed......................................
2024-05-04 15:23:13,979:INFO:Initializing predict_model()
2024-05-04 15:23:13,980:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30a0d9950>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3161753a0>)
2024-05-04 15:23:13,980:INFO:Checking exceptions
2024-05-04 15:23:13,980:INFO:Preloading libraries
2024-05-04 15:23:15,167:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 15:23:15,170:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:24:18,131:INFO:Initializing save_model()
2024-05-04 15:24:18,132:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), model_name=my_first_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-04 15:24:18,132:INFO:Adding model into prep_pipe
2024-05-04 15:24:18,276:INFO:my_first_pipeline.pkl saved in current working directory
2024-05-04 15:24:18,280:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('...
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=123,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2024-05-04 15:24:18,280:INFO:save_model() successfully completed......................................
2024-05-04 15:24:22,748:INFO:Initializing load_model()
2024-05-04 15:24:22,748:INFO:load_model(model_name=my_first_pipeline, platform=None, authentication=None, verbose=True)
2024-05-04 15:24:44,078:INFO:PyCaret ClassificationExperiment
2024-05-04 15:24:44,078:INFO:Logging name: clf-default-name
2024-05-04 15:24:44,078:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:24:44,078:INFO:version 3.3.2
2024-05-04 15:24:44,078:INFO:Initializing setup()
2024-05-04 15:24:44,078:INFO:self.USI: c651
2024-05-04 15:24:44,078:INFO:self._variable_keys: {'target_param', 'y', 'y_test', 'logging_param', 'gpu_n_jobs_param', 'fix_imbalance', 'data', 'html_param', 'exp_name_log', 'memory', 'idx', 'pipeline', 'X', 'gpu_param', 'X_train', 'is_multiclass', 'n_jobs_param', 'X_test', 'USI', 'exp_id', 'log_plots_param', 'y_train', 'fold_groups_param', '_ml_usecase', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'seed'}
2024-05-04 15:24:44,078:INFO:Checking environment
2024-05-04 15:24:44,078:INFO:python_version: 3.11.8
2024-05-04 15:24:44,078:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:24:44,078:INFO:machine: arm64
2024-05-04 15:24:44,078:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:24:44,078:INFO:Memory: svmem(total=17179869184, available=5794856960, percent=66.3, used=7635419136, free=156958720, active=5637849088, inactive=5634244608, wired=1997570048)
2024-05-04 15:24:44,078:INFO:Physical Core: 8
2024-05-04 15:24:44,078:INFO:Logical Core: 8
2024-05-04 15:24:44,078:INFO:Checking libraries
2024-05-04 15:24:44,078:INFO:System:
2024-05-04 15:24:44,078:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:24:44,078:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:24:44,078:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:24:44,078:INFO:PyCaret required dependencies:
2024-05-04 15:24:44,079:INFO:                 pip: 24.0
2024-05-04 15:24:44,079:INFO:          setuptools: 69.2.0
2024-05-04 15:24:44,079:INFO:             pycaret: 3.3.2
2024-05-04 15:24:44,079:INFO:             IPython: 8.22.2
2024-05-04 15:24:44,079:INFO:          ipywidgets: 8.1.2
2024-05-04 15:24:44,079:INFO:                tqdm: 4.66.2
2024-05-04 15:24:44,079:INFO:               numpy: 1.26.4
2024-05-04 15:24:44,079:INFO:              pandas: 2.1.4
2024-05-04 15:24:44,079:INFO:              jinja2: 3.1.3
2024-05-04 15:24:44,079:INFO:               scipy: 1.11.4
2024-05-04 15:24:44,079:INFO:              joblib: 1.3.2
2024-05-04 15:24:44,079:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:24:44,079:INFO:                pyod: 1.1.3
2024-05-04 15:24:44,079:INFO:            imblearn: 0.12.2
2024-05-04 15:24:44,079:INFO:   category_encoders: 2.6.3
2024-05-04 15:24:44,079:INFO:            lightgbm: 4.3.0
2024-05-04 15:24:44,079:INFO:               numba: 0.59.1
2024-05-04 15:24:44,079:INFO:            requests: 2.31.0
2024-05-04 15:24:44,079:INFO:          matplotlib: 3.7.5
2024-05-04 15:24:44,079:INFO:          scikitplot: 0.3.7
2024-05-04 15:24:44,079:INFO:         yellowbrick: 1.5
2024-05-04 15:24:44,079:INFO:              plotly: 5.19.0
2024-05-04 15:24:44,079:INFO:    plotly-resampler: Not installed
2024-05-04 15:24:44,079:INFO:             kaleido: 0.2.1
2024-05-04 15:24:44,079:INFO:           schemdraw: 0.15
2024-05-04 15:24:44,079:INFO:         statsmodels: 0.14.1
2024-05-04 15:24:44,079:INFO:              sktime: 0.26.0
2024-05-04 15:24:44,079:INFO:               tbats: 1.1.3
2024-05-04 15:24:44,079:INFO:            pmdarima: 2.0.4
2024-05-04 15:24:44,079:INFO:              psutil: 5.9.8
2024-05-04 15:24:44,079:INFO:          markupsafe: 2.1.5
2024-05-04 15:24:44,079:INFO:             pickle5: Not installed
2024-05-04 15:24:44,079:INFO:         cloudpickle: 3.0.0
2024-05-04 15:24:44,079:INFO:         deprecation: 2.1.0
2024-05-04 15:24:44,079:INFO:              xxhash: 3.4.1
2024-05-04 15:24:44,079:INFO:           wurlitzer: 3.0.3
2024-05-04 15:24:44,079:INFO:PyCaret optional dependencies:
2024-05-04 15:24:44,079:INFO:                shap: 0.44.1
2024-05-04 15:24:44,079:INFO:           interpret: 0.6.1
2024-05-04 15:24:44,079:INFO:                umap: 0.5.6
2024-05-04 15:24:44,079:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:24:44,079:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:24:44,079:INFO:             autoviz: Not installed
2024-05-04 15:24:44,079:INFO:           fairlearn: 0.7.0
2024-05-04 15:24:44,079:INFO:          deepchecks: Not installed
2024-05-04 15:24:44,079:INFO:             xgboost: Not installed
2024-05-04 15:24:44,079:INFO:            catboost: Not installed
2024-05-04 15:24:44,079:INFO:              kmodes: Not installed
2024-05-04 15:24:44,079:INFO:             mlxtend: 0.23.1
2024-05-04 15:24:44,079:INFO:       statsforecast: Not installed
2024-05-04 15:24:44,079:INFO:        tune_sklearn: Not installed
2024-05-04 15:24:44,079:INFO:                 ray: Not installed
2024-05-04 15:24:44,079:INFO:            hyperopt: Not installed
2024-05-04 15:24:44,079:INFO:              optuna: Not installed
2024-05-04 15:24:44,079:INFO:               skopt: Not installed
2024-05-04 15:24:44,079:INFO:              mlflow: 2.12.1
2024-05-04 15:24:44,079:INFO:              gradio: 4.29.0
2024-05-04 15:24:44,079:INFO:             fastapi: 0.111.0
2024-05-04 15:24:44,079:INFO:             uvicorn: 0.29.0
2024-05-04 15:24:44,079:INFO:              m2cgen: 0.10.0
2024-05-04 15:24:44,079:INFO:           evidently: 0.4.20
2024-05-04 15:24:44,079:INFO:               fugue: 0.8.7
2024-05-04 15:24:44,080:INFO:           streamlit: 1.33.0
2024-05-04 15:24:44,080:INFO:             prophet: Not installed
2024-05-04 15:24:44,080:INFO:None
2024-05-04 15:24:44,080:INFO:Set up data.
2024-05-04 15:24:44,535:INFO:Set up folding strategy.
2024-05-04 15:24:44,536:INFO:Set up train/test split.
2024-05-04 15:24:44,704:INFO:Set up index.
2024-05-04 15:24:44,705:INFO:Assigning column types.
2024-05-04 15:24:44,709:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 15:24:44,728:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:24:44,728:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:24:44,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,758:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:24:44,758:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:24:44,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,770:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 15:24:44,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:24:44,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,820:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:24:44,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,831:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-04 15:24:44,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:44,892:INFO:Preparing preprocessing pipeline...
2024-05-04 15:24:44,893:INFO:Set up label encoding.
2024-05-04 15:24:44,894:INFO:Set up simple imputation.
2024-05-04 15:24:44,903:INFO:Set up encoding of categorical features.
2024-05-04 15:24:47,193:INFO:Finished creating preprocessing pipeline.
2024-05-04 15:24:47,197:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-04 15:24:47,197:INFO:Creating final display dataframe.
2024-05-04 15:24:49,677:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target              Class
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape        (8000, 118)
5        Transformed data shape        (8000, 128)
6   Transformed train set shape        (5600, 128)
7    Transformed test set shape        (2400, 128)
8          Categorical features                117
9      Rows with missing values              35.1%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16               Fold Generator    StratifiedKFold
17                  Fold Number                 10
18                     CPU Jobs                 -1
19                      Use GPU              False
20               Log Experiment              False
21              Experiment Name   clf-default-name
22                          USI               c651
2024-05-04 15:24:49,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:49,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:49,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:49,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:24:49,748:INFO:setup() successfully completed in 5.67s...............
2024-05-04 15:24:53,492:INFO:Initializing get_config()
2024-05-04 15:24:53,492:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326624950>, variable=None)
2024-05-04 15:24:57,949:INFO:Initializing get_config()
2024-05-04 15:24:57,950:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326624950>, variable=X_train_transformed)
2024-05-04 15:24:58,572:INFO:Variable: X_train returned as       Group_G1  Group_G9  Group_G8  Group_G2  Group_G4  Group_G5  Group_G11  \
3269       1.0       0.0       0.0       0.0       0.0       0.0        0.0   
183        0.0       1.0       0.0       0.0       0.0       0.0        0.0   
6101       0.0       0.0       1.0       0.0       0.0       0.0        0.0   
7683       0.0       0.0       0.0       1.0       0.0       0.0        0.0   
5729       0.0       0.0       1.0       0.0       0.0       0.0        0.0   
...        ...       ...       ...       ...       ...       ...        ...   
5437       0.0       0.0       0.0       0.0       1.0       0.0        0.0   
3127       0.0       1.0       0.0       0.0       0.0       0.0        0.0   
2312       0.0       0.0       0.0       0.0       0.0       1.0        0.0   
7463       0.0       0.0       0.0       1.0       0.0       0.0        0.0   
7601       0.0       0.0       0.0       0.0       0.0       0.0        1.0   

      Group_G7  Group_G3  Group_G6  ...      dI49      dI50      dI51  \
3269       0.0       0.0       0.0  ...  1.000000  1.111312  1.005450   
183        0.0       0.0       0.0  ...  0.943056  0.943056  0.943056   
6101       0.0       0.0       0.0  ...  1.203273  1.203273  1.203273   
7683       0.0       0.0       0.0  ...  0.943056  0.930325  1.122604   
5729       0.0       0.0       0.0  ...  0.943056  0.943056  1.072176   
...        ...       ...       ...  ...       ...       ...       ...   
5437       0.0       0.0       0.0  ...  1.073164  1.073164  1.073164   
3127       0.0       0.0       0.0  ...  0.943056  1.111312  0.943056   
2312       0.0       0.0       0.0  ...  1.203273  1.203273  1.203273   
7463       0.0       0.0       0.0  ...  0.943056  0.943056  0.943056   
7601       0.0       0.0       0.0  ...  0.943056  0.943056  0.985988   

          dI52      dI53      dI54      dI55      dI56      dI57      dI58  
3269  0.994550  1.073164  1.073164  1.073164  1.073164  1.073164  0.846995  
183   0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  
6101  1.203273  1.203273  1.203273  1.203273  1.203273  1.203273  1.203273  
7683  0.930325  0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  
5729  0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  
...        ...       ...       ...       ...       ...       ...       ...  
5437  1.073164  1.073164  1.073164  1.073164  1.073164  1.073164  1.073164  
3127  0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  
2312  1.203273  1.203273  1.203273  1.203273  1.203273  1.203273  1.203273  
7463  0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  0.846995  
7601  0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  0.943056  

[5600 rows x 127 columns]
2024-05-04 15:24:58,572:INFO:get_config() successfully completed......................................
2024-05-04 15:26:32,989:INFO:Initializing get_config()
2024-05-04 15:26:32,990:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326624950>, variable=seed)
2024-05-04 15:26:32,990:INFO:Variable:  returned as 123
2024-05-04 15:26:32,990:INFO:get_config() successfully completed......................................
2024-05-04 15:26:32,990:INFO:Initializing set_config()
2024-05-04 15:26:32,990:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326624950>, variable=seed, value=786, kwargs={})
2024-05-04 15:26:32,991:INFO:Global variable: seed updated to 786
2024-05-04 15:26:32,991:INFO:set_config() successfully completed......................................
2024-05-04 15:26:32,991:INFO:Initializing get_config()
2024-05-04 15:26:32,991:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x326624950>, variable=seed)
2024-05-04 15:26:32,991:INFO:Variable:  returned as 786
2024-05-04 15:26:32,991:INFO:get_config() successfully completed......................................
2024-05-04 15:26:39,578:INFO:PyCaret ClassificationExperiment
2024-05-04 15:26:39,578:INFO:Logging name: clf-default-name
2024-05-04 15:26:39,578:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:26:39,578:INFO:version 3.3.2
2024-05-04 15:26:39,578:INFO:Initializing setup()
2024-05-04 15:26:39,578:INFO:self.USI: b25f
2024-05-04 15:26:39,578:INFO:self._variable_keys: {'target_param', 'y', 'y_test', 'logging_param', 'gpu_n_jobs_param', 'fix_imbalance', 'data', 'html_param', 'exp_name_log', 'memory', 'idx', 'pipeline', 'X', 'gpu_param', 'X_train', 'is_multiclass', 'n_jobs_param', 'X_test', 'USI', 'exp_id', 'log_plots_param', 'y_train', 'fold_groups_param', '_ml_usecase', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'seed'}
2024-05-04 15:26:39,578:INFO:Checking environment
2024-05-04 15:26:39,578:INFO:python_version: 3.11.8
2024-05-04 15:26:39,578:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:26:39,578:INFO:machine: arm64
2024-05-04 15:26:39,578:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:26:39,578:INFO:Memory: svmem(total=17179869184, available=5455659008, percent=68.2, used=7440629760, free=70139904, active=5395922944, inactive=5375623168, wired=2044706816)
2024-05-04 15:26:39,578:INFO:Physical Core: 8
2024-05-04 15:26:39,578:INFO:Logical Core: 8
2024-05-04 15:26:39,578:INFO:Checking libraries
2024-05-04 15:26:39,578:INFO:System:
2024-05-04 15:26:39,578:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:26:39,578:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:26:39,578:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:26:39,578:INFO:PyCaret required dependencies:
2024-05-04 15:26:39,579:INFO:                 pip: 24.0
2024-05-04 15:26:39,579:INFO:          setuptools: 69.2.0
2024-05-04 15:26:39,579:INFO:             pycaret: 3.3.2
2024-05-04 15:26:39,579:INFO:             IPython: 8.22.2
2024-05-04 15:26:39,579:INFO:          ipywidgets: 8.1.2
2024-05-04 15:26:39,579:INFO:                tqdm: 4.66.2
2024-05-04 15:26:39,579:INFO:               numpy: 1.26.4
2024-05-04 15:26:39,579:INFO:              pandas: 2.1.4
2024-05-04 15:26:39,579:INFO:              jinja2: 3.1.3
2024-05-04 15:26:39,579:INFO:               scipy: 1.11.4
2024-05-04 15:26:39,579:INFO:              joblib: 1.3.2
2024-05-04 15:26:39,579:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:26:39,579:INFO:                pyod: 1.1.3
2024-05-04 15:26:39,579:INFO:            imblearn: 0.12.2
2024-05-04 15:26:39,579:INFO:   category_encoders: 2.6.3
2024-05-04 15:26:39,579:INFO:            lightgbm: 4.3.0
2024-05-04 15:26:39,579:INFO:               numba: 0.59.1
2024-05-04 15:26:39,579:INFO:            requests: 2.31.0
2024-05-04 15:26:39,579:INFO:          matplotlib: 3.7.5
2024-05-04 15:26:39,579:INFO:          scikitplot: 0.3.7
2024-05-04 15:26:39,579:INFO:         yellowbrick: 1.5
2024-05-04 15:26:39,579:INFO:              plotly: 5.19.0
2024-05-04 15:26:39,579:INFO:    plotly-resampler: Not installed
2024-05-04 15:26:39,579:INFO:             kaleido: 0.2.1
2024-05-04 15:26:39,579:INFO:           schemdraw: 0.15
2024-05-04 15:26:39,579:INFO:         statsmodels: 0.14.1
2024-05-04 15:26:39,579:INFO:              sktime: 0.26.0
2024-05-04 15:26:39,579:INFO:               tbats: 1.1.3
2024-05-04 15:26:39,579:INFO:            pmdarima: 2.0.4
2024-05-04 15:26:39,579:INFO:              psutil: 5.9.8
2024-05-04 15:26:39,579:INFO:          markupsafe: 2.1.5
2024-05-04 15:26:39,579:INFO:             pickle5: Not installed
2024-05-04 15:26:39,579:INFO:         cloudpickle: 3.0.0
2024-05-04 15:26:39,579:INFO:         deprecation: 2.1.0
2024-05-04 15:26:39,579:INFO:              xxhash: 3.4.1
2024-05-04 15:26:39,579:INFO:           wurlitzer: 3.0.3
2024-05-04 15:26:39,579:INFO:PyCaret optional dependencies:
2024-05-04 15:26:39,579:INFO:                shap: 0.44.1
2024-05-04 15:26:39,579:INFO:           interpret: 0.6.1
2024-05-04 15:26:39,579:INFO:                umap: 0.5.6
2024-05-04 15:26:39,579:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:26:39,579:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:26:39,579:INFO:             autoviz: Not installed
2024-05-04 15:26:39,579:INFO:           fairlearn: 0.7.0
2024-05-04 15:26:39,579:INFO:          deepchecks: Not installed
2024-05-04 15:26:39,579:INFO:             xgboost: Not installed
2024-05-04 15:26:39,579:INFO:            catboost: Not installed
2024-05-04 15:26:39,579:INFO:              kmodes: Not installed
2024-05-04 15:26:39,579:INFO:             mlxtend: 0.23.1
2024-05-04 15:26:39,579:INFO:       statsforecast: Not installed
2024-05-04 15:26:39,579:INFO:        tune_sklearn: Not installed
2024-05-04 15:26:39,579:INFO:                 ray: Not installed
2024-05-04 15:26:39,579:INFO:            hyperopt: Not installed
2024-05-04 15:26:39,579:INFO:              optuna: Not installed
2024-05-04 15:26:39,579:INFO:               skopt: Not installed
2024-05-04 15:26:39,579:INFO:              mlflow: 2.12.1
2024-05-04 15:26:39,579:INFO:              gradio: 4.29.0
2024-05-04 15:26:39,579:INFO:             fastapi: 0.111.0
2024-05-04 15:26:39,579:INFO:             uvicorn: 0.29.0
2024-05-04 15:26:39,580:INFO:              m2cgen: 0.10.0
2024-05-04 15:26:39,580:INFO:           evidently: 0.4.20
2024-05-04 15:26:39,580:INFO:               fugue: 0.8.7
2024-05-04 15:26:39,580:INFO:           streamlit: 1.33.0
2024-05-04 15:26:39,580:INFO:             prophet: Not installed
2024-05-04 15:26:39,580:INFO:None
2024-05-04 15:26:39,580:INFO:Set up data.
2024-05-04 15:26:50,296:INFO:PyCaret ClassificationExperiment
2024-05-04 15:26:50,296:INFO:Logging name: clf-default-name
2024-05-04 15:26:50,296:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:26:50,296:INFO:version 3.3.2
2024-05-04 15:26:50,296:INFO:Initializing setup()
2024-05-04 15:26:50,296:INFO:self.USI: 0ca0
2024-05-04 15:26:50,296:INFO:self._variable_keys: {'target_param', 'y', 'y_test', 'logging_param', 'gpu_n_jobs_param', 'fix_imbalance', 'data', 'html_param', 'exp_name_log', 'memory', 'idx', 'pipeline', 'X', 'gpu_param', 'X_train', 'is_multiclass', 'n_jobs_param', 'X_test', 'USI', 'exp_id', 'log_plots_param', 'y_train', 'fold_groups_param', '_ml_usecase', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'seed'}
2024-05-04 15:26:50,296:INFO:Checking environment
2024-05-04 15:26:50,296:INFO:python_version: 3.11.8
2024-05-04 15:26:50,296:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:26:50,297:INFO:machine: arm64
2024-05-04 15:26:50,297:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:26:50,297:INFO:Memory: svmem(total=17179869184, available=5409832960, percent=68.5, used=7439056896, free=75694080, active=5346115584, inactive=5332074496, wired=2092941312)
2024-05-04 15:26:50,297:INFO:Physical Core: 8
2024-05-04 15:26:50,297:INFO:Logical Core: 8
2024-05-04 15:26:50,297:INFO:Checking libraries
2024-05-04 15:26:50,297:INFO:System:
2024-05-04 15:26:50,297:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:26:50,297:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:26:50,297:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:26:50,297:INFO:PyCaret required dependencies:
2024-05-04 15:26:50,297:INFO:                 pip: 24.0
2024-05-04 15:26:50,297:INFO:          setuptools: 69.2.0
2024-05-04 15:26:50,297:INFO:             pycaret: 3.3.2
2024-05-04 15:26:50,297:INFO:             IPython: 8.22.2
2024-05-04 15:26:50,297:INFO:          ipywidgets: 8.1.2
2024-05-04 15:26:50,297:INFO:                tqdm: 4.66.2
2024-05-04 15:26:50,297:INFO:               numpy: 1.26.4
2024-05-04 15:26:50,297:INFO:              pandas: 2.1.4
2024-05-04 15:26:50,297:INFO:              jinja2: 3.1.3
2024-05-04 15:26:50,297:INFO:               scipy: 1.11.4
2024-05-04 15:26:50,297:INFO:              joblib: 1.3.2
2024-05-04 15:26:50,297:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:26:50,297:INFO:                pyod: 1.1.3
2024-05-04 15:26:50,297:INFO:            imblearn: 0.12.2
2024-05-04 15:26:50,297:INFO:   category_encoders: 2.6.3
2024-05-04 15:26:50,297:INFO:            lightgbm: 4.3.0
2024-05-04 15:26:50,297:INFO:               numba: 0.59.1
2024-05-04 15:26:50,297:INFO:            requests: 2.31.0
2024-05-04 15:26:50,297:INFO:          matplotlib: 3.7.5
2024-05-04 15:26:50,297:INFO:          scikitplot: 0.3.7
2024-05-04 15:26:50,297:INFO:         yellowbrick: 1.5
2024-05-04 15:26:50,297:INFO:              plotly: 5.19.0
2024-05-04 15:26:50,297:INFO:    plotly-resampler: Not installed
2024-05-04 15:26:50,297:INFO:             kaleido: 0.2.1
2024-05-04 15:26:50,297:INFO:           schemdraw: 0.15
2024-05-04 15:26:50,297:INFO:         statsmodels: 0.14.1
2024-05-04 15:26:50,297:INFO:              sktime: 0.26.0
2024-05-04 15:26:50,297:INFO:               tbats: 1.1.3
2024-05-04 15:26:50,297:INFO:            pmdarima: 2.0.4
2024-05-04 15:26:50,297:INFO:              psutil: 5.9.8
2024-05-04 15:26:50,297:INFO:          markupsafe: 2.1.5
2024-05-04 15:26:50,297:INFO:             pickle5: Not installed
2024-05-04 15:26:50,297:INFO:         cloudpickle: 3.0.0
2024-05-04 15:26:50,297:INFO:         deprecation: 2.1.0
2024-05-04 15:26:50,297:INFO:              xxhash: 3.4.1
2024-05-04 15:26:50,297:INFO:           wurlitzer: 3.0.3
2024-05-04 15:26:50,297:INFO:PyCaret optional dependencies:
2024-05-04 15:26:50,297:INFO:                shap: 0.44.1
2024-05-04 15:26:50,297:INFO:           interpret: 0.6.1
2024-05-04 15:26:50,297:INFO:                umap: 0.5.6
2024-05-04 15:26:50,297:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:26:50,297:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:26:50,297:INFO:             autoviz: Not installed
2024-05-04 15:26:50,297:INFO:           fairlearn: 0.7.0
2024-05-04 15:26:50,297:INFO:          deepchecks: Not installed
2024-05-04 15:26:50,297:INFO:             xgboost: Not installed
2024-05-04 15:26:50,297:INFO:            catboost: Not installed
2024-05-04 15:26:50,297:INFO:              kmodes: Not installed
2024-05-04 15:26:50,297:INFO:             mlxtend: 0.23.1
2024-05-04 15:26:50,297:INFO:       statsforecast: Not installed
2024-05-04 15:26:50,297:INFO:        tune_sklearn: Not installed
2024-05-04 15:26:50,297:INFO:                 ray: Not installed
2024-05-04 15:26:50,297:INFO:            hyperopt: Not installed
2024-05-04 15:26:50,297:INFO:              optuna: Not installed
2024-05-04 15:26:50,297:INFO:               skopt: Not installed
2024-05-04 15:26:50,297:INFO:              mlflow: 2.12.1
2024-05-04 15:26:50,297:INFO:              gradio: 4.29.0
2024-05-04 15:26:50,297:INFO:             fastapi: 0.111.0
2024-05-04 15:26:50,297:INFO:             uvicorn: 0.29.0
2024-05-04 15:26:50,297:INFO:              m2cgen: 0.10.0
2024-05-04 15:26:50,297:INFO:           evidently: 0.4.20
2024-05-04 15:26:50,297:INFO:               fugue: 0.8.7
2024-05-04 15:26:50,297:INFO:           streamlit: 1.33.0
2024-05-04 15:26:50,297:INFO:             prophet: Not installed
2024-05-04 15:26:50,297:INFO:None
2024-05-04 15:26:50,298:INFO:Set up data.
2024-05-04 15:26:50,745:INFO:Set up folding strategy.
2024-05-04 15:26:50,745:INFO:Set up train/test split.
2024-05-04 15:26:50,927:INFO:Set up index.
2024-05-04 15:26:50,927:INFO:Assigning column types.
2024-05-04 15:26:50,932:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 15:26:50,952:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:26:50,952:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:26:50,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:50,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:50,989:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:26:50,991:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:26:51,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,003:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 15:26:51,023:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:26:51,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,054:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:26:51,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,065:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-04 15:26:51,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:26:51,127:INFO:Preparing preprocessing pipeline...
2024-05-04 15:26:51,128:INFO:Set up label encoding.
2024-05-04 15:26:51,128:INFO:Set up simple imputation.
2024-05-04 15:26:51,137:INFO:Set up encoding of categorical features.
2024-05-04 15:26:51,138:INFO:Set up feature normalization.
2024-05-04 15:26:54,618:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:249: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2024-05-04 15:26:55,147:INFO:Finished creating preprocessing pipeline.
2024-05-04 15:26:55,151:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2024-05-04 15:26:55,151:INFO:Creating final display dataframe.
2024-05-04 15:26:57,820:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:289: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-04 15:27:00,634:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:289: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-04 15:27:01,807:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target              Class
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape        (8000, 118)
5        Transformed data shape        (8000, 128)
6   Transformed train set shape        (5600, 128)
7    Transformed test set shape        (2400, 128)
8          Categorical features                117
9      Rows with missing values              35.1%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16                    Normalize               True
17             Normalize method             minmax
18               Fold Generator    StratifiedKFold
19                  Fold Number                 10
20                     CPU Jobs                 -1
21                      Use GPU              False
22               Log Experiment              False
23              Experiment Name   clf-default-name
24                          USI               0ca0
2024-05-04 15:27:01,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:27:01,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:27:01,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:27:01,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:27:01,876:INFO:setup() successfully completed in 11.58s...............
2024-05-04 15:27:09,306:INFO:Initializing get_config()
2024-05-04 15:27:09,306:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, variable=X_train_transformed)
2024-05-04 15:27:09,887:INFO:Variable: X_train returned as       Group_G1  Group_G9  Group_G8  Group_G2  Group_G4  Group_G5  Group_G11  \
3269       1.0       0.0       0.0       0.0       0.0       0.0        0.0   
183        0.0       1.0       0.0       0.0       0.0       0.0        0.0   
6101       0.0       0.0       1.0       0.0       0.0       0.0        0.0   
7683       0.0       0.0       0.0       1.0       0.0       0.0        0.0   
5729       0.0       0.0       1.0       0.0       0.0       0.0        0.0   
...        ...       ...       ...       ...       ...       ...        ...   
5437       0.0       0.0       0.0       0.0       1.0       0.0        0.0   
3127       0.0       1.0       0.0       0.0       0.0       0.0        0.0   
2312       0.0       0.0       0.0       0.0       0.0       1.0        0.0   
7463       0.0       0.0       0.0       1.0       0.0       0.0        0.0   
7601       0.0       0.0       0.0       0.0       0.0       0.0        1.0   

      Group_G7  Group_G3  Group_G6  ...      dI49      dI50      dI51  \
3269       0.0       0.0       0.0  ...  0.245591  0.612984  0.287441   
183        0.0       0.0       0.0  ...  0.044872  0.043116  0.085473   
6101       0.0       0.0       0.0  ...  0.962091  0.924444  0.927789   
7683       0.0       0.0       0.0  ...  0.044872  0.000000  0.666667   
5729       0.0       0.0       0.0  ...  0.044872  0.043116  0.503434   
...        ...       ...       ...  ...       ...       ...       ...   
5437       0.0       0.0       0.0  ...  0.503481  0.483780  0.506631   
3127       0.0       0.0       0.0  ...  0.044872  0.612984  0.085473   
2312       0.0       0.0       0.0  ...  0.962091  0.924444  0.927789   
7463       0.0       0.0       0.0  ...  0.044872  0.043116  0.085473   
7601       0.0       0.0       0.0  ...  0.044872  0.043116  0.224444   

          dI52      dI53      dI54      dI55      dI56  dI57      dI58  
3269  0.217524  0.526314  0.503481  0.503481  0.455748   0.5  0.000000  
183   0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  
6101  0.924444  0.963834  0.962091  0.962091  0.911496   1.0  1.000000  
7683  0.000000  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  
5729  0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  
...        ...       ...       ...       ...       ...   ...       ...  
5437  0.483780  0.526314  0.503481  0.503481  0.455748   0.5  0.634812  
3127  0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  
2312  0.924444  0.963834  0.962091  0.962091  0.911496   1.0  1.000000  
7463  0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.000000  
7601  0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  

[5600 rows x 127 columns]
2024-05-04 15:27:09,887:INFO:get_config() successfully completed......................................
2024-05-04 15:27:42,723:INFO:Initializing get_config()
2024-05-04 15:27:42,723:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, variable=X_train_transformed)
2024-05-04 15:27:43,318:INFO:Variable: X_train returned as       Group_G1  Group_G9  Group_G8  Group_G2  Group_G4  Group_G5  Group_G11  \
3269       1.0       0.0       0.0       0.0       0.0       0.0        0.0   
183        0.0       1.0       0.0       0.0       0.0       0.0        0.0   
6101       0.0       0.0       1.0       0.0       0.0       0.0        0.0   
7683       0.0       0.0       0.0       1.0       0.0       0.0        0.0   
5729       0.0       0.0       1.0       0.0       0.0       0.0        0.0   
...        ...       ...       ...       ...       ...       ...        ...   
5437       0.0       0.0       0.0       0.0       1.0       0.0        0.0   
3127       0.0       1.0       0.0       0.0       0.0       0.0        0.0   
2312       0.0       0.0       0.0       0.0       0.0       1.0        0.0   
7463       0.0       0.0       0.0       1.0       0.0       0.0        0.0   
7601       0.0       0.0       0.0       0.0       0.0       0.0        1.0   

      Group_G7  Group_G3  Group_G6  ...      dI49      dI50      dI51  \
3269       0.0       0.0       0.0  ...  0.245591  0.612984  0.287441   
183        0.0       0.0       0.0  ...  0.044872  0.043116  0.085473   
6101       0.0       0.0       0.0  ...  0.962091  0.924444  0.927789   
7683       0.0       0.0       0.0  ...  0.044872  0.000000  0.666667   
5729       0.0       0.0       0.0  ...  0.044872  0.043116  0.503434   
...        ...       ...       ...  ...       ...       ...       ...   
5437       0.0       0.0       0.0  ...  0.503481  0.483780  0.506631   
3127       0.0       0.0       0.0  ...  0.044872  0.612984  0.085473   
2312       0.0       0.0       0.0  ...  0.962091  0.924444  0.927789   
7463       0.0       0.0       0.0  ...  0.044872  0.043116  0.085473   
7601       0.0       0.0       0.0  ...  0.044872  0.043116  0.224444   

          dI52      dI53      dI54      dI55      dI56  dI57      dI58  
3269  0.217524  0.526314  0.503481  0.503481  0.455748   0.5  0.000000  
183   0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  
6101  0.924444  0.963834  0.962091  0.962091  0.911496   1.0  1.000000  
7683  0.000000  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  
5729  0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  
...        ...       ...       ...       ...       ...   ...       ...  
5437  0.483780  0.526314  0.503481  0.503481  0.455748   0.5  0.634812  
3127  0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  
2312  0.924444  0.963834  0.962091  0.962091  0.911496   1.0  1.000000  
7463  0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.000000  
7601  0.043116  0.088794  0.044872  0.044872  0.000000   0.0  0.269624  

[5600 rows x 127 columns]
2024-05-04 15:27:43,318:INFO:get_config() successfully completed......................................
2024-05-04 15:28:02,644:INFO:Initializing get_config()
2024-05-04 15:28:02,644:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, variable=X_train)
2024-05-04 15:28:02,644:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2024-05-04 15:28:02,647:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2024-05-04 15:28:02,658:INFO:Variable:  returned as      Group            I1            I2            I3            I4  \
3269    G1  -0,910584248   -0,03216073  -0,045021711           NaN   
183     G9  -0,450457096  -0,033553805  -0,024626107   0,292822523   
6101    G8  -0,428083158  -0,034215745  -0,041981188  -0,639002797   
7683    G2   0,620787533  -0,011168651    -0,0259444   0,021087544   
5729    G8  -0,253307154  -0,031294652  -0,037904882  -0,262726249   
...    ...           ...           ...           ...           ...   
5437    G4   3,962915512   0,024030023  -0,006177819   3,216059639   
3127    G9  -0,084276653  -0,023780803  -0,027931932    0,13693066   
2312    G5   -0,46187168  -0,023239269  -0,009985635  -0,561136111   
7463    G2  -0,580466957  -0,037818296  -0,047618186  -0,534485287   
7601   G11   2,042524168  -0,016470572  -0,037146281   0,459239456   

                I5            I6            I7            I8            I9  \
3269  -3,115790377  -0,816974808  -1,019090714  -0,079270031  -1,765654125   
183   -0,081481735  -0,210500655  -0,442018413  -0,055090212  -0,880678136   
6101  -0,514107721  -0,270860355  -0,319592253  -0,058521929  -1,018964186   
7683  -0,127563488  -0,052166745  -0,169342874  -0,036067645   0,089508878   
5729  -0,186656217  -0,182853385  -0,312781674    -0,0489867  -0,450363843   
...            ...           ...           ...           ...           ...   
5437  -0,009767816   0,785220249   0,809195776   0,007200149   4,157046425   
3127   0,088101714   0,447581293   0,353141444  -0,024636018   0,383716958   
2312  -0,236373695  -0,383379202  -0,620439433  -0,015163783  -0,210628564   
7463  -0,408391792  -0,750225304  -0,972219276   -0,08725086  -2,415386606   
7601   0,032622255   0,342322709   0,416851983  -0,034574722    2,35596451   

      ...          dI49          dI50        dI51          dI52          dI53  \
3269  ...           NaN           NaN         NaN           NaN   0,090952381   
183   ...  -0,181417266  -0,296110092  -0,1134375  -0,386974026  -0,022398374   
6101  ...  -1,298784173  -1,617238532  -2,5036875  -2,664961039   0,088376307   
7683  ...  -0,116273381   -0,07912844  -0,1349375   0,009701299   -0,01237863   
5729  ...  -0,443453237  -0,528458716   -0,554625  -0,589701299   0,049524971   
...   ...           ...           ...         ...           ...           ...   
5437  ...   1,001719424   1,439091743   0,5719375   1,370571429  -0,037370499   
3127  ...    1,14947482           NaN   1,6781875  -0,020636364  -0,225799071   
2312  ...   0,079863309    0,06266055    0,305375   0,001077922   0,035225319   
7463  ...  -0,262935252  -0,228082569  -0,6813125  -0,074701299   0,099543554   
7601  ...  -0,167769784  -0,219513761  -0,2009375  -0,185623377   0,006245064   

              dI54          dI55          dI56          dI57          dI58  
3269    -0,0140704   0,029244094  -0,118375785  -1,219395706           NaN  
183   -0,177406933   -0,47276378   0,168092196  -0,286877308   0,023486915  
6101    -0,3699696  -0,703202577   0,841647534  -0,029161427   0,023449553  
7683  -0,001098133  -0,333708661   0,322046311   0,007687996  -0,008270047  
5729   0,144592533   0,171455977   0,176538696  -0,040912012  -0,018238872  
...            ...           ...           ...           ...           ...  
5437  -0,345949333  -0,229511095   0,018107669  -0,125348187  -0,006443027  
3127  -1,149780267    -1,1163665   0,594076048  -0,011157829   0,002836917  
2312     0,0739792    0,41498282    0,36592493  -0,022407865  -0,004557993  
7463   0,817693333    0,03632355   0,788865891  -0,186573549           NaN  
7601    -0,0432272  -0,007411596  -0,100361765  -0,017457369  -0,000365154  

[5600 rows x 117 columns]
2024-05-04 15:28:02,658:INFO:get_config() successfully completed......................................
2024-05-04 15:28:29,927:INFO:Initializing compare_models()
2024-05-04 15:28:29,927:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-04 15:28:29,928:INFO:Checking exceptions
2024-05-04 15:28:29,937:INFO:Preparing display monitor
2024-05-04 15:28:29,948:INFO:Initializing Logistic Regression
2024-05-04 15:28:29,948:INFO:Total runtime is 4.319349924723307e-06 minutes
2024-05-04 15:28:29,950:INFO:SubProcess create_model() called ==================================
2024-05-04 15:28:29,950:INFO:Initializing create_model()
2024-05-04 15:28:29,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:28:29,950:INFO:Checking exceptions
2024-05-04 15:28:29,950:INFO:Importing libraries
2024-05-04 15:28:29,950:INFO:Copying training dataset
2024-05-04 15:28:29,962:INFO:Defining folds
2024-05-04 15:28:29,962:INFO:Declaring metric variables
2024-05-04 15:28:29,964:INFO:Importing untrained model
2024-05-04 15:28:29,966:INFO:Logistic Regression Imported successfully
2024-05-04 15:28:29,968:INFO:Starting cross validation
2024-05-04 15:28:29,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:28:34,276:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:34,284:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:34,681:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:34,685:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:34,690:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:34,696:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:34,823:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:34,827:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:35,064:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:35,068:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:35,276:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:35,280:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:35,499:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:35,502:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:35,570:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:35,574:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:36,221:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:36,223:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:36,309:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:36,311:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:36,503:INFO:Calculating mean and std
2024-05-04 15:28:36,505:INFO:Creating metrics dataframe
2024-05-04 15:28:36,511:INFO:Uploading results into container
2024-05-04 15:28:36,511:INFO:Uploading model into container now
2024-05-04 15:28:36,512:INFO:_master_model_container: 1
2024-05-04 15:28:36,512:INFO:_display_container: 2
2024-05-04 15:28:36,512:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-04 15:28:36,512:INFO:create_model() successfully completed......................................
2024-05-04 15:28:36,744:INFO:SubProcess create_model() end ==================================
2024-05-04 15:28:36,744:INFO:Creating metrics dataframe
2024-05-04 15:28:36,748:INFO:Initializing K Neighbors Classifier
2024-05-04 15:28:36,748:INFO:Total runtime is 0.11333266894022623 minutes
2024-05-04 15:28:36,749:INFO:SubProcess create_model() called ==================================
2024-05-04 15:28:36,750:INFO:Initializing create_model()
2024-05-04 15:28:36,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:28:36,750:INFO:Checking exceptions
2024-05-04 15:28:36,750:INFO:Importing libraries
2024-05-04 15:28:36,750:INFO:Copying training dataset
2024-05-04 15:28:36,761:INFO:Defining folds
2024-05-04 15:28:36,761:INFO:Declaring metric variables
2024-05-04 15:28:36,762:INFO:Importing untrained model
2024-05-04 15:28:36,764:INFO:K Neighbors Classifier Imported successfully
2024-05-04 15:28:36,766:INFO:Starting cross validation
2024-05-04 15:28:36,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:28:38,788:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:39,162:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:39,465:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:39,786:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:39,848:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:39,862:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:40,037:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:40,541:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:40,779:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:41,248:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:41,262:INFO:Calculating mean and std
2024-05-04 15:28:41,263:INFO:Creating metrics dataframe
2024-05-04 15:28:41,267:INFO:Uploading results into container
2024-05-04 15:28:41,267:INFO:Uploading model into container now
2024-05-04 15:28:41,268:INFO:_master_model_container: 2
2024-05-04 15:28:41,268:INFO:_display_container: 2
2024-05-04 15:28:41,268:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-04 15:28:41,268:INFO:create_model() successfully completed......................................
2024-05-04 15:28:41,485:INFO:SubProcess create_model() end ==================================
2024-05-04 15:28:41,485:INFO:Creating metrics dataframe
2024-05-04 15:28:41,489:INFO:Initializing Naive Bayes
2024-05-04 15:28:41,489:INFO:Total runtime is 0.1923475662867228 minutes
2024-05-04 15:28:41,490:INFO:SubProcess create_model() called ==================================
2024-05-04 15:28:41,491:INFO:Initializing create_model()
2024-05-04 15:28:41,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:28:41,491:INFO:Checking exceptions
2024-05-04 15:28:41,491:INFO:Importing libraries
2024-05-04 15:28:41,491:INFO:Copying training dataset
2024-05-04 15:28:41,501:INFO:Defining folds
2024-05-04 15:28:41,501:INFO:Declaring metric variables
2024-05-04 15:28:41,502:INFO:Importing untrained model
2024-05-04 15:28:41,504:INFO:Naive Bayes Imported successfully
2024-05-04 15:28:41,506:INFO:Starting cross validation
2024-05-04 15:28:41,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:28:43,291:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:43,513:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:43,601:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:43,699:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:43,708:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:43,876:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:44,057:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:44,250:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:44,789:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:44,949:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:44,961:INFO:Calculating mean and std
2024-05-04 15:28:44,962:INFO:Creating metrics dataframe
2024-05-04 15:28:44,964:INFO:Uploading results into container
2024-05-04 15:28:44,964:INFO:Uploading model into container now
2024-05-04 15:28:44,964:INFO:_master_model_container: 3
2024-05-04 15:28:44,964:INFO:_display_container: 2
2024-05-04 15:28:44,964:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-04 15:28:44,965:INFO:create_model() successfully completed......................................
2024-05-04 15:28:45,149:INFO:SubProcess create_model() end ==================================
2024-05-04 15:28:45,149:INFO:Creating metrics dataframe
2024-05-04 15:28:45,152:INFO:Initializing Decision Tree Classifier
2024-05-04 15:28:45,152:INFO:Total runtime is 0.2534053842226664 minutes
2024-05-04 15:28:45,153:INFO:SubProcess create_model() called ==================================
2024-05-04 15:28:45,154:INFO:Initializing create_model()
2024-05-04 15:28:45,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:28:45,154:INFO:Checking exceptions
2024-05-04 15:28:45,154:INFO:Importing libraries
2024-05-04 15:28:45,154:INFO:Copying training dataset
2024-05-04 15:28:45,163:INFO:Defining folds
2024-05-04 15:28:45,163:INFO:Declaring metric variables
2024-05-04 15:28:45,164:INFO:Importing untrained model
2024-05-04 15:28:45,165:INFO:Decision Tree Classifier Imported successfully
2024-05-04 15:28:45,168:INFO:Starting cross validation
2024-05-04 15:28:45,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:28:46,999:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:47,022:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:47,251:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:47,365:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:47,458:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:47,570:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:47,862:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:47,892:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:48,464:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:48,628:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:48,640:INFO:Calculating mean and std
2024-05-04 15:28:48,641:INFO:Creating metrics dataframe
2024-05-04 15:28:48,642:INFO:Uploading results into container
2024-05-04 15:28:48,642:INFO:Uploading model into container now
2024-05-04 15:28:48,643:INFO:_master_model_container: 4
2024-05-04 15:28:48,643:INFO:_display_container: 2
2024-05-04 15:28:48,643:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-05-04 15:28:48,643:INFO:create_model() successfully completed......................................
2024-05-04 15:28:48,824:INFO:SubProcess create_model() end ==================================
2024-05-04 15:28:48,824:INFO:Creating metrics dataframe
2024-05-04 15:28:48,827:INFO:Initializing SVM - Linear Kernel
2024-05-04 15:28:48,827:INFO:Total runtime is 0.314660366376241 minutes
2024-05-04 15:28:48,829:INFO:SubProcess create_model() called ==================================
2024-05-04 15:28:48,829:INFO:Initializing create_model()
2024-05-04 15:28:48,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:28:48,829:INFO:Checking exceptions
2024-05-04 15:28:48,829:INFO:Importing libraries
2024-05-04 15:28:48,829:INFO:Copying training dataset
2024-05-04 15:28:48,839:INFO:Defining folds
2024-05-04 15:28:48,839:INFO:Declaring metric variables
2024-05-04 15:28:48,841:INFO:Importing untrained model
2024-05-04 15:28:48,842:INFO:SVM - Linear Kernel Imported successfully
2024-05-04 15:28:48,845:INFO:Starting cross validation
2024-05-04 15:28:48,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:28:50,985:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:50,988:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:51,062:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:51,064:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:51,174:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:51,176:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:51,335:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:51,336:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:51,366:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:51,368:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:51,498:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:51,501:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:51,668:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:51,670:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:51,802:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:51,804:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:52,609:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:52,612:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:52,742:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:52,744:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:52,758:INFO:Calculating mean and std
2024-05-04 15:28:52,759:INFO:Creating metrics dataframe
2024-05-04 15:28:52,761:INFO:Uploading results into container
2024-05-04 15:28:52,761:INFO:Uploading model into container now
2024-05-04 15:28:52,761:INFO:_master_model_container: 5
2024-05-04 15:28:52,761:INFO:_display_container: 2
2024-05-04 15:28:52,762:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-04 15:28:52,762:INFO:create_model() successfully completed......................................
2024-05-04 15:28:52,957:INFO:SubProcess create_model() end ==================================
2024-05-04 15:28:52,957:INFO:Creating metrics dataframe
2024-05-04 15:28:52,961:INFO:Initializing Ridge Classifier
2024-05-04 15:28:52,961:INFO:Total runtime is 0.38355005184809365 minutes
2024-05-04 15:28:52,962:INFO:SubProcess create_model() called ==================================
2024-05-04 15:28:52,962:INFO:Initializing create_model()
2024-05-04 15:28:52,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:28:52,963:INFO:Checking exceptions
2024-05-04 15:28:52,963:INFO:Importing libraries
2024-05-04 15:28:52,963:INFO:Copying training dataset
2024-05-04 15:28:52,972:INFO:Defining folds
2024-05-04 15:28:52,972:INFO:Declaring metric variables
2024-05-04 15:28:52,974:INFO:Importing untrained model
2024-05-04 15:28:52,976:INFO:Ridge Classifier Imported successfully
2024-05-04 15:28:52,979:INFO:Starting cross validation
2024-05-04 15:28:52,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:28:54,768:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:54,770:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:55,009:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:55,016:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:55,117:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:55,118:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:55,336:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:55,338:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:55,342:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:55,344:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:55,375:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:55,377:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:55,683:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:55,684:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:55,922:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:55,924:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:56,342:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:56,344:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:56,451:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:28:56,452:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:56,458:INFO:Calculating mean and std
2024-05-04 15:28:56,459:INFO:Creating metrics dataframe
2024-05-04 15:28:56,462:INFO:Uploading results into container
2024-05-04 15:28:56,462:INFO:Uploading model into container now
2024-05-04 15:28:56,462:INFO:_master_model_container: 6
2024-05-04 15:28:56,462:INFO:_display_container: 2
2024-05-04 15:28:56,462:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-05-04 15:28:56,462:INFO:create_model() successfully completed......................................
2024-05-04 15:28:56,694:INFO:SubProcess create_model() end ==================================
2024-05-04 15:28:56,694:INFO:Creating metrics dataframe
2024-05-04 15:28:56,699:INFO:Initializing Random Forest Classifier
2024-05-04 15:28:56,699:INFO:Total runtime is 0.44584601720174155 minutes
2024-05-04 15:28:56,701:INFO:SubProcess create_model() called ==================================
2024-05-04 15:28:56,701:INFO:Initializing create_model()
2024-05-04 15:28:56,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:28:56,701:INFO:Checking exceptions
2024-05-04 15:28:56,701:INFO:Importing libraries
2024-05-04 15:28:56,701:INFO:Copying training dataset
2024-05-04 15:28:56,713:INFO:Defining folds
2024-05-04 15:28:56,713:INFO:Declaring metric variables
2024-05-04 15:28:56,715:INFO:Importing untrained model
2024-05-04 15:28:56,716:INFO:Random Forest Classifier Imported successfully
2024-05-04 15:28:56,719:INFO:Starting cross validation
2024-05-04 15:28:56,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:28:58,971:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:59,062:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:59,163:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:59,202:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:59,428:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:59,498:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:59,751:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:28:59,916:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:00,705:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:00,793:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:00,806:INFO:Calculating mean and std
2024-05-04 15:29:00,807:INFO:Creating metrics dataframe
2024-05-04 15:29:00,810:INFO:Uploading results into container
2024-05-04 15:29:00,810:INFO:Uploading model into container now
2024-05-04 15:29:00,810:INFO:_master_model_container: 7
2024-05-04 15:29:00,810:INFO:_display_container: 2
2024-05-04 15:29:00,810:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-05-04 15:29:00,811:INFO:create_model() successfully completed......................................
2024-05-04 15:29:01,010:INFO:SubProcess create_model() end ==================================
2024-05-04 15:29:01,010:INFO:Creating metrics dataframe
2024-05-04 15:29:01,014:INFO:Initializing Quadratic Discriminant Analysis
2024-05-04 15:29:01,014:INFO:Total runtime is 0.5177738348642985 minutes
2024-05-04 15:29:01,016:INFO:SubProcess create_model() called ==================================
2024-05-04 15:29:01,016:INFO:Initializing create_model()
2024-05-04 15:29:01,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:29:01,016:INFO:Checking exceptions
2024-05-04 15:29:01,016:INFO:Importing libraries
2024-05-04 15:29:01,016:INFO:Copying training dataset
2024-05-04 15:29:01,026:INFO:Defining folds
2024-05-04 15:29:01,026:INFO:Declaring metric variables
2024-05-04 15:29:01,028:INFO:Importing untrained model
2024-05-04 15:29:01,029:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-04 15:29:01,031:INFO:Starting cross validation
2024-05-04 15:29:01,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:29:02,813:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:02,904:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:02,999:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:03,001:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:03,087:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:03,089:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:03,164:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:03,166:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:03,341:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:03,343:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:03,350:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:03,363:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:03,365:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:03,468:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:03,506:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:03,508:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:03,576:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:03,630:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:03,632:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:03,687:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:03,721:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:03,723:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:03,829:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:03,831:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:04,466:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:04,602:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:04,604:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:04,605:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:29:04,733:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:04,735:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:04,740:INFO:Calculating mean and std
2024-05-04 15:29:04,741:INFO:Creating metrics dataframe
2024-05-04 15:29:04,743:INFO:Uploading results into container
2024-05-04 15:29:04,743:INFO:Uploading model into container now
2024-05-04 15:29:04,744:INFO:_master_model_container: 8
2024-05-04 15:29:04,744:INFO:_display_container: 2
2024-05-04 15:29:04,744:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-04 15:29:04,744:INFO:create_model() successfully completed......................................
2024-05-04 15:29:04,936:INFO:SubProcess create_model() end ==================================
2024-05-04 15:29:04,936:INFO:Creating metrics dataframe
2024-05-04 15:29:04,940:INFO:Initializing Ada Boost Classifier
2024-05-04 15:29:04,940:INFO:Total runtime is 0.5832085013389587 minutes
2024-05-04 15:29:04,942:INFO:SubProcess create_model() called ==================================
2024-05-04 15:29:04,942:INFO:Initializing create_model()
2024-05-04 15:29:04,942:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:29:04,942:INFO:Checking exceptions
2024-05-04 15:29:04,942:INFO:Importing libraries
2024-05-04 15:29:04,943:INFO:Copying training dataset
2024-05-04 15:29:04,953:INFO:Defining folds
2024-05-04 15:29:04,953:INFO:Declaring metric variables
2024-05-04 15:29:04,954:INFO:Importing untrained model
2024-05-04 15:29:04,956:INFO:Ada Boost Classifier Imported successfully
2024-05-04 15:29:04,958:INFO:Starting cross validation
2024-05-04 15:29:04,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:29:06,595:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:06,720:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:06,857:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:07,078:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:07,135:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:07,172:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:07,174:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:07,250:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:07,287:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:07,290:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:07,391:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:07,400:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:07,491:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:07,604:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:07,606:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:07,616:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:07,618:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:07,684:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:07,730:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:07,732:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:07,921:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:07,923:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:08,082:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:08,085:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:08,588:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:08,669:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:29:08,959:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:08,961:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:09,025:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:09,026:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:09,029:INFO:Calculating mean and std
2024-05-04 15:29:09,029:INFO:Creating metrics dataframe
2024-05-04 15:29:09,031:INFO:Uploading results into container
2024-05-04 15:29:09,031:INFO:Uploading model into container now
2024-05-04 15:29:09,031:INFO:_master_model_container: 9
2024-05-04 15:29:09,031:INFO:_display_container: 2
2024-05-04 15:29:09,031:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-05-04 15:29:09,031:INFO:create_model() successfully completed......................................
2024-05-04 15:29:09,236:INFO:SubProcess create_model() end ==================================
2024-05-04 15:29:09,236:INFO:Creating metrics dataframe
2024-05-04 15:29:09,240:INFO:Initializing Gradient Boosting Classifier
2024-05-04 15:29:09,241:INFO:Total runtime is 0.6548777341842651 minutes
2024-05-04 15:29:09,242:INFO:SubProcess create_model() called ==================================
2024-05-04 15:29:09,242:INFO:Initializing create_model()
2024-05-04 15:29:09,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:29:09,243:INFO:Checking exceptions
2024-05-04 15:29:09,243:INFO:Importing libraries
2024-05-04 15:29:09,243:INFO:Copying training dataset
2024-05-04 15:29:09,252:INFO:Defining folds
2024-05-04 15:29:09,252:INFO:Declaring metric variables
2024-05-04 15:29:09,254:INFO:Importing untrained model
2024-05-04 15:29:09,256:INFO:Gradient Boosting Classifier Imported successfully
2024-05-04 15:29:09,258:INFO:Starting cross validation
2024-05-04 15:29:09,265:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:29:13,133:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:13,135:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:13,207:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:13,221:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:13,325:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:13,327:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:13,492:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:13,518:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:13,571:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:13,573:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:13,573:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:13,575:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:13,833:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:13,835:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:13,877:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:13,879:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:16,148:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:16,150:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:16,285:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:16,287:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:16,302:INFO:Calculating mean and std
2024-05-04 15:29:16,303:INFO:Creating metrics dataframe
2024-05-04 15:29:16,306:INFO:Uploading results into container
2024-05-04 15:29:16,306:INFO:Uploading model into container now
2024-05-04 15:29:16,307:INFO:_master_model_container: 10
2024-05-04 15:29:16,307:INFO:_display_container: 2
2024-05-04 15:29:16,307:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-04 15:29:16,307:INFO:create_model() successfully completed......................................
2024-05-04 15:29:16,550:INFO:SubProcess create_model() end ==================================
2024-05-04 15:29:16,550:INFO:Creating metrics dataframe
2024-05-04 15:29:16,564:INFO:Initializing Linear Discriminant Analysis
2024-05-04 15:29:16,565:INFO:Total runtime is 0.7769537488619486 minutes
2024-05-04 15:29:16,567:INFO:SubProcess create_model() called ==================================
2024-05-04 15:29:16,568:INFO:Initializing create_model()
2024-05-04 15:29:16,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:29:16,568:INFO:Checking exceptions
2024-05-04 15:29:16,568:INFO:Importing libraries
2024-05-04 15:29:16,568:INFO:Copying training dataset
2024-05-04 15:29:16,579:INFO:Defining folds
2024-05-04 15:29:16,580:INFO:Declaring metric variables
2024-05-04 15:29:16,582:INFO:Importing untrained model
2024-05-04 15:29:16,584:INFO:Linear Discriminant Analysis Imported successfully
2024-05-04 15:29:16,587:INFO:Starting cross validation
2024-05-04 15:29:16,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:29:18,635:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:18,635:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:18,636:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:18,637:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:18,823:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:18,825:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:18,903:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:18,905:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:18,973:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:18,975:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:19,047:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:19,049:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:19,357:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:19,358:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:19,510:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:19,512:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:20,226:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:20,227:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:20,468:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:29:20,470:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:20,474:INFO:Calculating mean and std
2024-05-04 15:29:20,476:INFO:Creating metrics dataframe
2024-05-04 15:29:20,480:INFO:Uploading results into container
2024-05-04 15:29:20,481:INFO:Uploading model into container now
2024-05-04 15:29:20,481:INFO:_master_model_container: 11
2024-05-04 15:29:20,481:INFO:_display_container: 2
2024-05-04 15:29:20,482:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-04 15:29:20,482:INFO:create_model() successfully completed......................................
2024-05-04 15:29:20,716:INFO:SubProcess create_model() end ==================================
2024-05-04 15:29:20,716:INFO:Creating metrics dataframe
2024-05-04 15:29:20,721:INFO:Initializing Extra Trees Classifier
2024-05-04 15:29:20,721:INFO:Total runtime is 0.8462245186169941 minutes
2024-05-04 15:29:20,723:INFO:SubProcess create_model() called ==================================
2024-05-04 15:29:20,723:INFO:Initializing create_model()
2024-05-04 15:29:20,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:29:20,723:INFO:Checking exceptions
2024-05-04 15:29:20,723:INFO:Importing libraries
2024-05-04 15:29:20,723:INFO:Copying training dataset
2024-05-04 15:29:20,733:INFO:Defining folds
2024-05-04 15:29:20,733:INFO:Declaring metric variables
2024-05-04 15:29:20,735:INFO:Importing untrained model
2024-05-04 15:29:20,736:INFO:Extra Trees Classifier Imported successfully
2024-05-04 15:29:20,738:INFO:Starting cross validation
2024-05-04 15:29:20,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:29:22,909:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:22,925:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:23,112:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:23,181:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:23,299:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:23,329:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:23,500:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:23,571:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:24,400:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:24,577:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:24,591:INFO:Calculating mean and std
2024-05-04 15:29:24,592:INFO:Creating metrics dataframe
2024-05-04 15:29:24,594:INFO:Uploading results into container
2024-05-04 15:29:24,594:INFO:Uploading model into container now
2024-05-04 15:29:24,594:INFO:_master_model_container: 12
2024-05-04 15:29:24,594:INFO:_display_container: 2
2024-05-04 15:29:24,595:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-05-04 15:29:24,595:INFO:create_model() successfully completed......................................
2024-05-04 15:29:24,794:INFO:SubProcess create_model() end ==================================
2024-05-04 15:29:24,795:INFO:Creating metrics dataframe
2024-05-04 15:29:24,799:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 15:29:24,799:INFO:Total runtime is 0.9141928990681965 minutes
2024-05-04 15:29:24,801:INFO:SubProcess create_model() called ==================================
2024-05-04 15:29:24,801:INFO:Initializing create_model()
2024-05-04 15:29:24,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:29:24,801:INFO:Checking exceptions
2024-05-04 15:29:24,802:INFO:Importing libraries
2024-05-04 15:29:24,802:INFO:Copying training dataset
2024-05-04 15:29:24,812:INFO:Defining folds
2024-05-04 15:29:24,812:INFO:Declaring metric variables
2024-05-04 15:29:24,814:INFO:Importing untrained model
2024-05-04 15:29:24,815:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:29:24,818:INFO:Starting cross validation
2024-05-04 15:29:24,825:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:29:27,162:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 15:29:27,163:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 15:29:27,164:INFO:Initializing create_model()
2024-05-04 15:29:27,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:29:27,164:INFO:Checking exceptions
2024-05-04 15:29:27,164:INFO:Importing libraries
2024-05-04 15:29:27,164:INFO:Copying training dataset
2024-05-04 15:29:27,174:INFO:Defining folds
2024-05-04 15:29:27,174:INFO:Declaring metric variables
2024-05-04 15:29:27,176:INFO:Importing untrained model
2024-05-04 15:29:27,177:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:29:27,180:INFO:Starting cross validation
2024-05-04 15:29:27,187:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:29:31,179:WARNING:OMP: Error #179: Function pthread_mutex_init failed:
2024-05-04 15:29:31,182:WARNING:OMP: System error #22: Invalid argument
2024-05-04 15:29:31,317:WARNING:OMP: Error #179: Function pthread_mutex_init failed:
2024-05-04 15:29:31,317:WARNING:OMP: System error #22: Invalid argument
2024-05-04 15:29:32,058:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 15:29:32,060:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 15:29:32,060:INFO:Initializing Dummy Classifier
2024-05-04 15:29:32,060:INFO:Total runtime is 1.0352048357327777 minutes
2024-05-04 15:29:32,063:INFO:SubProcess create_model() called ==================================
2024-05-04 15:29:32,063:INFO:Initializing create_model()
2024-05-04 15:29:32,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3333cd550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:29:32,063:INFO:Checking exceptions
2024-05-04 15:29:32,063:INFO:Importing libraries
2024-05-04 15:29:32,063:INFO:Copying training dataset
2024-05-04 15:29:32,073:INFO:Defining folds
2024-05-04 15:29:32,073:INFO:Declaring metric variables
2024-05-04 15:29:32,075:INFO:Importing untrained model
2024-05-04 15:29:32,076:INFO:Dummy Classifier Imported successfully
2024-05-04 15:29:32,079:INFO:Starting cross validation
2024-05-04 15:29:32,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:29:35,463:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:35,759:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:35,998:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:36,134:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:36,226:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:36,272:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:36,495:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:36,519:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:37,061:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:37,220:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:29:37,229:INFO:Calculating mean and std
2024-05-04 15:29:37,231:INFO:Creating metrics dataframe
2024-05-04 15:29:37,233:INFO:Uploading results into container
2024-05-04 15:29:37,233:INFO:Uploading model into container now
2024-05-04 15:29:37,234:INFO:_master_model_container: 13
2024-05-04 15:29:37,234:INFO:_display_container: 2
2024-05-04 15:29:37,234:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-05-04 15:29:37,234:INFO:create_model() successfully completed......................................
2024-05-04 15:29:37,452:INFO:SubProcess create_model() end ==================================
2024-05-04 15:29:37,452:INFO:Creating metrics dataframe
2024-05-04 15:29:37,457:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 15:29:37,461:INFO:Initializing create_model()
2024-05-04 15:29:37,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:29:37,461:INFO:Checking exceptions
2024-05-04 15:29:37,462:INFO:Importing libraries
2024-05-04 15:29:37,462:INFO:Copying training dataset
2024-05-04 15:29:37,473:INFO:Defining folds
2024-05-04 15:29:37,473:INFO:Declaring metric variables
2024-05-04 15:29:37,473:INFO:Importing untrained model
2024-05-04 15:29:37,473:INFO:Declaring custom model
2024-05-04 15:29:37,473:INFO:Dummy Classifier Imported successfully
2024-05-04 15:29:37,477:INFO:Cross validation set to False
2024-05-04 15:29:37,477:INFO:Fitting Model
2024-05-04 15:29:38,500:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-05-04 15:29:38,501:INFO:create_model() successfully completed......................................
2024-05-04 15:29:38,700:INFO:_master_model_container: 13
2024-05-04 15:29:38,700:INFO:_display_container: 2
2024-05-04 15:29:38,700:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-05-04 15:29:38,700:INFO:compare_models() successfully completed......................................
2024-05-04 15:29:55,665:INFO:gpu_param set to False
2024-05-04 15:29:55,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:29:55,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:29:55,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:29:55,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:30:00,664:INFO:Initializing compare_models()
2024-05-04 15:30:00,665:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, include=['dt', 'rf', 'et', 'gbc', 'xgboost', 'lightgbm', 'catboost'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, 'include': ['dt', 'rf', 'et', 'gbc', 'xgboost', 'lightgbm', 'catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-04 15:30:00,665:INFO:Checking exceptions
2024-05-04 15:30:13,643:INFO:Initializing compare_models()
2024-05-04 15:30:13,643:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, include=['dt', 'rf', 'et', 'gbc', 'lightgbm', 'catboost'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, 'include': ['dt', 'rf', 'et', 'gbc', 'lightgbm', 'catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-04 15:30:13,643:INFO:Checking exceptions
2024-05-04 15:30:19,306:INFO:Initializing compare_models()
2024-05-04 15:30:19,306:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, include=['dt', 'rf', 'et', 'gbc', 'lightgbm', 'catboost'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, 'include': ['dt', 'rf', 'et', 'gbc', 'lightgbm', 'catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-04 15:30:19,306:INFO:Checking exceptions
2024-05-04 15:30:28,861:INFO:Initializing compare_models()
2024-05-04 15:30:28,861:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, include=['dt', 'rf', 'et', 'gbc', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, 'include': ['dt', 'rf', 'et', 'gbc', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-04 15:30:28,861:INFO:Checking exceptions
2024-05-04 15:30:28,867:INFO:Preparing display monitor
2024-05-04 15:30:28,877:INFO:Initializing Decision Tree Classifier
2024-05-04 15:30:28,877:INFO:Total runtime is 4.398822784423828e-06 minutes
2024-05-04 15:30:28,879:INFO:SubProcess create_model() called ==================================
2024-05-04 15:30:28,879:INFO:Initializing create_model()
2024-05-04 15:30:28,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33656d510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:30:28,879:INFO:Checking exceptions
2024-05-04 15:30:28,879:INFO:Importing libraries
2024-05-04 15:30:28,879:INFO:Copying training dataset
2024-05-04 15:30:28,890:INFO:Defining folds
2024-05-04 15:30:28,890:INFO:Declaring metric variables
2024-05-04 15:30:28,891:INFO:Importing untrained model
2024-05-04 15:30:28,893:INFO:Decision Tree Classifier Imported successfully
2024-05-04 15:30:28,896:INFO:Starting cross validation
2024-05-04 15:30:28,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:30:30,915:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:31,094:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:31,195:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:31,231:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:31,429:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:31,476:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:31,613:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:31,907:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:32,423:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:32,601:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:32,606:INFO:Calculating mean and std
2024-05-04 15:30:32,607:INFO:Creating metrics dataframe
2024-05-04 15:30:32,610:INFO:Uploading results into container
2024-05-04 15:30:32,610:INFO:Uploading model into container now
2024-05-04 15:30:32,611:INFO:_master_model_container: 14
2024-05-04 15:30:32,611:INFO:_display_container: 3
2024-05-04 15:30:32,612:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-05-04 15:30:32,612:INFO:create_model() successfully completed......................................
2024-05-04 15:30:32,893:INFO:SubProcess create_model() end ==================================
2024-05-04 15:30:32,893:INFO:Creating metrics dataframe
2024-05-04 15:30:32,896:INFO:Initializing Random Forest Classifier
2024-05-04 15:30:32,896:INFO:Total runtime is 0.06698873043060304 minutes
2024-05-04 15:30:32,898:INFO:SubProcess create_model() called ==================================
2024-05-04 15:30:32,898:INFO:Initializing create_model()
2024-05-04 15:30:32,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33656d510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:30:32,898:INFO:Checking exceptions
2024-05-04 15:30:32,898:INFO:Importing libraries
2024-05-04 15:30:32,898:INFO:Copying training dataset
2024-05-04 15:30:32,907:INFO:Defining folds
2024-05-04 15:30:32,907:INFO:Declaring metric variables
2024-05-04 15:30:32,909:INFO:Importing untrained model
2024-05-04 15:30:32,910:INFO:Random Forest Classifier Imported successfully
2024-05-04 15:30:32,913:INFO:Starting cross validation
2024-05-04 15:30:32,928:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:30:35,179:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:35,353:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:35,392:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:35,429:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:35,477:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:35,542:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:35,658:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:35,731:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:36,668:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:36,865:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:36,875:INFO:Calculating mean and std
2024-05-04 15:30:36,875:INFO:Creating metrics dataframe
2024-05-04 15:30:36,877:INFO:Uploading results into container
2024-05-04 15:30:36,877:INFO:Uploading model into container now
2024-05-04 15:30:36,877:INFO:_master_model_container: 15
2024-05-04 15:30:36,877:INFO:_display_container: 3
2024-05-04 15:30:36,878:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-05-04 15:30:36,878:INFO:create_model() successfully completed......................................
2024-05-04 15:30:37,072:INFO:SubProcess create_model() end ==================================
2024-05-04 15:30:37,073:INFO:Creating metrics dataframe
2024-05-04 15:30:37,076:INFO:Initializing Extra Trees Classifier
2024-05-04 15:30:37,076:INFO:Total runtime is 0.13664895296096802 minutes
2024-05-04 15:30:37,077:INFO:SubProcess create_model() called ==================================
2024-05-04 15:30:37,077:INFO:Initializing create_model()
2024-05-04 15:30:37,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33656d510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:30:37,078:INFO:Checking exceptions
2024-05-04 15:30:37,078:INFO:Importing libraries
2024-05-04 15:30:37,078:INFO:Copying training dataset
2024-05-04 15:30:37,088:INFO:Defining folds
2024-05-04 15:30:37,088:INFO:Declaring metric variables
2024-05-04 15:30:37,089:INFO:Importing untrained model
2024-05-04 15:30:37,091:INFO:Extra Trees Classifier Imported successfully
2024-05-04 15:30:37,094:INFO:Starting cross validation
2024-05-04 15:30:37,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:30:39,344:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:39,387:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:39,406:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:39,749:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:39,765:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:39,930:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:40,057:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:40,232:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:41,137:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:41,400:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:41,417:INFO:Calculating mean and std
2024-05-04 15:30:41,419:INFO:Creating metrics dataframe
2024-05-04 15:30:41,424:INFO:Uploading results into container
2024-05-04 15:30:41,424:INFO:Uploading model into container now
2024-05-04 15:30:41,425:INFO:_master_model_container: 16
2024-05-04 15:30:41,425:INFO:_display_container: 3
2024-05-04 15:30:41,425:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-05-04 15:30:41,425:INFO:create_model() successfully completed......................................
2024-05-04 15:30:41,657:INFO:SubProcess create_model() end ==================================
2024-05-04 15:30:41,657:INFO:Creating metrics dataframe
2024-05-04 15:30:41,660:INFO:Initializing Gradient Boosting Classifier
2024-05-04 15:30:41,660:INFO:Total runtime is 0.2130547841389974 minutes
2024-05-04 15:30:41,662:INFO:SubProcess create_model() called ==================================
2024-05-04 15:30:41,662:INFO:Initializing create_model()
2024-05-04 15:30:41,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33656d510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:30:41,662:INFO:Checking exceptions
2024-05-04 15:30:41,662:INFO:Importing libraries
2024-05-04 15:30:41,662:INFO:Copying training dataset
2024-05-04 15:30:41,674:INFO:Defining folds
2024-05-04 15:30:41,674:INFO:Declaring metric variables
2024-05-04 15:30:41,676:INFO:Importing untrained model
2024-05-04 15:30:41,677:INFO:Gradient Boosting Classifier Imported successfully
2024-05-04 15:30:41,680:INFO:Starting cross validation
2024-05-04 15:30:41,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:30:46,136:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:46,139:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:46,153:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:46,156:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:46,392:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:46,395:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:46,396:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:46,398:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:46,495:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:46,504:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:46,683:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:46,686:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:46,904:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:46,908:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:47,125:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:47,127:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:49,836:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:49,838:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:49,880:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:30:49,882:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:30:49,894:INFO:Calculating mean and std
2024-05-04 15:30:49,896:INFO:Creating metrics dataframe
2024-05-04 15:30:49,902:INFO:Uploading results into container
2024-05-04 15:30:49,902:INFO:Uploading model into container now
2024-05-04 15:30:49,903:INFO:_master_model_container: 17
2024-05-04 15:30:49,903:INFO:_display_container: 3
2024-05-04 15:30:49,903:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-04 15:30:49,903:INFO:create_model() successfully completed......................................
2024-05-04 15:30:50,180:INFO:SubProcess create_model() end ==================================
2024-05-04 15:30:50,181:INFO:Creating metrics dataframe
2024-05-04 15:30:50,185:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 15:30:50,185:INFO:Total runtime is 0.35512966712315874 minutes
2024-05-04 15:30:50,186:INFO:SubProcess create_model() called ==================================
2024-05-04 15:30:50,187:INFO:Initializing create_model()
2024-05-04 15:30:50,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33656d510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:30:50,187:INFO:Checking exceptions
2024-05-04 15:30:50,187:INFO:Importing libraries
2024-05-04 15:30:50,187:INFO:Copying training dataset
2024-05-04 15:30:50,199:INFO:Defining folds
2024-05-04 15:30:50,199:INFO:Declaring metric variables
2024-05-04 15:30:50,200:INFO:Importing untrained model
2024-05-04 15:30:50,202:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:30:50,205:INFO:Starting cross validation
2024-05-04 15:30:50,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:30:52,484:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 15:30:52,485:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 15:30:52,485:INFO:Initializing create_model()
2024-05-04 15:30:52,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33656d510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:30:52,486:INFO:Checking exceptions
2024-05-04 15:30:52,486:INFO:Importing libraries
2024-05-04 15:30:52,486:INFO:Copying training dataset
2024-05-04 15:30:52,494:INFO:Defining folds
2024-05-04 15:30:52,494:INFO:Declaring metric variables
2024-05-04 15:30:52,496:INFO:Importing untrained model
2024-05-04 15:30:52,497:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:30:52,500:INFO:Starting cross validation
2024-05-04 15:30:52,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:30:57,419:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 15:30:57,421:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 15:30:57,422:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 15:30:57,427:INFO:Initializing create_model()
2024-05-04 15:30:57,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:30:57,427:INFO:Checking exceptions
2024-05-04 15:30:57,428:INFO:Importing libraries
2024-05-04 15:30:57,429:INFO:Copying training dataset
2024-05-04 15:30:57,439:INFO:Defining folds
2024-05-04 15:30:57,439:INFO:Declaring metric variables
2024-05-04 15:30:57,440:INFO:Importing untrained model
2024-05-04 15:30:57,440:INFO:Declaring custom model
2024-05-04 15:30:57,440:INFO:Decision Tree Classifier Imported successfully
2024-05-04 15:30:57,445:INFO:Cross validation set to False
2024-05-04 15:30:57,445:INFO:Fitting Model
2024-05-04 15:30:58,450:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-05-04 15:30:58,450:INFO:create_model() successfully completed......................................
2024-05-04 15:30:58,671:INFO:_master_model_container: 17
2024-05-04 15:30:58,671:INFO:_display_container: 3
2024-05-04 15:30:58,671:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-05-04 15:30:58,671:INFO:compare_models() successfully completed......................................
2024-05-04 15:31:22,734:INFO:Initializing compare_models()
2024-05-04 15:31:22,734:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-04 15:31:22,735:INFO:Checking exceptions
2024-05-04 15:31:22,739:INFO:Preparing display monitor
2024-05-04 15:31:22,751:INFO:Initializing Logistic Regression
2024-05-04 15:31:22,751:INFO:Total runtime is 3.548463185628255e-06 minutes
2024-05-04 15:31:22,753:INFO:SubProcess create_model() called ==================================
2024-05-04 15:31:22,753:INFO:Initializing create_model()
2024-05-04 15:31:22,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:31:22,753:INFO:Checking exceptions
2024-05-04 15:31:22,754:INFO:Importing libraries
2024-05-04 15:31:22,754:INFO:Copying training dataset
2024-05-04 15:31:22,767:INFO:Defining folds
2024-05-04 15:31:22,767:INFO:Declaring metric variables
2024-05-04 15:31:22,768:INFO:Importing untrained model
2024-05-04 15:31:22,770:INFO:Logistic Regression Imported successfully
2024-05-04 15:31:22,773:INFO:Starting cross validation
2024-05-04 15:31:22,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:31:27,060:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:27,064:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:27,070:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:27,074:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:27,127:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:27,135:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:27,167:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:27,173:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:27,541:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:27,543:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:27,626:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:27,629:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:27,670:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:27,673:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:27,811:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:27,813:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:28,750:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:28,752:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:28,853:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:28,855:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:28,865:INFO:Calculating mean and std
2024-05-04 15:31:28,868:INFO:Creating metrics dataframe
2024-05-04 15:31:28,880:INFO:Uploading results into container
2024-05-04 15:31:28,881:INFO:Uploading model into container now
2024-05-04 15:31:28,882:INFO:_master_model_container: 18
2024-05-04 15:31:28,882:INFO:_display_container: 4
2024-05-04 15:31:28,883:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-04 15:31:28,883:INFO:create_model() successfully completed......................................
2024-05-04 15:31:29,216:INFO:SubProcess create_model() end ==================================
2024-05-04 15:31:29,217:INFO:Creating metrics dataframe
2024-05-04 15:31:29,220:INFO:Initializing K Neighbors Classifier
2024-05-04 15:31:29,220:INFO:Total runtime is 0.10782273213068645 minutes
2024-05-04 15:31:29,222:INFO:SubProcess create_model() called ==================================
2024-05-04 15:31:29,222:INFO:Initializing create_model()
2024-05-04 15:31:29,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:31:29,222:INFO:Checking exceptions
2024-05-04 15:31:29,222:INFO:Importing libraries
2024-05-04 15:31:29,222:INFO:Copying training dataset
2024-05-04 15:31:29,233:INFO:Defining folds
2024-05-04 15:31:29,233:INFO:Declaring metric variables
2024-05-04 15:31:29,235:INFO:Importing untrained model
2024-05-04 15:31:29,237:INFO:K Neighbors Classifier Imported successfully
2024-05-04 15:31:29,240:INFO:Starting cross validation
2024-05-04 15:31:29,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:31:31,278:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:31,280:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:31,432:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:31,481:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:31,746:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:32,308:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:32,584:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:32,969:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:32,982:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:33,079:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:33,089:INFO:Calculating mean and std
2024-05-04 15:31:33,090:INFO:Creating metrics dataframe
2024-05-04 15:31:33,092:INFO:Uploading results into container
2024-05-04 15:31:33,092:INFO:Uploading model into container now
2024-05-04 15:31:33,092:INFO:_master_model_container: 19
2024-05-04 15:31:33,092:INFO:_display_container: 4
2024-05-04 15:31:33,093:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-04 15:31:33,093:INFO:create_model() successfully completed......................................
2024-05-04 15:31:33,313:INFO:SubProcess create_model() end ==================================
2024-05-04 15:31:33,313:INFO:Creating metrics dataframe
2024-05-04 15:31:33,316:INFO:Initializing Naive Bayes
2024-05-04 15:31:33,316:INFO:Total runtime is 0.1760821302731832 minutes
2024-05-04 15:31:33,317:INFO:SubProcess create_model() called ==================================
2024-05-04 15:31:33,318:INFO:Initializing create_model()
2024-05-04 15:31:33,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:31:33,318:INFO:Checking exceptions
2024-05-04 15:31:33,318:INFO:Importing libraries
2024-05-04 15:31:33,318:INFO:Copying training dataset
2024-05-04 15:31:33,328:INFO:Defining folds
2024-05-04 15:31:33,328:INFO:Declaring metric variables
2024-05-04 15:31:33,331:INFO:Importing untrained model
2024-05-04 15:31:33,332:INFO:Naive Bayes Imported successfully
2024-05-04 15:31:33,335:INFO:Starting cross validation
2024-05-04 15:31:33,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:31:35,415:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:35,599:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:35,750:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:35,887:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:35,944:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:36,140:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:36,392:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:36,584:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:37,093:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:37,388:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:37,399:INFO:Calculating mean and std
2024-05-04 15:31:37,401:INFO:Creating metrics dataframe
2024-05-04 15:31:37,405:INFO:Uploading results into container
2024-05-04 15:31:37,406:INFO:Uploading model into container now
2024-05-04 15:31:37,407:INFO:_master_model_container: 20
2024-05-04 15:31:37,407:INFO:_display_container: 4
2024-05-04 15:31:37,407:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-04 15:31:37,407:INFO:create_model() successfully completed......................................
2024-05-04 15:31:37,703:INFO:SubProcess create_model() end ==================================
2024-05-04 15:31:37,703:INFO:Creating metrics dataframe
2024-05-04 15:31:37,707:INFO:Initializing Decision Tree Classifier
2024-05-04 15:31:37,707:INFO:Total runtime is 0.2492697278658549 minutes
2024-05-04 15:31:37,709:INFO:SubProcess create_model() called ==================================
2024-05-04 15:31:37,709:INFO:Initializing create_model()
2024-05-04 15:31:37,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:31:37,709:INFO:Checking exceptions
2024-05-04 15:31:37,709:INFO:Importing libraries
2024-05-04 15:31:37,709:INFO:Copying training dataset
2024-05-04 15:31:37,719:INFO:Defining folds
2024-05-04 15:31:37,719:INFO:Declaring metric variables
2024-05-04 15:31:37,721:INFO:Importing untrained model
2024-05-04 15:31:37,722:INFO:Decision Tree Classifier Imported successfully
2024-05-04 15:31:37,725:INFO:Starting cross validation
2024-05-04 15:31:37,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:31:39,578:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:39,835:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:39,941:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:40,034:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:40,072:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:40,260:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:40,310:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:40,608:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:41,210:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:41,272:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:41,282:INFO:Calculating mean and std
2024-05-04 15:31:41,282:INFO:Creating metrics dataframe
2024-05-04 15:31:41,284:INFO:Uploading results into container
2024-05-04 15:31:41,284:INFO:Uploading model into container now
2024-05-04 15:31:41,284:INFO:_master_model_container: 21
2024-05-04 15:31:41,284:INFO:_display_container: 4
2024-05-04 15:31:41,284:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-05-04 15:31:41,284:INFO:create_model() successfully completed......................................
2024-05-04 15:31:41,487:INFO:SubProcess create_model() end ==================================
2024-05-04 15:31:41,487:INFO:Creating metrics dataframe
2024-05-04 15:31:41,492:INFO:Initializing SVM - Linear Kernel
2024-05-04 15:31:41,492:INFO:Total runtime is 0.3123434503873189 minutes
2024-05-04 15:31:41,494:INFO:SubProcess create_model() called ==================================
2024-05-04 15:31:41,495:INFO:Initializing create_model()
2024-05-04 15:31:41,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:31:41,495:INFO:Checking exceptions
2024-05-04 15:31:41,495:INFO:Importing libraries
2024-05-04 15:31:41,495:INFO:Copying training dataset
2024-05-04 15:31:41,506:INFO:Defining folds
2024-05-04 15:31:41,506:INFO:Declaring metric variables
2024-05-04 15:31:41,508:INFO:Importing untrained model
2024-05-04 15:31:41,510:INFO:SVM - Linear Kernel Imported successfully
2024-05-04 15:31:41,514:INFO:Starting cross validation
2024-05-04 15:31:41,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:31:43,818:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:43,820:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:43,991:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:43,999:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:44,268:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:44,270:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:44,309:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:44,311:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:44,333:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:44,335:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:44,498:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:44,500:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:44,795:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:44,797:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:45,034:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:45,035:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:45,517:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:45,519:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:45,625:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:45,627:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:45,640:INFO:Calculating mean and std
2024-05-04 15:31:45,641:INFO:Creating metrics dataframe
2024-05-04 15:31:45,644:INFO:Uploading results into container
2024-05-04 15:31:45,644:INFO:Uploading model into container now
2024-05-04 15:31:45,644:INFO:_master_model_container: 22
2024-05-04 15:31:45,644:INFO:_display_container: 4
2024-05-04 15:31:45,645:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-04 15:31:45,645:INFO:create_model() successfully completed......................................
2024-05-04 15:31:45,868:INFO:SubProcess create_model() end ==================================
2024-05-04 15:31:45,868:INFO:Creating metrics dataframe
2024-05-04 15:31:45,872:INFO:Initializing Ridge Classifier
2024-05-04 15:31:45,872:INFO:Total runtime is 0.3853477478027344 minutes
2024-05-04 15:31:45,874:INFO:SubProcess create_model() called ==================================
2024-05-04 15:31:45,874:INFO:Initializing create_model()
2024-05-04 15:31:45,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:31:45,874:INFO:Checking exceptions
2024-05-04 15:31:45,874:INFO:Importing libraries
2024-05-04 15:31:45,874:INFO:Copying training dataset
2024-05-04 15:31:45,885:INFO:Defining folds
2024-05-04 15:31:45,886:INFO:Declaring metric variables
2024-05-04 15:31:45,888:INFO:Importing untrained model
2024-05-04 15:31:45,890:INFO:Ridge Classifier Imported successfully
2024-05-04 15:31:45,893:INFO:Starting cross validation
2024-05-04 15:31:45,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:31:47,858:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:47,860:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:47,881:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:47,883:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:48,167:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:48,169:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:48,268:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:48,270:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:48,307:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:48,309:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:48,383:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:48,386:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:48,543:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:48,545:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:48,839:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:48,841:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:49,364:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:49,367:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:49,543:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:49,545:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:49,579:INFO:Calculating mean and std
2024-05-04 15:31:49,582:INFO:Creating metrics dataframe
2024-05-04 15:31:49,589:INFO:Uploading results into container
2024-05-04 15:31:49,589:INFO:Uploading model into container now
2024-05-04 15:31:49,589:INFO:_master_model_container: 23
2024-05-04 15:31:49,589:INFO:_display_container: 4
2024-05-04 15:31:49,589:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-05-04 15:31:49,589:INFO:create_model() successfully completed......................................
2024-05-04 15:31:49,792:INFO:SubProcess create_model() end ==================================
2024-05-04 15:31:49,792:INFO:Creating metrics dataframe
2024-05-04 15:31:49,795:INFO:Initializing Random Forest Classifier
2024-05-04 15:31:49,795:INFO:Total runtime is 0.4507393121719361 minutes
2024-05-04 15:31:49,797:INFO:SubProcess create_model() called ==================================
2024-05-04 15:31:49,797:INFO:Initializing create_model()
2024-05-04 15:31:49,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:31:49,797:INFO:Checking exceptions
2024-05-04 15:31:49,797:INFO:Importing libraries
2024-05-04 15:31:49,797:INFO:Copying training dataset
2024-05-04 15:31:49,807:INFO:Defining folds
2024-05-04 15:31:49,807:INFO:Declaring metric variables
2024-05-04 15:31:49,809:INFO:Importing untrained model
2024-05-04 15:31:49,810:INFO:Random Forest Classifier Imported successfully
2024-05-04 15:31:49,813:INFO:Starting cross validation
2024-05-04 15:31:49,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:31:52,096:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:52,138:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:52,195:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:52,354:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:52,386:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:52,461:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:52,504:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:52,829:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:53,755:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:53,956:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:53,969:INFO:Calculating mean and std
2024-05-04 15:31:53,970:INFO:Creating metrics dataframe
2024-05-04 15:31:53,973:INFO:Uploading results into container
2024-05-04 15:31:53,974:INFO:Uploading model into container now
2024-05-04 15:31:53,974:INFO:_master_model_container: 24
2024-05-04 15:31:53,974:INFO:_display_container: 4
2024-05-04 15:31:53,975:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-05-04 15:31:53,975:INFO:create_model() successfully completed......................................
2024-05-04 15:31:54,201:INFO:SubProcess create_model() end ==================================
2024-05-04 15:31:54,201:INFO:Creating metrics dataframe
2024-05-04 15:31:54,205:INFO:Initializing Quadratic Discriminant Analysis
2024-05-04 15:31:54,205:INFO:Total runtime is 0.5242276827494303 minutes
2024-05-04 15:31:54,206:INFO:SubProcess create_model() called ==================================
2024-05-04 15:31:54,206:INFO:Initializing create_model()
2024-05-04 15:31:54,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:31:54,207:INFO:Checking exceptions
2024-05-04 15:31:54,207:INFO:Importing libraries
2024-05-04 15:31:54,207:INFO:Copying training dataset
2024-05-04 15:31:54,217:INFO:Defining folds
2024-05-04 15:31:54,217:INFO:Declaring metric variables
2024-05-04 15:31:54,219:INFO:Importing untrained model
2024-05-04 15:31:54,220:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-04 15:31:54,223:INFO:Starting cross validation
2024-05-04 15:31:54,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:31:56,046:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:56,241:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:56,264:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:56,267:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:56,479:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:56,481:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:56,515:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:56,602:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:56,694:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:56,697:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:56,782:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:56,826:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:56,828:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:56,859:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:56,966:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:56,968:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:57,056:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:57,058:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:57,180:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:57,285:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:57,347:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:57,349:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:57,431:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:57,433:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:57,960:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:58,008:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:31:58,101:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:58,102:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:58,139:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:31:58,141:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:31:58,157:INFO:Calculating mean and std
2024-05-04 15:31:58,157:INFO:Creating metrics dataframe
2024-05-04 15:31:58,159:INFO:Uploading results into container
2024-05-04 15:31:58,159:INFO:Uploading model into container now
2024-05-04 15:31:58,159:INFO:_master_model_container: 25
2024-05-04 15:31:58,159:INFO:_display_container: 4
2024-05-04 15:31:58,159:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-04 15:31:58,160:INFO:create_model() successfully completed......................................
2024-05-04 15:31:58,361:INFO:SubProcess create_model() end ==================================
2024-05-04 15:31:58,361:INFO:Creating metrics dataframe
2024-05-04 15:31:58,365:INFO:Initializing Ada Boost Classifier
2024-05-04 15:31:58,365:INFO:Total runtime is 0.5935703794161479 minutes
2024-05-04 15:31:58,367:INFO:SubProcess create_model() called ==================================
2024-05-04 15:31:58,367:INFO:Initializing create_model()
2024-05-04 15:31:58,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:31:58,367:INFO:Checking exceptions
2024-05-04 15:31:58,367:INFO:Importing libraries
2024-05-04 15:31:58,367:INFO:Copying training dataset
2024-05-04 15:31:58,378:INFO:Defining folds
2024-05-04 15:31:58,378:INFO:Declaring metric variables
2024-05-04 15:31:58,379:INFO:Importing untrained model
2024-05-04 15:31:58,381:INFO:Ada Boost Classifier Imported successfully
2024-05-04 15:31:58,385:INFO:Starting cross validation
2024-05-04 15:31:58,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:32:00,186:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:00,334:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:00,592:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:00,719:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:00,721:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:00,740:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:00,923:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:00,925:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:00,957:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:01,141:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:01,171:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:01,214:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:01,216:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:01,251:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:01,318:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:01,320:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:01,488:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:01,490:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:01,630:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:01,632:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:01,632:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:01,634:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:01,680:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:01,682:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:02,204:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:02,307:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:32:02,564:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:02,566:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:02,682:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:02,684:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:02,689:INFO:Calculating mean and std
2024-05-04 15:32:02,692:INFO:Creating metrics dataframe
2024-05-04 15:32:02,696:INFO:Uploading results into container
2024-05-04 15:32:02,697:INFO:Uploading model into container now
2024-05-04 15:32:02,697:INFO:_master_model_container: 26
2024-05-04 15:32:02,697:INFO:_display_container: 4
2024-05-04 15:32:02,698:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-05-04 15:32:02,698:INFO:create_model() successfully completed......................................
2024-05-04 15:32:02,968:INFO:SubProcess create_model() end ==================================
2024-05-04 15:32:02,968:INFO:Creating metrics dataframe
2024-05-04 15:32:02,973:INFO:Initializing Gradient Boosting Classifier
2024-05-04 15:32:02,973:INFO:Total runtime is 0.6703592658042907 minutes
2024-05-04 15:32:02,974:INFO:SubProcess create_model() called ==================================
2024-05-04 15:32:02,974:INFO:Initializing create_model()
2024-05-04 15:32:02,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:32:02,974:INFO:Checking exceptions
2024-05-04 15:32:02,975:INFO:Importing libraries
2024-05-04 15:32:02,975:INFO:Copying training dataset
2024-05-04 15:32:02,985:INFO:Defining folds
2024-05-04 15:32:02,985:INFO:Declaring metric variables
2024-05-04 15:32:02,986:INFO:Importing untrained model
2024-05-04 15:32:02,988:INFO:Gradient Boosting Classifier Imported successfully
2024-05-04 15:32:02,991:INFO:Starting cross validation
2024-05-04 15:32:02,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:32:07,668:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:07,670:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:07,726:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:07,729:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:08,042:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:08,044:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:08,168:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:08,171:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:08,208:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:08,210:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:08,379:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:08,381:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:08,491:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:08,493:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:08,587:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:08,589:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:10,856:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:10,858:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:10,868:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:10,869:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:10,877:INFO:Calculating mean and std
2024-05-04 15:32:10,878:INFO:Creating metrics dataframe
2024-05-04 15:32:10,881:INFO:Uploading results into container
2024-05-04 15:32:10,881:INFO:Uploading model into container now
2024-05-04 15:32:10,881:INFO:_master_model_container: 27
2024-05-04 15:32:10,881:INFO:_display_container: 4
2024-05-04 15:32:10,882:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-04 15:32:10,882:INFO:create_model() successfully completed......................................
2024-05-04 15:32:11,120:INFO:SubProcess create_model() end ==================================
2024-05-04 15:32:11,120:INFO:Creating metrics dataframe
2024-05-04 15:32:11,124:INFO:Initializing Linear Discriminant Analysis
2024-05-04 15:32:11,124:INFO:Total runtime is 0.8062176982561746 minutes
2024-05-04 15:32:11,126:INFO:SubProcess create_model() called ==================================
2024-05-04 15:32:11,126:INFO:Initializing create_model()
2024-05-04 15:32:11,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:32:11,126:INFO:Checking exceptions
2024-05-04 15:32:11,126:INFO:Importing libraries
2024-05-04 15:32:11,126:INFO:Copying training dataset
2024-05-04 15:32:11,136:INFO:Defining folds
2024-05-04 15:32:11,136:INFO:Declaring metric variables
2024-05-04 15:32:11,138:INFO:Importing untrained model
2024-05-04 15:32:11,139:INFO:Linear Discriminant Analysis Imported successfully
2024-05-04 15:32:11,142:INFO:Starting cross validation
2024-05-04 15:32:11,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:32:13,285:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:13,292:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:13,513:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:13,515:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:13,555:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:13,559:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:13,774:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:13,777:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:13,832:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:13,833:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:13,964:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:13,966:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:14,153:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:14,156:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:14,318:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:14,319:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:15,058:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:15,059:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:15,174:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:32:15,176:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:15,191:INFO:Calculating mean and std
2024-05-04 15:32:15,191:INFO:Creating metrics dataframe
2024-05-04 15:32:15,193:INFO:Uploading results into container
2024-05-04 15:32:15,193:INFO:Uploading model into container now
2024-05-04 15:32:15,193:INFO:_master_model_container: 28
2024-05-04 15:32:15,193:INFO:_display_container: 4
2024-05-04 15:32:15,193:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-04 15:32:15,193:INFO:create_model() successfully completed......................................
2024-05-04 15:32:15,391:INFO:SubProcess create_model() end ==================================
2024-05-04 15:32:15,391:INFO:Creating metrics dataframe
2024-05-04 15:32:15,395:INFO:Initializing Extra Trees Classifier
2024-05-04 15:32:15,396:INFO:Total runtime is 0.8774106502532958 minutes
2024-05-04 15:32:15,397:INFO:SubProcess create_model() called ==================================
2024-05-04 15:32:15,397:INFO:Initializing create_model()
2024-05-04 15:32:15,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:32:15,397:INFO:Checking exceptions
2024-05-04 15:32:15,397:INFO:Importing libraries
2024-05-04 15:32:15,397:INFO:Copying training dataset
2024-05-04 15:32:15,407:INFO:Defining folds
2024-05-04 15:32:15,408:INFO:Declaring metric variables
2024-05-04 15:32:15,409:INFO:Importing untrained model
2024-05-04 15:32:15,411:INFO:Extra Trees Classifier Imported successfully
2024-05-04 15:32:15,413:INFO:Starting cross validation
2024-05-04 15:32:15,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:32:17,671:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:17,687:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:17,826:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:17,854:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:17,978:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:18,046:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:18,080:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:18,120:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:19,173:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:19,331:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:19,342:INFO:Calculating mean and std
2024-05-04 15:32:19,344:INFO:Creating metrics dataframe
2024-05-04 15:32:19,355:INFO:Uploading results into container
2024-05-04 15:32:19,356:INFO:Uploading model into container now
2024-05-04 15:32:19,356:INFO:_master_model_container: 29
2024-05-04 15:32:19,356:INFO:_display_container: 4
2024-05-04 15:32:19,357:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-05-04 15:32:19,357:INFO:create_model() successfully completed......................................
2024-05-04 15:32:19,620:INFO:SubProcess create_model() end ==================================
2024-05-04 15:32:19,620:INFO:Creating metrics dataframe
2024-05-04 15:32:19,624:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 15:32:19,624:INFO:Total runtime is 0.9478877981503804 minutes
2024-05-04 15:32:19,626:INFO:SubProcess create_model() called ==================================
2024-05-04 15:32:19,626:INFO:Initializing create_model()
2024-05-04 15:32:19,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:32:19,626:INFO:Checking exceptions
2024-05-04 15:32:19,626:INFO:Importing libraries
2024-05-04 15:32:19,626:INFO:Copying training dataset
2024-05-04 15:32:19,636:INFO:Defining folds
2024-05-04 15:32:19,636:INFO:Declaring metric variables
2024-05-04 15:32:19,637:INFO:Importing untrained model
2024-05-04 15:32:19,638:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:32:19,641:INFO:Starting cross validation
2024-05-04 15:32:19,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:32:21,741:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 15:32:21,742:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 15:32:21,743:INFO:Initializing create_model()
2024-05-04 15:32:21,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:32:21,743:INFO:Checking exceptions
2024-05-04 15:32:21,743:INFO:Importing libraries
2024-05-04 15:32:21,743:INFO:Copying training dataset
2024-05-04 15:32:21,751:INFO:Defining folds
2024-05-04 15:32:21,751:INFO:Declaring metric variables
2024-05-04 15:32:21,752:INFO:Importing untrained model
2024-05-04 15:32:21,754:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:32:21,757:INFO:Starting cross validation
2024-05-04 15:32:21,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:32:25,751:WARNING:OMP: Error #179: Function pthread_mutex_init failed:
2024-05-04 15:32:25,752:WARNING:OMP: System error #22: Invalid argument
2024-05-04 15:32:26,531:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 15:32:26,533:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGABRT(-6)}

2024-05-04 15:32:26,533:INFO:Initializing Dummy Classifier
2024-05-04 15:32:26,533:INFO:Total runtime is 1.063025430838267 minutes
2024-05-04 15:32:26,536:INFO:SubProcess create_model() called ==================================
2024-05-04 15:32:26,536:INFO:Initializing create_model()
2024-05-04 15:32:26,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333a3d550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:32:26,536:INFO:Checking exceptions
2024-05-04 15:32:26,536:INFO:Importing libraries
2024-05-04 15:32:26,536:INFO:Copying training dataset
2024-05-04 15:32:26,546:INFO:Defining folds
2024-05-04 15:32:26,546:INFO:Declaring metric variables
2024-05-04 15:32:26,548:INFO:Importing untrained model
2024-05-04 15:32:26,550:INFO:Dummy Classifier Imported successfully
2024-05-04 15:32:26,552:INFO:Starting cross validation
2024-05-04 15:32:26,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:32:30,140:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:30,369:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:30,387:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:30,486:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:30,542:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:30,769:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:30,822:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:31,081:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:31,738:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:31,842:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:32:31,855:INFO:Calculating mean and std
2024-05-04 15:32:31,857:INFO:Creating metrics dataframe
2024-05-04 15:32:31,859:INFO:Uploading results into container
2024-05-04 15:32:31,860:INFO:Uploading model into container now
2024-05-04 15:32:31,860:INFO:_master_model_container: 30
2024-05-04 15:32:31,860:INFO:_display_container: 4
2024-05-04 15:32:31,861:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-05-04 15:32:31,861:INFO:create_model() successfully completed......................................
2024-05-04 15:32:32,073:INFO:SubProcess create_model() end ==================================
2024-05-04 15:32:32,073:INFO:Creating metrics dataframe
2024-05-04 15:32:32,078:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 15:32:32,081:INFO:Initializing create_model()
2024-05-04 15:32:32,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:32:32,082:INFO:Checking exceptions
2024-05-04 15:32:32,082:INFO:Importing libraries
2024-05-04 15:32:32,082:INFO:Copying training dataset
2024-05-04 15:32:32,092:INFO:Defining folds
2024-05-04 15:32:32,092:INFO:Declaring metric variables
2024-05-04 15:32:32,092:INFO:Importing untrained model
2024-05-04 15:32:32,092:INFO:Declaring custom model
2024-05-04 15:32:32,092:INFO:Dummy Classifier Imported successfully
2024-05-04 15:32:32,096:INFO:Cross validation set to False
2024-05-04 15:32:32,097:INFO:Fitting Model
2024-05-04 15:32:33,114:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-05-04 15:32:33,114:INFO:create_model() successfully completed......................................
2024-05-04 15:32:33,318:INFO:Initializing create_model()
2024-05-04 15:32:33,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:32:33,319:INFO:Checking exceptions
2024-05-04 15:32:33,320:INFO:Importing libraries
2024-05-04 15:32:33,320:INFO:Copying training dataset
2024-05-04 15:32:33,329:INFO:Defining folds
2024-05-04 15:32:33,329:INFO:Declaring metric variables
2024-05-04 15:32:33,329:INFO:Importing untrained model
2024-05-04 15:32:33,329:INFO:Declaring custom model
2024-05-04 15:32:33,329:INFO:Ridge Classifier Imported successfully
2024-05-04 15:32:33,332:INFO:Cross validation set to False
2024-05-04 15:32:33,332:INFO:Fitting Model
2024-05-04 15:32:34,341:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-05-04 15:32:34,341:INFO:create_model() successfully completed......................................
2024-05-04 15:32:34,602:INFO:Initializing create_model()
2024-05-04 15:32:34,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x31862fc10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:32:34,602:INFO:Checking exceptions
2024-05-04 15:32:34,603:INFO:Importing libraries
2024-05-04 15:32:34,603:INFO:Copying training dataset
2024-05-04 15:32:34,611:INFO:Defining folds
2024-05-04 15:32:34,611:INFO:Declaring metric variables
2024-05-04 15:32:34,611:INFO:Importing untrained model
2024-05-04 15:32:34,611:INFO:Declaring custom model
2024-05-04 15:32:34,612:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-04 15:32:34,615:INFO:Cross validation set to False
2024-05-04 15:32:34,616:INFO:Fitting Model
2024-05-04 15:32:35,637:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:32:35,720:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-04 15:32:35,720:INFO:create_model() successfully completed......................................
2024-05-04 15:32:35,932:INFO:_master_model_container: 30
2024-05-04 15:32:35,932:INFO:_display_container: 4
2024-05-04 15:32:35,933:INFO:[DummyClassifier(constant=None, random_state=123, strategy='prior'), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)]
2024-05-04 15:32:35,933:INFO:compare_models() successfully completed......................................
2024-05-04 15:35:02,754:INFO:gpu_param set to False
2024-05-04 15:35:02,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:02,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:02,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:02,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:15,728:INFO:PyCaret ClassificationExperiment
2024-05-04 15:35:15,728:INFO:Logging name: iris_experiment
2024-05-04 15:35:15,728:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:35:15,728:INFO:version 3.3.2
2024-05-04 15:35:15,728:INFO:Initializing setup()
2024-05-04 15:35:15,728:INFO:self.USI: de30
2024-05-04 15:35:15,728:INFO:self._variable_keys: {'target_param', 'y', 'y_test', 'logging_param', 'gpu_n_jobs_param', 'fix_imbalance', 'data', 'html_param', 'exp_name_log', 'memory', 'idx', 'pipeline', 'X', 'gpu_param', 'X_train', 'is_multiclass', 'n_jobs_param', 'X_test', 'USI', 'exp_id', 'log_plots_param', 'y_train', 'fold_groups_param', '_ml_usecase', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'seed'}
2024-05-04 15:35:15,728:INFO:Checking environment
2024-05-04 15:35:15,728:INFO:python_version: 3.11.8
2024-05-04 15:35:15,728:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:35:15,728:INFO:machine: arm64
2024-05-04 15:35:15,728:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:35:15,728:INFO:Memory: svmem(total=17179869184, available=4621647872, percent=73.1, used=6571753472, free=42631168, active=4594221056, inactive=4574822400, wired=1977532416)
2024-05-04 15:35:15,729:INFO:Physical Core: 8
2024-05-04 15:35:15,729:INFO:Logical Core: 8
2024-05-04 15:35:15,729:INFO:Checking libraries
2024-05-04 15:35:15,729:INFO:System:
2024-05-04 15:35:15,729:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:35:15,729:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:35:15,729:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:35:15,729:INFO:PyCaret required dependencies:
2024-05-04 15:35:15,729:INFO:                 pip: 24.0
2024-05-04 15:35:15,729:INFO:          setuptools: 69.2.0
2024-05-04 15:35:15,729:INFO:             pycaret: 3.3.2
2024-05-04 15:35:15,729:INFO:             IPython: 8.22.2
2024-05-04 15:35:15,729:INFO:          ipywidgets: 8.1.2
2024-05-04 15:35:15,729:INFO:                tqdm: 4.66.2
2024-05-04 15:35:15,729:INFO:               numpy: 1.26.4
2024-05-04 15:35:15,729:INFO:              pandas: 2.1.4
2024-05-04 15:35:15,729:INFO:              jinja2: 3.1.3
2024-05-04 15:35:15,729:INFO:               scipy: 1.11.4
2024-05-04 15:35:15,729:INFO:              joblib: 1.3.2
2024-05-04 15:35:15,729:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:35:15,729:INFO:                pyod: 1.1.3
2024-05-04 15:35:15,729:INFO:            imblearn: 0.12.2
2024-05-04 15:35:15,729:INFO:   category_encoders: 2.6.3
2024-05-04 15:35:15,729:INFO:            lightgbm: 4.3.0
2024-05-04 15:35:15,729:INFO:               numba: 0.59.1
2024-05-04 15:35:15,729:INFO:            requests: 2.31.0
2024-05-04 15:35:15,729:INFO:          matplotlib: 3.7.5
2024-05-04 15:35:15,729:INFO:          scikitplot: 0.3.7
2024-05-04 15:35:15,729:INFO:         yellowbrick: 1.5
2024-05-04 15:35:15,729:INFO:              plotly: 5.19.0
2024-05-04 15:35:15,729:INFO:    plotly-resampler: Not installed
2024-05-04 15:35:15,729:INFO:             kaleido: 0.2.1
2024-05-04 15:35:15,729:INFO:           schemdraw: 0.15
2024-05-04 15:35:15,729:INFO:         statsmodels: 0.14.1
2024-05-04 15:35:15,729:INFO:              sktime: 0.26.0
2024-05-04 15:35:15,729:INFO:               tbats: 1.1.3
2024-05-04 15:35:15,729:INFO:            pmdarima: 2.0.4
2024-05-04 15:35:15,729:INFO:              psutil: 5.9.8
2024-05-04 15:35:15,729:INFO:          markupsafe: 2.1.5
2024-05-04 15:35:15,729:INFO:             pickle5: Not installed
2024-05-04 15:35:15,729:INFO:         cloudpickle: 3.0.0
2024-05-04 15:35:15,729:INFO:         deprecation: 2.1.0
2024-05-04 15:35:15,729:INFO:              xxhash: 3.4.1
2024-05-04 15:35:15,729:INFO:           wurlitzer: 3.0.3
2024-05-04 15:35:15,729:INFO:PyCaret optional dependencies:
2024-05-04 15:35:15,729:INFO:                shap: 0.44.1
2024-05-04 15:35:15,729:INFO:           interpret: 0.6.1
2024-05-04 15:35:15,729:INFO:                umap: 0.5.6
2024-05-04 15:35:15,729:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:35:15,729:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:35:15,729:INFO:             autoviz: Not installed
2024-05-04 15:35:15,729:INFO:           fairlearn: 0.7.0
2024-05-04 15:35:15,729:INFO:          deepchecks: Not installed
2024-05-04 15:35:15,729:INFO:             xgboost: Not installed
2024-05-04 15:35:15,729:INFO:            catboost: Not installed
2024-05-04 15:35:15,729:INFO:              kmodes: Not installed
2024-05-04 15:35:15,729:INFO:             mlxtend: 0.23.1
2024-05-04 15:35:15,729:INFO:       statsforecast: Not installed
2024-05-04 15:35:15,729:INFO:        tune_sklearn: Not installed
2024-05-04 15:35:15,729:INFO:                 ray: Not installed
2024-05-04 15:35:15,729:INFO:            hyperopt: Not installed
2024-05-04 15:35:15,730:INFO:              optuna: Not installed
2024-05-04 15:35:15,730:INFO:               skopt: Not installed
2024-05-04 15:35:15,730:INFO:              mlflow: 2.12.1
2024-05-04 15:35:15,730:INFO:              gradio: 4.29.0
2024-05-04 15:35:15,730:INFO:             fastapi: 0.111.0
2024-05-04 15:35:15,730:INFO:             uvicorn: 0.29.0
2024-05-04 15:35:15,730:INFO:              m2cgen: 0.10.0
2024-05-04 15:35:15,730:INFO:           evidently: 0.4.20
2024-05-04 15:35:15,730:INFO:               fugue: 0.8.7
2024-05-04 15:35:15,730:INFO:           streamlit: 1.33.0
2024-05-04 15:35:15,730:INFO:             prophet: Not installed
2024-05-04 15:35:15,730:INFO:None
2024-05-04 15:35:15,730:INFO:Set up data.
2024-05-04 15:35:21,419:INFO:PyCaret ClassificationExperiment
2024-05-04 15:35:21,419:INFO:Logging name: iris_experiment
2024-05-04 15:35:21,419:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:35:21,419:INFO:version 3.3.2
2024-05-04 15:35:21,419:INFO:Initializing setup()
2024-05-04 15:35:21,419:INFO:self.USI: d075
2024-05-04 15:35:21,419:INFO:self._variable_keys: {'target_param', 'y', 'y_test', 'logging_param', 'gpu_n_jobs_param', 'fix_imbalance', 'data', 'html_param', 'exp_name_log', 'memory', 'idx', 'pipeline', 'X', 'gpu_param', 'X_train', 'is_multiclass', 'n_jobs_param', 'X_test', 'USI', 'exp_id', 'log_plots_param', 'y_train', 'fold_groups_param', '_ml_usecase', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'seed'}
2024-05-04 15:35:21,419:INFO:Checking environment
2024-05-04 15:35:21,419:INFO:python_version: 3.11.8
2024-05-04 15:35:21,419:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:35:21,419:INFO:machine: arm64
2024-05-04 15:35:21,419:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:35:21,419:INFO:Memory: svmem(total=17179869184, available=4645502976, percent=73.0, used=6660603904, free=30720000, active=4622942208, inactive=4608802816, wired=2037661696)
2024-05-04 15:35:21,419:INFO:Physical Core: 8
2024-05-04 15:35:21,419:INFO:Logical Core: 8
2024-05-04 15:35:21,419:INFO:Checking libraries
2024-05-04 15:35:21,419:INFO:System:
2024-05-04 15:35:21,420:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:35:21,420:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:35:21,420:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:35:21,420:INFO:PyCaret required dependencies:
2024-05-04 15:35:21,420:INFO:                 pip: 24.0
2024-05-04 15:35:21,420:INFO:          setuptools: 69.2.0
2024-05-04 15:35:21,420:INFO:             pycaret: 3.3.2
2024-05-04 15:35:21,420:INFO:             IPython: 8.22.2
2024-05-04 15:35:21,420:INFO:          ipywidgets: 8.1.2
2024-05-04 15:35:21,420:INFO:                tqdm: 4.66.2
2024-05-04 15:35:21,420:INFO:               numpy: 1.26.4
2024-05-04 15:35:21,420:INFO:              pandas: 2.1.4
2024-05-04 15:35:21,420:INFO:              jinja2: 3.1.3
2024-05-04 15:35:21,420:INFO:               scipy: 1.11.4
2024-05-04 15:35:21,420:INFO:              joblib: 1.3.2
2024-05-04 15:35:21,420:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:35:21,420:INFO:                pyod: 1.1.3
2024-05-04 15:35:21,420:INFO:            imblearn: 0.12.2
2024-05-04 15:35:21,420:INFO:   category_encoders: 2.6.3
2024-05-04 15:35:21,420:INFO:            lightgbm: 4.3.0
2024-05-04 15:35:21,420:INFO:               numba: 0.59.1
2024-05-04 15:35:21,420:INFO:            requests: 2.31.0
2024-05-04 15:35:21,420:INFO:          matplotlib: 3.7.5
2024-05-04 15:35:21,420:INFO:          scikitplot: 0.3.7
2024-05-04 15:35:21,420:INFO:         yellowbrick: 1.5
2024-05-04 15:35:21,420:INFO:              plotly: 5.19.0
2024-05-04 15:35:21,420:INFO:    plotly-resampler: Not installed
2024-05-04 15:35:21,420:INFO:             kaleido: 0.2.1
2024-05-04 15:35:21,420:INFO:           schemdraw: 0.15
2024-05-04 15:35:21,420:INFO:         statsmodels: 0.14.1
2024-05-04 15:35:21,420:INFO:              sktime: 0.26.0
2024-05-04 15:35:21,420:INFO:               tbats: 1.1.3
2024-05-04 15:35:21,420:INFO:            pmdarima: 2.0.4
2024-05-04 15:35:21,420:INFO:              psutil: 5.9.8
2024-05-04 15:35:21,420:INFO:          markupsafe: 2.1.5
2024-05-04 15:35:21,420:INFO:             pickle5: Not installed
2024-05-04 15:35:21,420:INFO:         cloudpickle: 3.0.0
2024-05-04 15:35:21,420:INFO:         deprecation: 2.1.0
2024-05-04 15:35:21,420:INFO:              xxhash: 3.4.1
2024-05-04 15:35:21,420:INFO:           wurlitzer: 3.0.3
2024-05-04 15:35:21,420:INFO:PyCaret optional dependencies:
2024-05-04 15:35:21,420:INFO:                shap: 0.44.1
2024-05-04 15:35:21,420:INFO:           interpret: 0.6.1
2024-05-04 15:35:21,420:INFO:                umap: 0.5.6
2024-05-04 15:35:21,420:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:35:21,420:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:35:21,420:INFO:             autoviz: Not installed
2024-05-04 15:35:21,420:INFO:           fairlearn: 0.7.0
2024-05-04 15:35:21,420:INFO:          deepchecks: Not installed
2024-05-04 15:35:21,420:INFO:             xgboost: Not installed
2024-05-04 15:35:21,420:INFO:            catboost: Not installed
2024-05-04 15:35:21,420:INFO:              kmodes: Not installed
2024-05-04 15:35:21,420:INFO:             mlxtend: 0.23.1
2024-05-04 15:35:21,420:INFO:       statsforecast: Not installed
2024-05-04 15:35:21,420:INFO:        tune_sklearn: Not installed
2024-05-04 15:35:21,420:INFO:                 ray: Not installed
2024-05-04 15:35:21,420:INFO:            hyperopt: Not installed
2024-05-04 15:35:21,420:INFO:              optuna: Not installed
2024-05-04 15:35:21,420:INFO:               skopt: Not installed
2024-05-04 15:35:21,420:INFO:              mlflow: 2.12.1
2024-05-04 15:35:21,420:INFO:              gradio: 4.29.0
2024-05-04 15:35:21,420:INFO:             fastapi: 0.111.0
2024-05-04 15:35:21,420:INFO:             uvicorn: 0.29.0
2024-05-04 15:35:21,420:INFO:              m2cgen: 0.10.0
2024-05-04 15:35:21,420:INFO:           evidently: 0.4.20
2024-05-04 15:35:21,420:INFO:               fugue: 0.8.7
2024-05-04 15:35:21,421:INFO:           streamlit: 1.33.0
2024-05-04 15:35:21,421:INFO:             prophet: Not installed
2024-05-04 15:35:21,421:INFO:None
2024-05-04 15:35:21,421:INFO:Set up data.
2024-05-04 15:35:21,882:INFO:Set up folding strategy.
2024-05-04 15:35:21,882:INFO:Set up train/test split.
2024-05-04 15:35:22,054:INFO:Set up index.
2024-05-04 15:35:22,054:INFO:Assigning column types.
2024-05-04 15:35:22,060:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 15:35:22,079:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:35:22,080:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:35:22,092:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:35:22,112:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:35:22,124:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,124:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 15:35:22,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:35:22,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,174:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:35:22,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,186:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-04 15:35:22,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:22,249:INFO:Preparing preprocessing pipeline...
2024-05-04 15:35:22,250:INFO:Set up label encoding.
2024-05-04 15:35:22,250:INFO:Set up simple imputation.
2024-05-04 15:35:22,260:INFO:Set up encoding of categorical features.
2024-05-04 15:35:26,338:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:278: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2024-05-04 15:35:26,341:INFO:Finished creating preprocessing pipeline.
2024-05-04 15:35:26,345:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-04 15:35:26,345:INFO:Creating final display dataframe.
2024-05-04 15:35:29,310:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:111: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2024-05-04 15:35:29,899:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:289: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-04 15:35:32,979:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:289: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-04 15:35:34,169:INFO:Setup _display_container:                     Description              Value
0                    Session id               3917
1                        Target              Class
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape        (8000, 118)
5        Transformed data shape        (8000, 128)
6   Transformed train set shape        (5600, 128)
7    Transformed test set shape        (2400, 128)
8          Categorical features                117
9      Rows with missing values              35.1%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16               Fold Generator    StratifiedKFold
17                  Fold Number                 10
18                     CPU Jobs                 -1
19                      Use GPU              False
20               Log Experiment       MlflowLogger
21              Experiment Name    iris_experiment
22                          USI               d075
2024-05-04 15:35:34,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:34,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:34,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:34,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:34,239:INFO:Logging experiment in loggers
2024-05-04 15:35:34,404:INFO:SubProcess save_model() called ==================================
2024-05-04 15:35:34,412:INFO:Initializing save_model()
2024-05-04 15:35:34,412:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), model_name=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/tmpwceky2c0/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-04 15:35:34,412:INFO:Adding model into prep_pipe
2024-05-04 15:35:34,412:WARNING:Only Model saved as it was a pipeline.
2024-05-04 15:35:34,593:INFO:/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/tmpwceky2c0/Transformation Pipeline.pkl saved in current working directory
2024-05-04 15:35:34,597:INFO:Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-04 15:35:34,597:INFO:save_model() successfully completed......................................
2024-05-04 15:35:34,881:INFO:SubProcess save_model() end ==================================
2024-05-04 15:35:34,903:INFO:setup() successfully completed in 12.82s...............
2024-05-04 15:35:38,958:INFO:PyCaret ClassificationExperiment
2024-05-04 15:35:38,958:INFO:Logging name: test
2024-05-04 15:35:38,958:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-04 15:35:38,958:INFO:version 3.3.2
2024-05-04 15:35:38,958:INFO:Initializing setup()
2024-05-04 15:35:38,958:INFO:self.USI: 8640
2024-05-04 15:35:38,958:INFO:self._variable_keys: {'target_param', 'y', 'y_test', 'logging_param', 'gpu_n_jobs_param', 'fix_imbalance', 'data', 'html_param', 'exp_name_log', 'memory', 'idx', 'pipeline', 'X', 'gpu_param', 'X_train', 'is_multiclass', 'n_jobs_param', 'X_test', 'USI', 'exp_id', 'log_plots_param', 'y_train', 'fold_groups_param', '_ml_usecase', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'seed'}
2024-05-04 15:35:38,958:INFO:Checking environment
2024-05-04 15:35:38,958:INFO:python_version: 3.11.8
2024-05-04 15:35:38,958:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 15:35:38,958:INFO:machine: arm64
2024-05-04 15:35:38,958:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:35:38,958:INFO:Memory: svmem(total=17179869184, available=4681531392, percent=72.7, used=6578012160, free=35454976, active=4664246272, inactive=4578574336, wired=1913765888)
2024-05-04 15:35:38,958:INFO:Physical Core: 8
2024-05-04 15:35:38,958:INFO:Logical Core: 8
2024-05-04 15:35:38,958:INFO:Checking libraries
2024-05-04 15:35:38,958:INFO:System:
2024-05-04 15:35:38,958:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 15:35:38,958:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 15:35:38,958:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 15:35:38,958:INFO:PyCaret required dependencies:
2024-05-04 15:35:38,958:INFO:                 pip: 24.0
2024-05-04 15:35:38,958:INFO:          setuptools: 69.2.0
2024-05-04 15:35:38,958:INFO:             pycaret: 3.3.2
2024-05-04 15:35:38,958:INFO:             IPython: 8.22.2
2024-05-04 15:35:38,958:INFO:          ipywidgets: 8.1.2
2024-05-04 15:35:38,958:INFO:                tqdm: 4.66.2
2024-05-04 15:35:38,958:INFO:               numpy: 1.26.4
2024-05-04 15:35:38,958:INFO:              pandas: 2.1.4
2024-05-04 15:35:38,958:INFO:              jinja2: 3.1.3
2024-05-04 15:35:38,958:INFO:               scipy: 1.11.4
2024-05-04 15:35:38,958:INFO:              joblib: 1.3.2
2024-05-04 15:35:38,958:INFO:             sklearn: 1.4.1.post1
2024-05-04 15:35:38,958:INFO:                pyod: 1.1.3
2024-05-04 15:35:38,958:INFO:            imblearn: 0.12.2
2024-05-04 15:35:38,959:INFO:   category_encoders: 2.6.3
2024-05-04 15:35:38,959:INFO:            lightgbm: 4.3.0
2024-05-04 15:35:38,959:INFO:               numba: 0.59.1
2024-05-04 15:35:38,959:INFO:            requests: 2.31.0
2024-05-04 15:35:38,959:INFO:          matplotlib: 3.7.5
2024-05-04 15:35:38,959:INFO:          scikitplot: 0.3.7
2024-05-04 15:35:38,959:INFO:         yellowbrick: 1.5
2024-05-04 15:35:38,959:INFO:              plotly: 5.19.0
2024-05-04 15:35:38,959:INFO:    plotly-resampler: Not installed
2024-05-04 15:35:38,959:INFO:             kaleido: 0.2.1
2024-05-04 15:35:38,959:INFO:           schemdraw: 0.15
2024-05-04 15:35:38,959:INFO:         statsmodels: 0.14.1
2024-05-04 15:35:38,959:INFO:              sktime: 0.26.0
2024-05-04 15:35:38,959:INFO:               tbats: 1.1.3
2024-05-04 15:35:38,959:INFO:            pmdarima: 2.0.4
2024-05-04 15:35:38,959:INFO:              psutil: 5.9.8
2024-05-04 15:35:38,959:INFO:          markupsafe: 2.1.5
2024-05-04 15:35:38,959:INFO:             pickle5: Not installed
2024-05-04 15:35:38,959:INFO:         cloudpickle: 3.0.0
2024-05-04 15:35:38,959:INFO:         deprecation: 2.1.0
2024-05-04 15:35:38,959:INFO:              xxhash: 3.4.1
2024-05-04 15:35:38,959:INFO:           wurlitzer: 3.0.3
2024-05-04 15:35:38,959:INFO:PyCaret optional dependencies:
2024-05-04 15:35:38,959:INFO:                shap: 0.44.1
2024-05-04 15:35:38,959:INFO:           interpret: 0.6.1
2024-05-04 15:35:38,959:INFO:                umap: 0.5.6
2024-05-04 15:35:38,959:INFO:     ydata_profiling: 4.7.0
2024-05-04 15:35:38,959:INFO:  explainerdashboard: 0.4.7
2024-05-04 15:35:38,959:INFO:             autoviz: Not installed
2024-05-04 15:35:38,959:INFO:           fairlearn: 0.7.0
2024-05-04 15:35:38,959:INFO:          deepchecks: Not installed
2024-05-04 15:35:38,959:INFO:             xgboost: Not installed
2024-05-04 15:35:38,959:INFO:            catboost: Not installed
2024-05-04 15:35:38,959:INFO:              kmodes: Not installed
2024-05-04 15:35:38,959:INFO:             mlxtend: 0.23.1
2024-05-04 15:35:38,959:INFO:       statsforecast: Not installed
2024-05-04 15:35:38,959:INFO:        tune_sklearn: Not installed
2024-05-04 15:35:38,959:INFO:                 ray: Not installed
2024-05-04 15:35:38,959:INFO:            hyperopt: Not installed
2024-05-04 15:35:38,959:INFO:              optuna: Not installed
2024-05-04 15:35:38,959:INFO:               skopt: Not installed
2024-05-04 15:35:38,959:INFO:              mlflow: 2.12.1
2024-05-04 15:35:38,959:INFO:              gradio: 4.29.0
2024-05-04 15:35:38,959:INFO:             fastapi: 0.111.0
2024-05-04 15:35:38,959:INFO:             uvicorn: 0.29.0
2024-05-04 15:35:38,959:INFO:              m2cgen: 0.10.0
2024-05-04 15:35:38,959:INFO:           evidently: 0.4.20
2024-05-04 15:35:38,959:INFO:               fugue: 0.8.7
2024-05-04 15:35:38,959:INFO:           streamlit: 1.33.0
2024-05-04 15:35:38,959:INFO:             prophet: Not installed
2024-05-04 15:35:38,959:INFO:None
2024-05-04 15:35:38,959:INFO:Set up data.
2024-05-04 15:35:39,402:INFO:Set up folding strategy.
2024-05-04 15:35:39,402:INFO:Set up train/test split.
2024-05-04 15:35:39,579:INFO:Set up index.
2024-05-04 15:35:39,579:INFO:Assigning column types.
2024-05-04 15:35:39,585:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 15:35:39,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:35:39,605:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:35:39,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,636:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 15:35:39,637:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:35:39,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,649:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 15:35:39,669:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:35:39,681:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 15:35:39,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,713:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-04 15:35:39,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:39,776:INFO:Preparing preprocessing pipeline...
2024-05-04 15:35:39,778:INFO:Set up label encoding.
2024-05-04 15:35:39,778:INFO:Set up simple imputation.
2024-05-04 15:35:39,788:INFO:Set up encoding of categorical features.
2024-05-04 15:35:43,967:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:278: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2024-05-04 15:35:43,969:INFO:Finished creating preprocessing pipeline.
2024-05-04 15:35:43,973:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-04 15:35:43,973:INFO:Creating final display dataframe.
2024-05-04 15:35:46,900:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:111: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2024-05-04 15:35:47,516:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:289: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-04 15:35:50,837:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pipeline.py:289: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-04 15:35:52,067:INFO:Setup _display_container:                     Description              Value
0                    Session id               7470
1                        Target              Class
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape        (8000, 118)
5        Transformed data shape        (8000, 128)
6   Transformed train set shape        (5600, 128)
7    Transformed test set shape        (2400, 128)
8          Categorical features                117
9      Rows with missing values              35.1%
10                   Preprocess               True
11              Imputation type             simple
12           Numeric imputation               mean
13       Categorical imputation               mode
14     Maximum one-hot encoding                 25
15              Encoding method               None
16               Fold Generator    StratifiedKFold
17                  Fold Number                 10
18                     CPU Jobs                 -1
19                      Use GPU              False
20               Log Experiment       MlflowLogger
21              Experiment Name               test
22                          USI               8640
2024-05-04 15:35:52,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:52,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:52,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:52,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 15:35:52,137:INFO:Logging experiment in loggers
2024-05-04 15:35:52,165:INFO:SubProcess save_model() called ==================================
2024-05-04 15:35:52,172:INFO:Initializing save_model()
2024-05-04 15:35:52,173:INFO:save_model(model=Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), model_name=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/tmpohpcmlvf/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-04 15:35:52,173:INFO:Adding model into prep_pipe
2024-05-04 15:35:52,173:WARNING:Only Model saved as it was a pipeline.
2024-05-04 15:35:52,362:INFO:/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/tmpohpcmlvf/Transformation Pipeline.pkl saved in current working directory
2024-05-04 15:35:52,366:INFO:Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                                    transformer=TargetEncoder(cols=['I1', 'I2',
                                                                    'I3', 'I4',
                                                                    'I5', 'I6',
                                                                    'I7', 'I8',
                                                                    'I9', 'I10',
                                                                    'I11',
                                                                    'I12',
                                                                    'I13',
                                                                    'I14',
                                                                    'I15',
                                                                    'I16',
                                                                    'I17',
                                                                    'I18',
                                                                    'I19',
                                                                    'I20',
                                                                    'I21',
                                                                    'I22',
                                                                    'I23',
                                                                    'I24',
                                                                    'I25',
                                                                    'I26',
                                                                    'I27',
                                                                    'I28',
                                                                    'I29',
                                                                    'I30', ...],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-04 15:35:52,366:INFO:save_model() successfully completed......................................
2024-05-04 15:35:52,577:INFO:SubProcess save_model() end ==================================
2024-05-04 15:35:52,597:INFO:setup() successfully completed in 13.18s...............
2024-05-04 15:35:55,430:INFO:Initializing compare_models()
2024-05-04 15:35:55,430:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-04 15:35:55,430:INFO:Checking exceptions
2024-05-04 15:35:55,438:INFO:Preparing display monitor
2024-05-04 15:35:55,449:INFO:Initializing Logistic Regression
2024-05-04 15:35:55,449:INFO:Total runtime is 2.47955322265625e-06 minutes
2024-05-04 15:35:55,450:INFO:SubProcess create_model() called ==================================
2024-05-04 15:35:55,450:INFO:Initializing create_model()
2024-05-04 15:35:55,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:35:55,451:INFO:Checking exceptions
2024-05-04 15:35:55,451:INFO:Importing libraries
2024-05-04 15:35:55,451:INFO:Copying training dataset
2024-05-04 15:35:55,461:INFO:Defining folds
2024-05-04 15:35:55,461:INFO:Declaring metric variables
2024-05-04 15:35:55,463:INFO:Importing untrained model
2024-05-04 15:35:55,465:INFO:Logistic Regression Imported successfully
2024-05-04 15:35:55,468:INFO:Starting cross validation
2024-05-04 15:35:55,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:35:57,634:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:57,637:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:57,946:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:57,949:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:58,252:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:58,255:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:58,373:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:58,375:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:58,548:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:58,552:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:58,570:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:58,573:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:58,624:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:58,626:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:58,917:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:58,919:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:59,432:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:59,433:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:59,659:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:35:59,661:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:35:59,669:INFO:Calculating mean and std
2024-05-04 15:35:59,671:INFO:Creating metrics dataframe
2024-05-04 15:35:59,675:INFO:Uploading results into container
2024-05-04 15:35:59,676:INFO:Uploading model into container now
2024-05-04 15:35:59,676:INFO:_master_model_container: 1
2024-05-04 15:35:59,676:INFO:_display_container: 2
2024-05-04 15:35:59,677:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7470, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-04 15:35:59,677:INFO:create_model() successfully completed......................................
2024-05-04 15:35:59,969:INFO:SubProcess create_model() end ==================================
2024-05-04 15:35:59,969:INFO:Creating metrics dataframe
2024-05-04 15:35:59,973:INFO:Initializing K Neighbors Classifier
2024-05-04 15:35:59,973:INFO:Total runtime is 0.07540296316146851 minutes
2024-05-04 15:35:59,974:INFO:SubProcess create_model() called ==================================
2024-05-04 15:35:59,974:INFO:Initializing create_model()
2024-05-04 15:35:59,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:35:59,975:INFO:Checking exceptions
2024-05-04 15:35:59,975:INFO:Importing libraries
2024-05-04 15:35:59,975:INFO:Copying training dataset
2024-05-04 15:35:59,985:INFO:Defining folds
2024-05-04 15:35:59,985:INFO:Declaring metric variables
2024-05-04 15:35:59,987:INFO:Importing untrained model
2024-05-04 15:35:59,989:INFO:K Neighbors Classifier Imported successfully
2024-05-04 15:35:59,992:INFO:Starting cross validation
2024-05-04 15:35:59,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:02,254:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:02,362:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:02,560:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:02,697:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:02,805:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:02,916:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:03,551:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:03,942:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:04,419:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:04,792:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:04,798:INFO:Calculating mean and std
2024-05-04 15:36:04,799:INFO:Creating metrics dataframe
2024-05-04 15:36:04,801:INFO:Uploading results into container
2024-05-04 15:36:04,802:INFO:Uploading model into container now
2024-05-04 15:36:04,802:INFO:_master_model_container: 2
2024-05-04 15:36:04,802:INFO:_display_container: 2
2024-05-04 15:36:04,802:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-04 15:36:04,802:INFO:create_model() successfully completed......................................
2024-05-04 15:36:05,019:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:05,019:INFO:Creating metrics dataframe
2024-05-04 15:36:05,023:INFO:Initializing Naive Bayes
2024-05-04 15:36:05,023:INFO:Total runtime is 0.15957430203755696 minutes
2024-05-04 15:36:05,025:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:05,025:INFO:Initializing create_model()
2024-05-04 15:36:05,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:05,025:INFO:Checking exceptions
2024-05-04 15:36:05,025:INFO:Importing libraries
2024-05-04 15:36:05,025:INFO:Copying training dataset
2024-05-04 15:36:05,034:INFO:Defining folds
2024-05-04 15:36:05,035:INFO:Declaring metric variables
2024-05-04 15:36:05,036:INFO:Importing untrained model
2024-05-04 15:36:05,037:INFO:Naive Bayes Imported successfully
2024-05-04 15:36:05,040:INFO:Starting cross validation
2024-05-04 15:36:05,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:06,994:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:07,061:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:07,250:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:07,303:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:07,384:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:07,477:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:07,690:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:07,848:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:08,449:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:08,571:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:08,577:INFO:Calculating mean and std
2024-05-04 15:36:08,577:INFO:Creating metrics dataframe
2024-05-04 15:36:08,579:INFO:Uploading results into container
2024-05-04 15:36:08,579:INFO:Uploading model into container now
2024-05-04 15:36:08,579:INFO:_master_model_container: 3
2024-05-04 15:36:08,579:INFO:_display_container: 2
2024-05-04 15:36:08,579:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-04 15:36:08,579:INFO:create_model() successfully completed......................................
2024-05-04 15:36:08,844:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:08,844:INFO:Creating metrics dataframe
2024-05-04 15:36:08,848:INFO:Initializing Decision Tree Classifier
2024-05-04 15:36:08,848:INFO:Total runtime is 0.22332741419474283 minutes
2024-05-04 15:36:08,850:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:08,850:INFO:Initializing create_model()
2024-05-04 15:36:08,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:08,850:INFO:Checking exceptions
2024-05-04 15:36:08,850:INFO:Importing libraries
2024-05-04 15:36:08,850:INFO:Copying training dataset
2024-05-04 15:36:08,860:INFO:Defining folds
2024-05-04 15:36:08,860:INFO:Declaring metric variables
2024-05-04 15:36:08,862:INFO:Importing untrained model
2024-05-04 15:36:08,864:INFO:Decision Tree Classifier Imported successfully
2024-05-04 15:36:08,866:INFO:Starting cross validation
2024-05-04 15:36:08,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:10,841:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:10,876:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:11,167:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:11,179:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:11,295:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:11,326:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:11,607:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:11,701:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:12,313:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:12,512:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:12,517:INFO:Calculating mean and std
2024-05-04 15:36:12,518:INFO:Creating metrics dataframe
2024-05-04 15:36:12,521:INFO:Uploading results into container
2024-05-04 15:36:12,521:INFO:Uploading model into container now
2024-05-04 15:36:12,521:INFO:_master_model_container: 4
2024-05-04 15:36:12,521:INFO:_display_container: 2
2024-05-04 15:36:12,522:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 15:36:12,522:INFO:create_model() successfully completed......................................
2024-05-04 15:36:12,750:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:12,750:INFO:Creating metrics dataframe
2024-05-04 15:36:12,758:INFO:Initializing SVM - Linear Kernel
2024-05-04 15:36:12,758:INFO:Total runtime is 0.2884859959284465 minutes
2024-05-04 15:36:12,760:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:12,760:INFO:Initializing create_model()
2024-05-04 15:36:12,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:12,760:INFO:Checking exceptions
2024-05-04 15:36:12,760:INFO:Importing libraries
2024-05-04 15:36:12,760:INFO:Copying training dataset
2024-05-04 15:36:12,772:INFO:Defining folds
2024-05-04 15:36:12,772:INFO:Declaring metric variables
2024-05-04 15:36:12,775:INFO:Importing untrained model
2024-05-04 15:36:12,778:INFO:SVM - Linear Kernel Imported successfully
2024-05-04 15:36:12,781:INFO:Starting cross validation
2024-05-04 15:36:12,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:14,775:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:14,777:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:14,912:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:14,922:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:14,968:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:14,972:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:15,002:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:15,004:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:15,288:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:15,290:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:15,430:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:15,432:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:15,504:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:15,507:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:15,711:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:15,713:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:16,352:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:16,354:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:16,508:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:16,510:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:16,522:INFO:Calculating mean and std
2024-05-04 15:36:16,523:INFO:Creating metrics dataframe
2024-05-04 15:36:16,524:INFO:Uploading results into container
2024-05-04 15:36:16,524:INFO:Uploading model into container now
2024-05-04 15:36:16,524:INFO:_master_model_container: 5
2024-05-04 15:36:16,524:INFO:_display_container: 2
2024-05-04 15:36:16,524:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7470, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-04 15:36:16,524:INFO:create_model() successfully completed......................................
2024-05-04 15:36:16,782:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:16,782:INFO:Creating metrics dataframe
2024-05-04 15:36:16,786:INFO:Initializing Ridge Classifier
2024-05-04 15:36:16,786:INFO:Total runtime is 0.3556325991948446 minutes
2024-05-04 15:36:16,788:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:16,788:INFO:Initializing create_model()
2024-05-04 15:36:16,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:16,788:INFO:Checking exceptions
2024-05-04 15:36:16,789:INFO:Importing libraries
2024-05-04 15:36:16,789:INFO:Copying training dataset
2024-05-04 15:36:16,798:INFO:Defining folds
2024-05-04 15:36:16,798:INFO:Declaring metric variables
2024-05-04 15:36:16,800:INFO:Importing untrained model
2024-05-04 15:36:16,802:INFO:Ridge Classifier Imported successfully
2024-05-04 15:36:16,805:INFO:Starting cross validation
2024-05-04 15:36:16,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:18,603:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:18,605:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:18,720:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:18,722:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:18,915:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:18,916:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:18,922:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:18,924:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:19,083:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:19,086:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:19,139:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:19,141:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:19,321:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:19,322:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:19,680:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:19,681:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:20,103:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:20,105:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:20,270:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:20,272:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:20,275:INFO:Calculating mean and std
2024-05-04 15:36:20,276:INFO:Creating metrics dataframe
2024-05-04 15:36:20,277:INFO:Uploading results into container
2024-05-04 15:36:20,277:INFO:Uploading model into container now
2024-05-04 15:36:20,277:INFO:_master_model_container: 6
2024-05-04 15:36:20,277:INFO:_display_container: 2
2024-05-04 15:36:20,278:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7470, solver='auto',
                tol=0.0001)
2024-05-04 15:36:20,278:INFO:create_model() successfully completed......................................
2024-05-04 15:36:20,470:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:20,470:INFO:Creating metrics dataframe
2024-05-04 15:36:20,474:INFO:Initializing Random Forest Classifier
2024-05-04 15:36:20,474:INFO:Total runtime is 0.4170935312906901 minutes
2024-05-04 15:36:20,475:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:20,476:INFO:Initializing create_model()
2024-05-04 15:36:20,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:20,476:INFO:Checking exceptions
2024-05-04 15:36:20,476:INFO:Importing libraries
2024-05-04 15:36:20,476:INFO:Copying training dataset
2024-05-04 15:36:20,486:INFO:Defining folds
2024-05-04 15:36:20,486:INFO:Declaring metric variables
2024-05-04 15:36:20,487:INFO:Importing untrained model
2024-05-04 15:36:20,489:INFO:Random Forest Classifier Imported successfully
2024-05-04 15:36:20,491:INFO:Starting cross validation
2024-05-04 15:36:20,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:22,701:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:22,764:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:22,886:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:23,013:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:23,022:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:23,108:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:23,212:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:23,220:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:24,241:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:24,387:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:24,398:INFO:Calculating mean and std
2024-05-04 15:36:24,400:INFO:Creating metrics dataframe
2024-05-04 15:36:24,402:INFO:Uploading results into container
2024-05-04 15:36:24,402:INFO:Uploading model into container now
2024-05-04 15:36:24,403:INFO:_master_model_container: 7
2024-05-04 15:36:24,403:INFO:_display_container: 2
2024-05-04 15:36:24,403:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7470, verbose=0,
                       warm_start=False)
2024-05-04 15:36:24,403:INFO:create_model() successfully completed......................................
2024-05-04 15:36:24,610:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:24,610:INFO:Creating metrics dataframe
2024-05-04 15:36:24,614:INFO:Initializing Quadratic Discriminant Analysis
2024-05-04 15:36:24,614:INFO:Total runtime is 0.48608609835306804 minutes
2024-05-04 15:36:24,615:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:24,615:INFO:Initializing create_model()
2024-05-04 15:36:24,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:24,615:INFO:Checking exceptions
2024-05-04 15:36:24,615:INFO:Importing libraries
2024-05-04 15:36:24,616:INFO:Copying training dataset
2024-05-04 15:36:24,625:INFO:Defining folds
2024-05-04 15:36:24,625:INFO:Declaring metric variables
2024-05-04 15:36:24,627:INFO:Importing untrained model
2024-05-04 15:36:24,628:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-04 15:36:24,631:INFO:Starting cross validation
2024-05-04 15:36:24,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:26,414:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:26,417:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:26,588:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:26,590:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:26,637:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:26,639:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:26,660:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:26,720:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:26,844:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:26,846:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:26,915:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:26,918:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:27,012:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:27,035:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:27,130:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:27,165:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:27,167:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:27,174:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:27,185:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:27,277:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:27,279:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:27,318:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:27,320:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:27,966:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:28,097:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:28,098:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:28,135:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 15:36:28,264:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:28,266:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:28,279:INFO:Calculating mean and std
2024-05-04 15:36:28,280:INFO:Creating metrics dataframe
2024-05-04 15:36:28,282:INFO:Uploading results into container
2024-05-04 15:36:28,282:INFO:Uploading model into container now
2024-05-04 15:36:28,282:INFO:_master_model_container: 8
2024-05-04 15:36:28,282:INFO:_display_container: 2
2024-05-04 15:36:28,282:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-04 15:36:28,282:INFO:create_model() successfully completed......................................
2024-05-04 15:36:28,537:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:28,537:INFO:Creating metrics dataframe
2024-05-04 15:36:28,542:INFO:Initializing Ada Boost Classifier
2024-05-04 15:36:28,542:INFO:Total runtime is 0.551554532845815 minutes
2024-05-04 15:36:28,544:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:28,544:INFO:Initializing create_model()
2024-05-04 15:36:28,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:28,544:INFO:Checking exceptions
2024-05-04 15:36:28,544:INFO:Importing libraries
2024-05-04 15:36:28,544:INFO:Copying training dataset
2024-05-04 15:36:28,555:INFO:Defining folds
2024-05-04 15:36:28,555:INFO:Declaring metric variables
2024-05-04 15:36:28,559:INFO:Importing untrained model
2024-05-04 15:36:28,561:INFO:Ada Boost Classifier Imported successfully
2024-05-04 15:36:28,565:INFO:Starting cross validation
2024-05-04 15:36:28,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:30,167:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:30,379:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:30,584:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:30,668:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:30,710:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:30,741:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:30,743:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:30,928:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:30,931:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:30,941:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:31,132:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:31,134:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:31,176:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:31,215:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:31,217:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:31,236:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:31,255:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:31,257:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:31,411:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:31,413:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:31,587:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:31,589:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:31,638:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:31,640:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:32,167:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:32,293:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 15:36:32,518:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:32,519:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:32,657:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:32,659:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:32,672:INFO:Calculating mean and std
2024-05-04 15:36:32,673:INFO:Creating metrics dataframe
2024-05-04 15:36:32,674:INFO:Uploading results into container
2024-05-04 15:36:32,674:INFO:Uploading model into container now
2024-05-04 15:36:32,675:INFO:_master_model_container: 9
2024-05-04 15:36:32,675:INFO:_display_container: 2
2024-05-04 15:36:32,675:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7470)
2024-05-04 15:36:32,675:INFO:create_model() successfully completed......................................
2024-05-04 15:36:32,872:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:32,872:INFO:Creating metrics dataframe
2024-05-04 15:36:32,876:INFO:Initializing Gradient Boosting Classifier
2024-05-04 15:36:32,876:INFO:Total runtime is 0.6237921317418417 minutes
2024-05-04 15:36:32,877:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:32,878:INFO:Initializing create_model()
2024-05-04 15:36:32,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:32,878:INFO:Checking exceptions
2024-05-04 15:36:32,878:INFO:Importing libraries
2024-05-04 15:36:32,878:INFO:Copying training dataset
2024-05-04 15:36:32,887:INFO:Defining folds
2024-05-04 15:36:32,887:INFO:Declaring metric variables
2024-05-04 15:36:32,889:INFO:Importing untrained model
2024-05-04 15:36:32,890:INFO:Gradient Boosting Classifier Imported successfully
2024-05-04 15:36:32,893:INFO:Starting cross validation
2024-05-04 15:36:32,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:36,866:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:36,868:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:36,911:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:36,912:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:36,933:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:36,942:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:37,078:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:37,080:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:37,220:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:37,222:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:37,291:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:37,292:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:37,380:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:37,382:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:37,441:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:37,442:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:39,781:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:39,783:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:39,803:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:39,805:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:39,815:INFO:Calculating mean and std
2024-05-04 15:36:39,817:INFO:Creating metrics dataframe
2024-05-04 15:36:39,821:INFO:Uploading results into container
2024-05-04 15:36:39,821:INFO:Uploading model into container now
2024-05-04 15:36:39,822:INFO:_master_model_container: 10
2024-05-04 15:36:39,822:INFO:_display_container: 2
2024-05-04 15:36:39,823:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7470, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-04 15:36:39,823:INFO:create_model() successfully completed......................................
2024-05-04 15:36:40,060:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:40,060:INFO:Creating metrics dataframe
2024-05-04 15:36:40,064:INFO:Initializing Linear Discriminant Analysis
2024-05-04 15:36:40,064:INFO:Total runtime is 0.7435984333356221 minutes
2024-05-04 15:36:40,066:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:40,066:INFO:Initializing create_model()
2024-05-04 15:36:40,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:40,066:INFO:Checking exceptions
2024-05-04 15:36:40,066:INFO:Importing libraries
2024-05-04 15:36:40,066:INFO:Copying training dataset
2024-05-04 15:36:40,075:INFO:Defining folds
2024-05-04 15:36:40,075:INFO:Declaring metric variables
2024-05-04 15:36:40,076:INFO:Importing untrained model
2024-05-04 15:36:40,077:INFO:Linear Discriminant Analysis Imported successfully
2024-05-04 15:36:40,080:INFO:Starting cross validation
2024-05-04 15:36:40,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:42,035:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:42,037:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:42,145:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:42,149:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:42,332:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:42,334:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:42,548:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:42,550:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:42,553:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:42,555:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:42,683:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:42,685:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:42,725:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:42,727:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:42,892:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:42,894:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:43,648:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:43,650:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:43,736:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 15:36:43,738:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:43,752:INFO:Calculating mean and std
2024-05-04 15:36:43,753:INFO:Creating metrics dataframe
2024-05-04 15:36:43,754:INFO:Uploading results into container
2024-05-04 15:36:43,754:INFO:Uploading model into container now
2024-05-04 15:36:43,755:INFO:_master_model_container: 11
2024-05-04 15:36:43,755:INFO:_display_container: 2
2024-05-04 15:36:43,755:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-04 15:36:43,755:INFO:create_model() successfully completed......................................
2024-05-04 15:36:44,014:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:44,014:INFO:Creating metrics dataframe
2024-05-04 15:36:44,018:INFO:Initializing Extra Trees Classifier
2024-05-04 15:36:44,019:INFO:Total runtime is 0.8095011830329895 minutes
2024-05-04 15:36:44,020:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:44,020:INFO:Initializing create_model()
2024-05-04 15:36:44,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:44,020:INFO:Checking exceptions
2024-05-04 15:36:44,020:INFO:Importing libraries
2024-05-04 15:36:44,020:INFO:Copying training dataset
2024-05-04 15:36:44,031:INFO:Defining folds
2024-05-04 15:36:44,031:INFO:Declaring metric variables
2024-05-04 15:36:44,033:INFO:Importing untrained model
2024-05-04 15:36:44,034:INFO:Extra Trees Classifier Imported successfully
2024-05-04 15:36:44,037:INFO:Starting cross validation
2024-05-04 15:36:44,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:46,214:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:46,391:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:46,453:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:46,643:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:46,674:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:46,736:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:46,782:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:46,783:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:47,710:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:47,862:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:47,866:INFO:Calculating mean and std
2024-05-04 15:36:47,867:INFO:Creating metrics dataframe
2024-05-04 15:36:47,869:INFO:Uploading results into container
2024-05-04 15:36:47,869:INFO:Uploading model into container now
2024-05-04 15:36:47,869:INFO:_master_model_container: 12
2024-05-04 15:36:47,869:INFO:_display_container: 2
2024-05-04 15:36:47,870:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7470, verbose=0,
                     warm_start=False)
2024-05-04 15:36:47,870:INFO:create_model() successfully completed......................................
2024-05-04 15:36:48,069:INFO:SubProcess create_model() end ==================================
2024-05-04 15:36:48,069:INFO:Creating metrics dataframe
2024-05-04 15:36:48,074:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 15:36:48,074:INFO:Total runtime is 0.8770925521850585 minutes
2024-05-04 15:36:48,075:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:48,076:INFO:Initializing create_model()
2024-05-04 15:36:48,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:48,076:INFO:Checking exceptions
2024-05-04 15:36:48,076:INFO:Importing libraries
2024-05-04 15:36:48,076:INFO:Copying training dataset
2024-05-04 15:36:48,086:INFO:Defining folds
2024-05-04 15:36:48,086:INFO:Declaring metric variables
2024-05-04 15:36:48,087:INFO:Importing untrained model
2024-05-04 15:36:48,089:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:36:48,092:INFO:Starting cross validation
2024-05-04 15:36:48,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:50,251:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 15:36:50,252:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 15:36:50,252:INFO:Initializing create_model()
2024-05-04 15:36:50,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:50,252:INFO:Checking exceptions
2024-05-04 15:36:50,252:INFO:Importing libraries
2024-05-04 15:36:50,252:INFO:Copying training dataset
2024-05-04 15:36:50,261:INFO:Defining folds
2024-05-04 15:36:50,261:INFO:Declaring metric variables
2024-05-04 15:36:50,263:INFO:Importing untrained model
2024-05-04 15:36:50,264:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 15:36:50,267:INFO:Starting cross validation
2024-05-04 15:36:50,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:54,903:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 15:36:54,905:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 15:36:54,905:INFO:Initializing Dummy Classifier
2024-05-04 15:36:54,905:INFO:Total runtime is 0.9909413297971089 minutes
2024-05-04 15:36:54,908:INFO:SubProcess create_model() called ==================================
2024-05-04 15:36:54,908:INFO:Initializing create_model()
2024-05-04 15:36:54,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31e29edd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:36:54,908:INFO:Checking exceptions
2024-05-04 15:36:54,908:INFO:Importing libraries
2024-05-04 15:36:54,908:INFO:Copying training dataset
2024-05-04 15:36:54,918:INFO:Defining folds
2024-05-04 15:36:54,918:INFO:Declaring metric variables
2024-05-04 15:36:54,920:INFO:Importing untrained model
2024-05-04 15:36:54,921:INFO:Dummy Classifier Imported successfully
2024-05-04 15:36:54,923:INFO:Starting cross validation
2024-05-04 15:36:54,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 15:36:58,492:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:58,496:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:58,628:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:58,659:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:58,715:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:58,988:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:59,041:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:36:59,271:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:37:00,007:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:37:00,116:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:37:00,130:INFO:Calculating mean and std
2024-05-04 15:37:00,132:INFO:Creating metrics dataframe
2024-05-04 15:37:00,135:INFO:Uploading results into container
2024-05-04 15:37:00,135:INFO:Uploading model into container now
2024-05-04 15:37:00,136:INFO:_master_model_container: 13
2024-05-04 15:37:00,136:INFO:_display_container: 2
2024-05-04 15:37:00,136:INFO:DummyClassifier(constant=None, random_state=7470, strategy='prior')
2024-05-04 15:37:00,136:INFO:create_model() successfully completed......................................
2024-05-04 15:37:00,351:INFO:SubProcess create_model() end ==================================
2024-05-04 15:37:00,351:INFO:Creating metrics dataframe
2024-05-04 15:37:00,356:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 15:37:00,359:INFO:Initializing create_model()
2024-05-04 15:37:00,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7470, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 15:37:00,359:INFO:Checking exceptions
2024-05-04 15:37:00,360:INFO:Importing libraries
2024-05-04 15:37:00,360:INFO:Copying training dataset
2024-05-04 15:37:00,369:INFO:Defining folds
2024-05-04 15:37:00,369:INFO:Declaring metric variables
2024-05-04 15:37:00,369:INFO:Importing untrained model
2024-05-04 15:37:00,369:INFO:Declaring custom model
2024-05-04 15:37:00,369:INFO:Ridge Classifier Imported successfully
2024-05-04 15:37:00,374:INFO:Cross validation set to False
2024-05-04 15:37:00,374:INFO:Fitting Model
2024-05-04 15:37:01,399:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7470, solver='auto',
                tol=0.0001)
2024-05-04 15:37:01,399:INFO:create_model() successfully completed......................................
2024-05-04 15:37:01,666:INFO:Creating Dashboard logs
2024-05-04 15:37:01,668:INFO:Model: Ridge Classifier
2024-05-04 15:37:01,682:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 7470, 'solver': 'auto', 'tol': 0.0001}
2024-05-04 15:37:01,707:INFO:Initializing predict_model()
2024-05-04 15:37:01,707:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7470, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x31eed9e40>)
2024-05-04 15:37:01,707:INFO:Checking exceptions
2024-05-04 15:37:01,707:INFO:Preloading libraries
2024-05-04 15:37:02,919:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 15:37:02,921:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 15:37:03,125:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-05-04 15:37:04,237:INFO:Creating Dashboard logs
2024-05-04 15:37:04,239:INFO:Model: Dummy Classifier
2024-05-04 15:37:04,251:INFO:Logged params: {'constant': None, 'random_state': 7470, 'strategy': 'prior'}
2024-05-04 15:37:04,620:INFO:Creating Dashboard logs
2024-05-04 15:37:04,621:INFO:Model: Quadratic Discriminant Analysis
2024-05-04 15:37:04,633:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-05-04 15:37:05,001:INFO:Creating Dashboard logs
2024-05-04 15:37:05,003:INFO:Model: SVM - Linear Kernel
2024-05-04 15:37:05,014:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 7470, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-04 15:37:05,390:INFO:Creating Dashboard logs
2024-05-04 15:37:05,392:INFO:Model: Gradient Boosting Classifier
2024-05-04 15:37:05,404:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 7470, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-05-04 15:37:05,776:INFO:Creating Dashboard logs
2024-05-04 15:37:05,777:INFO:Model: Logistic Regression
2024-05-04 15:37:05,789:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 7470, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-04 15:37:06,171:INFO:Creating Dashboard logs
2024-05-04 15:37:06,172:INFO:Model: K Neighbors Classifier
2024-05-04 15:37:06,184:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-05-04 15:37:06,557:INFO:Creating Dashboard logs
2024-05-04 15:37:06,558:INFO:Model: Naive Bayes
2024-05-04 15:37:06,570:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-05-04 15:37:06,932:INFO:Creating Dashboard logs
2024-05-04 15:37:06,934:INFO:Model: Decision Tree Classifier
2024-05-04 15:37:06,946:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 7470, 'splitter': 'best'}
2024-05-04 15:37:07,320:INFO:Creating Dashboard logs
2024-05-04 15:37:07,322:INFO:Model: Random Forest Classifier
2024-05-04 15:37:07,333:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7470, 'verbose': 0, 'warm_start': False}
2024-05-04 15:37:07,714:INFO:Creating Dashboard logs
2024-05-04 15:37:07,715:INFO:Model: Ada Boost Classifier
2024-05-04 15:37:07,728:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 7470}
2024-05-04 15:37:08,094:INFO:Creating Dashboard logs
2024-05-04 15:37:08,096:INFO:Model: Linear Discriminant Analysis
2024-05-04 15:37:08,135:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-05-04 15:37:08,505:INFO:Creating Dashboard logs
2024-05-04 15:37:08,507:INFO:Model: Extra Trees Classifier
2024-05-04 15:37:08,518:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 7470, 'verbose': 0, 'warm_start': False}
2024-05-04 15:37:08,904:INFO:_master_model_container: 13
2024-05-04 15:37:08,904:INFO:_display_container: 2
2024-05-04 15:37:08,905:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7470, solver='auto',
                tol=0.0001)
2024-05-04 15:37:08,905:INFO:compare_models() successfully completed......................................
2024-05-04 16:39:17,391:INFO:gpu_param set to False
2024-05-04 16:39:17,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 16:39:17,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 16:39:17,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 16:39:17,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 16:39:22,515:INFO:Initializing create_model()
2024-05-04 16:39:22,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:39:22,515:INFO:Checking exceptions
2024-05-04 16:39:22,528:INFO:Importing libraries
2024-05-04 16:39:22,528:INFO:Copying training dataset
2024-05-04 16:39:22,544:INFO:Defining folds
2024-05-04 16:39:22,545:INFO:Declaring metric variables
2024-05-04 16:39:22,546:INFO:Importing untrained model
2024-05-04 16:39:22,548:INFO:Logistic Regression Imported successfully
2024-05-04 16:39:22,551:INFO:Starting cross validation
2024-05-04 16:39:22,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:39:27,312:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:27,316:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:27,354:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:27,357:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:27,380:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:27,383:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:27,427:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:27,428:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:27,429:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:27,430:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:27,576:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:27,578:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:27,773:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:27,775:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:27,806:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:27,809:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:29,199:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:29,201:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:29,272:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:29,274:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:29,280:INFO:Calculating mean and std
2024-05-04 16:39:29,283:INFO:Creating metrics dataframe
2024-05-04 16:39:29,290:INFO:Finalizing model
2024-05-04 16:39:30,699:INFO:Creating Dashboard logs
2024-05-04 16:39:30,701:INFO:Model: Logistic Regression
2024-05-04 16:39:30,715:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 7470, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-04 16:39:30,752:INFO:Initializing predict_model()
2024-05-04 16:39:30,752:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7470, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318f41f80>)
2024-05-04 16:39:30,752:INFO:Checking exceptions
2024-05-04 16:39:30,752:INFO:Preloading libraries
2024-05-04 16:39:32,058:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:39:32,060:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:32,744:INFO:Uploading results into container
2024-05-04 16:39:32,744:INFO:Uploading model into container now
2024-05-04 16:39:32,749:INFO:_master_model_container: 14
2024-05-04 16:39:32,749:INFO:_display_container: 3
2024-05-04 16:39:32,749:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7470, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-04 16:39:32,749:INFO:create_model() successfully completed......................................
2024-05-04 16:39:47,950:INFO:Initializing create_model()
2024-05-04 16:39:47,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=lr, fold=3, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:39:47,951:INFO:Checking exceptions
2024-05-04 16:39:47,959:INFO:Importing libraries
2024-05-04 16:39:47,960:INFO:Copying training dataset
2024-05-04 16:39:47,974:INFO:Defining folds
2024-05-04 16:39:47,974:INFO:Declaring metric variables
2024-05-04 16:39:47,976:INFO:Importing untrained model
2024-05-04 16:39:47,978:INFO:Logistic Regression Imported successfully
2024-05-04 16:39:47,981:INFO:Starting cross validation
2024-05-04 16:39:47,987:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:39:49,677:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:49,680:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:49,697:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:49,699:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:49,774:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:39:49,776:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:49,792:INFO:Calculating mean and std
2024-05-04 16:39:49,793:INFO:Creating metrics dataframe
2024-05-04 16:39:49,797:INFO:Finalizing model
2024-05-04 16:39:51,380:INFO:Creating Dashboard logs
2024-05-04 16:39:51,382:INFO:Model: Logistic Regression
2024-05-04 16:39:51,395:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 7470, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-04 16:39:51,420:INFO:Initializing predict_model()
2024-05-04 16:39:51,420:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7470, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318f42160>)
2024-05-04 16:39:51,420:INFO:Checking exceptions
2024-05-04 16:39:51,420:INFO:Preloading libraries
2024-05-04 16:39:52,643:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:39:52,645:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:39:53,213:INFO:Uploading results into container
2024-05-04 16:39:53,213:INFO:Uploading model into container now
2024-05-04 16:39:53,218:INFO:_master_model_container: 15
2024-05-04 16:39:53,218:INFO:_display_container: 4
2024-05-04 16:39:53,218:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7470, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-04 16:39:53,218:INFO:create_model() successfully completed......................................
2024-05-04 16:40:00,678:INFO:Initializing create_model()
2024-05-04 16:40:00,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'C': 0.5, 'l1_ratio': 0.15})
2024-05-04 16:40:00,679:INFO:Checking exceptions
2024-05-04 16:40:00,687:INFO:Importing libraries
2024-05-04 16:40:00,687:INFO:Copying training dataset
2024-05-04 16:40:00,699:INFO:Defining folds
2024-05-04 16:40:00,699:INFO:Declaring metric variables
2024-05-04 16:40:00,701:INFO:Importing untrained model
2024-05-04 16:40:00,704:INFO:Logistic Regression Imported successfully
2024-05-04 16:40:00,707:INFO:Starting cross validation
2024-05-04 16:40:00,713:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:40:02,505:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:02,651:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:02,805:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:02,852:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:02,998:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:03,083:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:03,084:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:03,085:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:03,091:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:03,165:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:03,200:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:03,202:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:03,262:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:03,264:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:03,355:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:03,357:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:03,365:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:03,488:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:03,490:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:03,628:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:03,679:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:03,680:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:03,956:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:03,959:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:04,486:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:04,716:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:04,742:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:04,744:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:05,043:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:05,045:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:05,057:INFO:Calculating mean and std
2024-05-04 16:40:05,058:INFO:Creating metrics dataframe
2024-05-04 16:40:05,061:INFO:Finalizing model
2024-05-04 16:40:06,141:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1175: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)
  warnings.warn(

2024-05-04 16:40:06,567:INFO:Creating Dashboard logs
2024-05-04 16:40:06,569:INFO:Model: Logistic Regression
2024-05-04 16:40:06,582:INFO:Logged params: {'C': 0.5, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': 0.15, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 7470, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-04 16:40:06,611:INFO:Initializing predict_model()
2024-05-04 16:40:06,611:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=0.15, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7470, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318f43600>)
2024-05-04 16:40:06,611:INFO:Checking exceptions
2024-05-04 16:40:06,611:INFO:Preloading libraries
2024-05-04 16:40:07,862:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:40:07,864:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:08,534:INFO:Uploading results into container
2024-05-04 16:40:08,535:INFO:Uploading model into container now
2024-05-04 16:40:08,539:INFO:_master_model_container: 16
2024-05-04 16:40:08,539:INFO:_display_container: 5
2024-05-04 16:40:08,540:INFO:LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=0.15, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7470, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-04 16:40:08,540:INFO:create_model() successfully completed......................................
2024-05-04 16:40:12,742:INFO:Initializing create_model()
2024-05-04 16:40:12,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, error_score=0.0, kwargs={})
2024-05-04 16:40:12,742:INFO:Checking exceptions
2024-05-04 16:40:12,750:INFO:Importing libraries
2024-05-04 16:40:12,750:INFO:Copying training dataset
2024-05-04 16:40:12,772:INFO:Defining folds
2024-05-04 16:40:12,772:INFO:Declaring metric variables
2024-05-04 16:40:12,774:INFO:Importing untrained model
2024-05-04 16:40:12,776:INFO:Logistic Regression Imported successfully
2024-05-04 16:40:12,781:INFO:Starting cross validation
2024-05-04 16:40:12,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:40:15,626:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:15,629:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:15,644:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:15,646:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:16,108:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:16,125:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:16,128:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:16,142:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:16,457:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:16,463:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:16,509:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:16,800:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:16,803:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:16,804:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:16,953:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:16,955:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:17,149:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:17,297:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:17,352:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:17,356:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:17,583:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:17,586:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:17,627:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:17,871:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:18,044:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:18,046:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:18,330:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:18,332:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:18,371:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:18,596:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:40:18,608:INFO:Calculating mean and std
2024-05-04 16:40:18,611:INFO:Creating metrics dataframe
2024-05-04 16:40:18,620:INFO:Finalizing model
2024-05-04 16:40:20,308:INFO:Initializing predict_model()
2024-05-04 16:40:20,308:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=7470,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3100df240>)
2024-05-04 16:40:20,308:INFO:Checking exceptions
2024-05-04 16:40:20,308:INFO:Preloading libraries
2024-05-04 16:40:20,308:INFO:Set up data.
2024-05-04 16:40:20,316:INFO:Set up index.
2024-05-04 16:40:20,974:INFO:Creating Dashboard logs
2024-05-04 16:40:20,976:INFO:Model: Logistic Regression
2024-05-04 16:40:20,988:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 7470, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-05-04 16:40:21,019:INFO:Initializing predict_model()
2024-05-04 16:40:21,020:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7470, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318f43c40>)
2024-05-04 16:40:21,020:INFO:Checking exceptions
2024-05-04 16:40:21,020:INFO:Preloading libraries
2024-05-04 16:40:22,456:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:40:22,459:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:23,082:INFO:Uploading results into container
2024-05-04 16:40:23,082:INFO:Uploading model into container now
2024-05-04 16:40:23,088:INFO:_master_model_container: 17
2024-05-04 16:40:23,089:INFO:_display_container: 6
2024-05-04 16:40:23,089:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7470, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-04 16:40:23,089:INFO:create_model() successfully completed......................................
2024-05-04 16:40:42,823:INFO:Initializing create_model()
2024-05-04 16:40:42,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:40:42,824:INFO:Checking exceptions
2024-05-04 16:40:42,833:INFO:Importing libraries
2024-05-04 16:40:42,833:INFO:Copying training dataset
2024-05-04 16:40:42,848:INFO:Defining folds
2024-05-04 16:40:42,848:INFO:Declaring metric variables
2024-05-04 16:40:42,855:INFO:Importing untrained model
2024-05-04 16:40:42,859:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:40:42,872:INFO:Starting cross validation
2024-05-04 16:40:42,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:40:45,069:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:45,092:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:45,285:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:45,390:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:45,547:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:45,615:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:45,634:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:46,057:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:46,568:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:46,863:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:46,878:INFO:Calculating mean and std
2024-05-04 16:40:46,881:INFO:Creating metrics dataframe
2024-05-04 16:40:46,887:INFO:Finalizing model
2024-05-04 16:40:47,944:INFO:Creating Dashboard logs
2024-05-04 16:40:47,950:INFO:Model: Decision Tree Classifier
2024-05-04 16:40:47,980:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 7470, 'splitter': 'best'}
2024-05-04 16:40:48,011:INFO:Initializing predict_model()
2024-05-04 16:40:48,011:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318f42ca0>)
2024-05-04 16:40:48,011:INFO:Checking exceptions
2024-05-04 16:40:48,011:INFO:Preloading libraries
2024-05-04 16:40:49,266:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:40:49,269:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:40:50,024:INFO:Uploading results into container
2024-05-04 16:40:50,025:INFO:Uploading model into container now
2024-05-04 16:40:50,030:INFO:_master_model_container: 18
2024-05-04 16:40:50,030:INFO:_display_container: 7
2024-05-04 16:40:50,030:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:40:50,030:INFO:create_model() successfully completed......................................
2024-05-04 16:40:54,482:INFO:Initializing tune_model()
2024-05-04 16:40:54,482:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-04 16:40:54,482:INFO:Checking exceptions
2024-05-04 16:40:54,494:INFO:Copying training dataset
2024-05-04 16:40:54,502:INFO:Checking base model
2024-05-04 16:40:54,502:INFO:Base model : Decision Tree Classifier
2024-05-04 16:40:54,504:INFO:Declaring metric variables
2024-05-04 16:40:54,505:INFO:Defining Hyperparameters
2024-05-04 16:40:54,722:INFO:Tuning with n_jobs=-1
2024-05-04 16:40:54,722:INFO:Initializing RandomizedSearchCV
2024-05-04 16:41:24,096:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini'}
2024-05-04 16:41:24,098:INFO:Hyperparameter search completed
2024-05-04 16:41:24,099:INFO:SubProcess create_model() called ==================================
2024-05-04 16:41:24,099:INFO:Initializing create_model()
2024-05-04 16:41:24,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335b7cbd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'gini'})
2024-05-04 16:41:24,099:INFO:Checking exceptions
2024-05-04 16:41:24,100:INFO:Importing libraries
2024-05-04 16:41:24,100:INFO:Copying training dataset
2024-05-04 16:41:24,120:INFO:Defining folds
2024-05-04 16:41:24,120:INFO:Declaring metric variables
2024-05-04 16:41:24,124:INFO:Importing untrained model
2024-05-04 16:41:24,124:INFO:Declaring custom model
2024-05-04 16:41:24,126:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:41:24,129:INFO:Starting cross validation
2024-05-04 16:41:24,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:41:26,201:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:26,318:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:26,489:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:26,550:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:26,615:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:26,711:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:26,909:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:27,033:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:27,703:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:27,842:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:27,854:INFO:Calculating mean and std
2024-05-04 16:41:27,855:INFO:Creating metrics dataframe
2024-05-04 16:41:27,858:INFO:Finalizing model
2024-05-04 16:41:28,929:INFO:Uploading results into container
2024-05-04 16:41:28,930:INFO:Uploading model into container now
2024-05-04 16:41:28,930:INFO:_master_model_container: 19
2024-05-04 16:41:28,930:INFO:_display_container: 8
2024-05-04 16:41:28,931:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:41:28,931:INFO:create_model() successfully completed......................................
2024-05-04 16:41:29,255:INFO:SubProcess create_model() end ==================================
2024-05-04 16:41:29,256:INFO:choose_better activated
2024-05-04 16:41:29,257:INFO:SubProcess create_model() called ==================================
2024-05-04 16:41:29,257:INFO:Initializing create_model()
2024-05-04 16:41:29,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:41:29,258:INFO:Checking exceptions
2024-05-04 16:41:29,258:INFO:Importing libraries
2024-05-04 16:41:29,258:INFO:Copying training dataset
2024-05-04 16:41:29,268:INFO:Defining folds
2024-05-04 16:41:29,268:INFO:Declaring metric variables
2024-05-04 16:41:29,268:INFO:Importing untrained model
2024-05-04 16:41:29,268:INFO:Declaring custom model
2024-05-04 16:41:29,268:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:41:29,268:INFO:Starting cross validation
2024-05-04 16:41:29,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:41:31,316:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:31,494:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:31,557:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:31,687:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:31,735:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:31,919:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:32,014:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:32,149:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:32,888:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:32,950:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:32,954:INFO:Calculating mean and std
2024-05-04 16:41:32,954:INFO:Creating metrics dataframe
2024-05-04 16:41:32,955:INFO:Finalizing model
2024-05-04 16:41:33,985:INFO:Uploading results into container
2024-05-04 16:41:33,986:INFO:Uploading model into container now
2024-05-04 16:41:33,986:INFO:_master_model_container: 20
2024-05-04 16:41:33,986:INFO:_display_container: 9
2024-05-04 16:41:33,986:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:41:33,986:INFO:create_model() successfully completed......................................
2024-05-04 16:41:34,185:INFO:SubProcess create_model() end ==================================
2024-05-04 16:41:34,186:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') result for Accuracy is 0.142
2024-05-04 16:41:34,186:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') result for Accuracy is 0.387
2024-05-04 16:41:34,186:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') is best model
2024-05-04 16:41:34,186:INFO:choose_better completed
2024-05-04 16:41:34,186:INFO:Creating Dashboard logs
2024-05-04 16:41:34,187:INFO:Model: Decision Tree Classifier
2024-05-04 16:41:34,200:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_features': 1.0, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.4, 'min_samples_leaf': 2, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 7470, 'splitter': 'best'}
2024-05-04 16:41:34,226:INFO:Initializing predict_model()
2024-05-04 16:41:34,226:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318f43920>)
2024-05-04 16:41:34,226:INFO:Checking exceptions
2024-05-04 16:41:34,226:INFO:Preloading libraries
2024-05-04 16:41:35,483:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:41:35,485:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:41:36,074:INFO:_master_model_container: 20
2024-05-04 16:41:36,074:INFO:_display_container: 8
2024-05-04 16:41:36,074:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:41:36,074:INFO:tune_model() successfully completed......................................
2024-05-04 16:43:08,680:INFO:Initializing tune_model()
2024-05-04 16:43:08,681:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=None, round=4, n_iter=10, custom_grid={'max_depth': [None, 2, 4, 6, 8, 10, 12]}, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-04 16:43:08,681:INFO:Checking exceptions
2024-05-04 16:43:08,696:INFO:Copying training dataset
2024-05-04 16:43:08,707:INFO:Checking base model
2024-05-04 16:43:08,707:INFO:Base model : Decision Tree Classifier
2024-05-04 16:43:08,708:INFO:Declaring metric variables
2024-05-04 16:43:08,710:INFO:Defining Hyperparameters
2024-05-04 16:43:08,953:INFO:custom_grid: {'actual_estimator__max_depth': [None, 2, 4, 6, 8, 10, 12]}
2024-05-04 16:43:08,953:INFO:Tuning with n_jobs=-1
2024-05-04 16:43:08,953:INFO:Initializing RandomizedSearchCV
2024-05-04 16:43:08,957:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 7 is smaller than n_iter=10. Running 7 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

2024-05-04 16:43:29,756:INFO:best_params: {'actual_estimator__max_depth': None}
2024-05-04 16:43:29,758:INFO:Hyperparameter search completed
2024-05-04 16:43:29,759:INFO:SubProcess create_model() called ==================================
2024-05-04 16:43:29,759:INFO:Initializing create_model()
2024-05-04 16:43:29,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31ddf4390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'max_depth': None})
2024-05-04 16:43:29,760:INFO:Checking exceptions
2024-05-04 16:43:29,760:INFO:Importing libraries
2024-05-04 16:43:29,760:INFO:Copying training dataset
2024-05-04 16:43:29,775:INFO:Defining folds
2024-05-04 16:43:29,775:INFO:Declaring metric variables
2024-05-04 16:43:29,778:INFO:Importing untrained model
2024-05-04 16:43:29,778:INFO:Declaring custom model
2024-05-04 16:43:29,780:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:43:29,782:INFO:Starting cross validation
2024-05-04 16:43:29,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:43:31,843:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:31,861:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:31,944:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:32,070:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:32,095:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:32,342:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:32,347:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:32,366:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:33,266:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:33,359:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:33,370:INFO:Calculating mean and std
2024-05-04 16:43:33,371:INFO:Creating metrics dataframe
2024-05-04 16:43:33,374:INFO:Finalizing model
2024-05-04 16:43:34,401:INFO:Uploading results into container
2024-05-04 16:43:34,402:INFO:Uploading model into container now
2024-05-04 16:43:34,402:INFO:_master_model_container: 21
2024-05-04 16:43:34,402:INFO:_display_container: 9
2024-05-04 16:43:34,402:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:43:34,402:INFO:create_model() successfully completed......................................
2024-05-04 16:43:34,711:INFO:SubProcess create_model() end ==================================
2024-05-04 16:43:34,711:INFO:choose_better activated
2024-05-04 16:43:34,713:INFO:SubProcess create_model() called ==================================
2024-05-04 16:43:34,713:INFO:Initializing create_model()
2024-05-04 16:43:34,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:43:34,713:INFO:Checking exceptions
2024-05-04 16:43:34,714:INFO:Importing libraries
2024-05-04 16:43:34,714:INFO:Copying training dataset
2024-05-04 16:43:34,723:INFO:Defining folds
2024-05-04 16:43:34,723:INFO:Declaring metric variables
2024-05-04 16:43:34,723:INFO:Importing untrained model
2024-05-04 16:43:34,723:INFO:Declaring custom model
2024-05-04 16:43:34,723:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:43:34,723:INFO:Starting cross validation
2024-05-04 16:43:34,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:43:36,756:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:36,914:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:36,933:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:37,204:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:37,240:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:37,320:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:37,373:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:37,416:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:38,263:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:38,357:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:38,368:INFO:Calculating mean and std
2024-05-04 16:43:38,368:INFO:Creating metrics dataframe
2024-05-04 16:43:38,369:INFO:Finalizing model
2024-05-04 16:43:39,382:INFO:Uploading results into container
2024-05-04 16:43:39,382:INFO:Uploading model into container now
2024-05-04 16:43:39,382:INFO:_master_model_container: 22
2024-05-04 16:43:39,382:INFO:_display_container: 10
2024-05-04 16:43:39,382:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:43:39,382:INFO:create_model() successfully completed......................................
2024-05-04 16:43:39,588:INFO:SubProcess create_model() end ==================================
2024-05-04 16:43:39,588:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') result for F1 is 0.0353
2024-05-04 16:43:39,588:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') result for F1 is 0.0353
2024-05-04 16:43:39,588:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') is best model
2024-05-04 16:43:39,588:INFO:choose_better completed
2024-05-04 16:43:39,588:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-04 16:43:39,589:INFO:Creating Dashboard logs
2024-05-04 16:43:39,590:INFO:Model: Decision Tree Classifier
2024-05-04 16:43:39,605:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 7470, 'splitter': 'best'}
2024-05-04 16:43:39,631:INFO:Initializing predict_model()
2024-05-04 16:43:39,631:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318f41d00>)
2024-05-04 16:43:39,631:INFO:Checking exceptions
2024-05-04 16:43:39,631:INFO:Preloading libraries
2024-05-04 16:43:40,899:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:43:40,901:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:43:41,478:INFO:_master_model_container: 22
2024-05-04 16:43:41,479:INFO:_display_container: 9
2024-05-04 16:43:41,479:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:43:41,479:INFO:tune_model() successfully completed......................................
2024-05-04 16:43:48,982:INFO:Initializing tune_model()
2024-05-04 16:43:48,983:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-04 16:43:48,983:INFO:Checking exceptions
2024-05-04 16:43:48,996:INFO:Copying training dataset
2024-05-04 16:43:49,005:INFO:Checking base model
2024-05-04 16:43:49,005:INFO:Base model : Decision Tree Classifier
2024-05-04 16:43:49,007:INFO:Declaring metric variables
2024-05-04 16:43:49,009:INFO:Defining Hyperparameters
2024-05-04 16:43:49,222:INFO:Tuning with n_jobs=-1
2024-05-04 16:43:49,222:INFO:Initializing RandomizedSearchCV
2024-05-04 16:44:19,410:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini'}
2024-05-04 16:44:19,412:INFO:Hyperparameter search completed
2024-05-04 16:44:19,412:INFO:SubProcess create_model() called ==================================
2024-05-04 16:44:19,413:INFO:Initializing create_model()
2024-05-04 16:44:19,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x335098950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'gini'})
2024-05-04 16:44:19,413:INFO:Checking exceptions
2024-05-04 16:44:19,414:INFO:Importing libraries
2024-05-04 16:44:19,414:INFO:Copying training dataset
2024-05-04 16:44:19,428:INFO:Defining folds
2024-05-04 16:44:19,428:INFO:Declaring metric variables
2024-05-04 16:44:19,431:INFO:Importing untrained model
2024-05-04 16:44:19,431:INFO:Declaring custom model
2024-05-04 16:44:19,433:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:44:19,436:INFO:Starting cross validation
2024-05-04 16:44:19,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:44:21,561:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:21,763:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:21,983:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:22,102:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:22,201:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:22,297:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:22,486:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:22,497:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:23,310:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:23,425:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:23,437:INFO:Calculating mean and std
2024-05-04 16:44:23,438:INFO:Creating metrics dataframe
2024-05-04 16:44:23,441:INFO:Finalizing model
2024-05-04 16:44:24,505:INFO:Uploading results into container
2024-05-04 16:44:24,506:INFO:Uploading model into container now
2024-05-04 16:44:24,506:INFO:_master_model_container: 23
2024-05-04 16:44:24,506:INFO:_display_container: 10
2024-05-04 16:44:24,506:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:44:24,506:INFO:create_model() successfully completed......................................
2024-05-04 16:44:24,815:INFO:SubProcess create_model() end ==================================
2024-05-04 16:44:24,815:INFO:choose_better activated
2024-05-04 16:44:24,817:INFO:SubProcess create_model() called ==================================
2024-05-04 16:44:24,817:INFO:Initializing create_model()
2024-05-04 16:44:24,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:44:24,817:INFO:Checking exceptions
2024-05-04 16:44:24,818:INFO:Importing libraries
2024-05-04 16:44:24,818:INFO:Copying training dataset
2024-05-04 16:44:24,827:INFO:Defining folds
2024-05-04 16:44:24,827:INFO:Declaring metric variables
2024-05-04 16:44:24,827:INFO:Importing untrained model
2024-05-04 16:44:24,827:INFO:Declaring custom model
2024-05-04 16:44:24,827:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:44:24,827:INFO:Starting cross validation
2024-05-04 16:44:24,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:44:27,012:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:27,042:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:27,264:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:27,365:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:27,426:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:27,586:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:27,609:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:27,845:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:28,792:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:28,831:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:28,840:INFO:Calculating mean and std
2024-05-04 16:44:28,840:INFO:Creating metrics dataframe
2024-05-04 16:44:28,841:INFO:Finalizing model
2024-05-04 16:44:29,939:INFO:Uploading results into container
2024-05-04 16:44:29,939:INFO:Uploading model into container now
2024-05-04 16:44:29,939:INFO:_master_model_container: 24
2024-05-04 16:44:29,940:INFO:_display_container: 11
2024-05-04 16:44:29,940:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:44:29,940:INFO:create_model() successfully completed......................................
2024-05-04 16:44:30,162:INFO:SubProcess create_model() end ==================================
2024-05-04 16:44:30,163:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') result for Accuracy is 0.142
2024-05-04 16:44:30,163:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') result for Accuracy is 0.387
2024-05-04 16:44:30,163:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') is best model
2024-05-04 16:44:30,163:INFO:choose_better completed
2024-05-04 16:44:30,163:INFO:Creating Dashboard logs
2024-05-04 16:44:30,164:INFO:Model: Decision Tree Classifier
2024-05-04 16:44:30,179:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_features': 1.0, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.4, 'min_samples_leaf': 2, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 7470, 'splitter': 'best'}
2024-05-04 16:44:30,207:INFO:Initializing predict_model()
2024-05-04 16:44:30,207:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318f434c0>)
2024-05-04 16:44:30,207:INFO:Checking exceptions
2024-05-04 16:44:30,207:INFO:Preloading libraries
2024-05-04 16:44:31,605:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:44:31,608:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:44:32,246:INFO:_master_model_container: 24
2024-05-04 16:44:32,246:INFO:_display_container: 10
2024-05-04 16:44:32,246:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:44:32,246:INFO:tune_model() successfully completed......................................
2024-05-04 16:45:11,145:INFO:Initializing tune_model()
2024-05-04 16:45:11,145:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-04 16:45:11,145:INFO:Checking exceptions
2024-05-04 16:45:11,145:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-05-04 16:45:33,279:INFO:Initializing tune_model()
2024-05-04 16:45:33,280:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-04 16:45:33,280:INFO:Checking exceptions
2024-05-04 16:45:33,280:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-05-04 16:45:34,427:INFO:Initializing tune_model()
2024-05-04 16:45:34,427:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-04 16:45:34,427:INFO:Checking exceptions
2024-05-04 16:45:34,427:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-05-04 16:45:54,964:INFO:Initializing tune_model()
2024-05-04 16:45:54,965:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-04 16:45:54,965:INFO:Checking exceptions
2024-05-04 16:45:54,966:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-05-04 16:46:22,390:INFO:Initializing tune_model()
2024-05-04 16:46:22,390:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-04 16:46:22,390:INFO:Checking exceptions
2024-05-04 16:46:22,390:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-05-04 16:47:03,072:INFO:Initializing tune_model()
2024-05-04 16:47:03,073:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-05-04 16:47:03,073:INFO:Checking exceptions
2024-05-04 16:47:03,090:INFO:Copying training dataset
2024-05-04 16:47:03,100:INFO:Checking base model
2024-05-04 16:47:03,101:INFO:Base model : Decision Tree Classifier
2024-05-04 16:47:03,102:INFO:Declaring metric variables
2024-05-04 16:47:03,104:INFO:Defining Hyperparameters
2024-05-04 16:47:03,432:INFO:Tuning with n_jobs=-1
2024-05-04 16:47:03,432:INFO:Initializing RandomizedSearchCV
2024-05-04 16:47:35,981:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini'}
2024-05-04 16:47:35,989:INFO:Hyperparameter search completed
2024-05-04 16:47:35,990:INFO:SubProcess create_model() called ==================================
2024-05-04 16:47:35,991:INFO:Initializing create_model()
2024-05-04 16:47:35,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x333acb790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'gini'})
2024-05-04 16:47:35,991:INFO:Checking exceptions
2024-05-04 16:47:35,991:INFO:Importing libraries
2024-05-04 16:47:35,991:INFO:Copying training dataset
2024-05-04 16:47:36,014:INFO:Defining folds
2024-05-04 16:47:36,016:INFO:Declaring metric variables
2024-05-04 16:47:36,021:INFO:Importing untrained model
2024-05-04 16:47:36,022:INFO:Declaring custom model
2024-05-04 16:47:36,024:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:47:36,031:INFO:Starting cross validation
2024-05-04 16:47:36,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:47:38,152:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:38,301:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:38,420:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:38,671:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:38,818:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:38,926:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:39,087:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:39,095:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:39,850:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:39,932:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:39,940:INFO:Calculating mean and std
2024-05-04 16:47:39,941:INFO:Creating metrics dataframe
2024-05-04 16:47:39,944:INFO:Finalizing model
2024-05-04 16:47:41,054:INFO:Uploading results into container
2024-05-04 16:47:41,055:INFO:Uploading model into container now
2024-05-04 16:47:41,055:INFO:_master_model_container: 25
2024-05-04 16:47:41,056:INFO:_display_container: 11
2024-05-04 16:47:41,056:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:47:41,056:INFO:create_model() successfully completed......................................
2024-05-04 16:47:41,380:INFO:SubProcess create_model() end ==================================
2024-05-04 16:47:41,380:INFO:choose_better activated
2024-05-04 16:47:41,381:INFO:SubProcess create_model() called ==================================
2024-05-04 16:47:41,381:INFO:Initializing create_model()
2024-05-04 16:47:41,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:47:41,382:INFO:Checking exceptions
2024-05-04 16:47:41,382:INFO:Importing libraries
2024-05-04 16:47:41,382:INFO:Copying training dataset
2024-05-04 16:47:41,392:INFO:Defining folds
2024-05-04 16:47:41,392:INFO:Declaring metric variables
2024-05-04 16:47:41,392:INFO:Importing untrained model
2024-05-04 16:47:41,392:INFO:Declaring custom model
2024-05-04 16:47:41,392:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:47:41,392:INFO:Starting cross validation
2024-05-04 16:47:41,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:47:43,479:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:43,599:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:43,721:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:44,017:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:44,083:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:44,100:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:44,157:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:44,371:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:45,091:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:45,210:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:45,223:INFO:Calculating mean and std
2024-05-04 16:47:45,224:INFO:Creating metrics dataframe
2024-05-04 16:47:45,227:INFO:Finalizing model
2024-05-04 16:47:46,447:INFO:Uploading results into container
2024-05-04 16:47:46,447:INFO:Uploading model into container now
2024-05-04 16:47:46,448:INFO:_master_model_container: 26
2024-05-04 16:47:46,448:INFO:_display_container: 12
2024-05-04 16:47:46,448:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:47:46,448:INFO:create_model() successfully completed......................................
2024-05-04 16:47:46,669:INFO:SubProcess create_model() end ==================================
2024-05-04 16:47:46,670:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') result for Accuracy is 0.142
2024-05-04 16:47:46,670:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') result for Accuracy is 0.387
2024-05-04 16:47:46,670:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best') is best model
2024-05-04 16:47:46,670:INFO:choose_better completed
2024-05-04 16:47:46,670:INFO:Creating Dashboard logs
2024-05-04 16:47:46,672:INFO:Model: Decision Tree Classifier
2024-05-04 16:47:46,692:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_features': 1.0, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.4, 'min_samples_leaf': 2, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 7470, 'splitter': 'best'}
2024-05-04 16:47:46,727:INFO:Initializing predict_model()
2024-05-04 16:47:46,728:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318124f40>)
2024-05-04 16:47:46,728:INFO:Checking exceptions
2024-05-04 16:47:46,728:INFO:Preloading libraries
2024-05-04 16:47:48,067:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:47:48,069:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:47:48,669:INFO:_master_model_container: 26
2024-05-04 16:47:48,669:INFO:_display_container: 11
2024-05-04 16:47:48,669:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.4, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best')
2024-05-04 16:47:48,669:INFO:tune_model() successfully completed......................................
2024-05-04 16:47:57,950:INFO:Initializing ensemble_model()
2024-05-04 16:47:57,950:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-05-04 16:47:57,950:INFO:Checking exceptions
2024-05-04 16:47:57,966:INFO:Importing libraries
2024-05-04 16:47:57,966:INFO:Copying training dataset
2024-05-04 16:47:57,966:INFO:Checking base model
2024-05-04 16:47:57,967:INFO:Base model : Decision Tree Classifier
2024-05-04 16:47:57,970:INFO:Importing untrained ensembler
2024-05-04 16:47:57,970:INFO:Ensemble method set to Bagging
2024-05-04 16:47:57,970:INFO:SubProcess create_model() called ==================================
2024-05-04 16:47:57,971:INFO:Initializing create_model()
2024-05-04 16:47:57,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   monotonic_cst=None,
                                                   random_state=7470,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=7470, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x332a0ea90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:47:57,971:INFO:Checking exceptions
2024-05-04 16:47:57,971:INFO:Importing libraries
2024-05-04 16:47:57,971:INFO:Copying training dataset
2024-05-04 16:47:57,982:INFO:Defining folds
2024-05-04 16:47:57,982:INFO:Declaring metric variables
2024-05-04 16:47:57,984:INFO:Importing untrained model
2024-05-04 16:47:57,984:INFO:Declaring custom model
2024-05-04 16:47:57,985:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:47:57,988:INFO:Starting cross validation
2024-05-04 16:47:57,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:48:00,199:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:00,444:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:00,533:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:00,688:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:00,738:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:01,008:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:01,032:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:01,093:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:01,799:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:01,984:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:01,989:INFO:Calculating mean and std
2024-05-04 16:48:01,991:INFO:Creating metrics dataframe
2024-05-04 16:48:01,997:INFO:Finalizing model
2024-05-04 16:48:03,079:INFO:Uploading results into container
2024-05-04 16:48:03,080:INFO:Uploading model into container now
2024-05-04 16:48:03,080:INFO:_master_model_container: 27
2024-05-04 16:48:03,080:INFO:_display_container: 12
2024-05-04 16:48:03,081:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   monotonic_cst=None,
                                                   random_state=7470,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=7470, verbose=0,
                  warm_start=False)
2024-05-04 16:48:03,081:INFO:create_model() successfully completed......................................
2024-05-04 16:48:03,378:INFO:SubProcess create_model() end ==================================
2024-05-04 16:48:03,378:INFO:Creating Dashboard logs
2024-05-04 16:48:03,380:INFO:Model: Decision Tree Classifier
2024-05-04 16:48:03,394:INFO:Logged params: {'bootstrap': True, 'bootstrap_features': False, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__monotonic_cst': None, 'estimator__random_state': 7470, 'estimator__splitter': 'best', 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 7470, 'verbose': 0, 'warm_start': False}
2024-05-04 16:48:03,422:INFO:Initializing predict_model()
2024-05-04 16:48:03,422:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   monotonic_cst=None,
                                                   random_state=7470,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=7470, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318124e00>)
2024-05-04 16:48:03,422:INFO:Checking exceptions
2024-05-04 16:48:03,422:INFO:Preloading libraries
2024-05-04 16:48:04,681:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:48:04,684:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:05,273:INFO:_master_model_container: 27
2024-05-04 16:48:05,273:INFO:_display_container: 12
2024-05-04 16:48:05,273:INFO:BaggingClassifier(bootstrap=True, bootstrap_features=False,
                  estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features=None,
                                                   max_leaf_nodes=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   monotonic_cst=None,
                                                   random_state=7470,
                                                   splitter='best'),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=7470, verbose=0,
                  warm_start=False)
2024-05-04 16:48:05,273:INFO:ensemble_model() successfully completed......................................
2024-05-04 16:48:13,669:INFO:Initializing ensemble_model()
2024-05-04 16:48:13,670:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7470, splitter='best'), method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-05-04 16:48:13,670:INFO:Checking exceptions
2024-05-04 16:48:14,962:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:14,981:INFO:Importing libraries
2024-05-04 16:48:14,982:INFO:Copying training dataset
2024-05-04 16:48:14,982:INFO:Checking base model
2024-05-04 16:48:14,982:INFO:Base model : Decision Tree Classifier
2024-05-04 16:48:14,985:INFO:Importing untrained ensembler
2024-05-04 16:48:14,985:INFO:Ensemble method set to Boosting
2024-05-04 16:48:14,985:INFO:SubProcess create_model() called ==================================
2024-05-04 16:48:14,985:INFO:Initializing create_model()
2024-05-04 16:48:14,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=AdaBoostClassifier(algorithm='SAMME.R',
                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                    class_weight=None,
                                                    criterion='gini',
                                                    max_depth=None,
                                                    max_features=None,
                                                    max_leaf_nodes=None,
                                                    min_impurity_decrease=0.0,
                                                    min_samples_leaf=1,
                                                    min_samples_split=2,
                                                    min_weight_fraction_leaf=0.0,
                                                    monotonic_cst=None,
                                                    random_state=7470,
                                                    splitter='best'),
                   learning_rate=1.0, n_estimators=10, random_state=7470), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x313040ad0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:48:14,986:INFO:Checking exceptions
2024-05-04 16:48:14,986:INFO:Importing libraries
2024-05-04 16:48:14,986:INFO:Copying training dataset
2024-05-04 16:48:14,997:INFO:Defining folds
2024-05-04 16:48:14,997:INFO:Declaring metric variables
2024-05-04 16:48:14,999:INFO:Importing untrained model
2024-05-04 16:48:14,999:INFO:Declaring custom model
2024-05-04 16:48:15,002:INFO:Decision Tree Classifier Imported successfully
2024-05-04 16:48:15,005:INFO:Starting cross validation
2024-05-04 16:48:15,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:48:16,974:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:17,167:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:17,170:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:17,223:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:17,307:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:17,320:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:17,505:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:17,507:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:17,526:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:17,536:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:17,539:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:17,540:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:17,603:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:17,713:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:17,739:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:17,741:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:17,983:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:17,995:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:18,003:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:18,185:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:18,211:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:18,213:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:18,329:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:18,331:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:19,051:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:19,187:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:19,189:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:19,288:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:19,441:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:19,445:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:19,463:INFO:Calculating mean and std
2024-05-04 16:48:19,465:INFO:Creating metrics dataframe
2024-05-04 16:48:19,473:INFO:Finalizing model
2024-05-04 16:48:20,662:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-04 16:48:20,679:INFO:Uploading results into container
2024-05-04 16:48:20,680:INFO:Uploading model into container now
2024-05-04 16:48:20,680:INFO:_master_model_container: 28
2024-05-04 16:48:20,680:INFO:_display_container: 13
2024-05-04 16:48:20,681:INFO:AdaBoostClassifier(algorithm='SAMME.R',
                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                    class_weight=None,
                                                    criterion='gini',
                                                    max_depth=None,
                                                    max_features=None,
                                                    max_leaf_nodes=None,
                                                    min_impurity_decrease=0.0,
                                                    min_samples_leaf=1,
                                                    min_samples_split=2,
                                                    min_weight_fraction_leaf=0.0,
                                                    monotonic_cst=None,
                                                    random_state=7470,
                                                    splitter='best'),
                   learning_rate=1.0, n_estimators=10, random_state=7470)
2024-05-04 16:48:20,681:INFO:create_model() successfully completed......................................
2024-05-04 16:48:21,023:INFO:SubProcess create_model() end ==================================
2024-05-04 16:48:21,023:INFO:Creating Dashboard logs
2024-05-04 16:48:21,025:INFO:Model: Decision Tree Classifier
2024-05-04 16:48:21,040:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__monotonic_cst': None, 'estimator__random_state': 7470, 'estimator__splitter': 'best', 'learning_rate': 1.0, 'n_estimators': 10, 'random_state': 7470}
2024-05-04 16:48:21,076:INFO:Initializing predict_model()
2024-05-04 16:48:21,076:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=AdaBoostClassifier(algorithm='SAMME.R',
                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                    class_weight=None,
                                                    criterion='gini',
                                                    max_depth=None,
                                                    max_features=None,
                                                    max_leaf_nodes=None,
                                                    min_impurity_decrease=0.0,
                                                    min_samples_leaf=1,
                                                    min_samples_split=2,
                                                    min_weight_fraction_leaf=0.0,
                                                    monotonic_cst=None,
                                                    random_state=7470,
                                                    splitter='best'),
                   learning_rate=1.0, n_estimators=10, random_state=7470), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318125080>)
2024-05-04 16:48:21,076:INFO:Checking exceptions
2024-05-04 16:48:21,076:INFO:Preloading libraries
2024-05-04 16:48:22,446:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:48:22,448:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:23,079:INFO:_master_model_container: 28
2024-05-04 16:48:23,079:INFO:_display_container: 13
2024-05-04 16:48:23,079:INFO:AdaBoostClassifier(algorithm='SAMME.R',
                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,
                                                    class_weight=None,
                                                    criterion='gini',
                                                    max_depth=None,
                                                    max_features=None,
                                                    max_leaf_nodes=None,
                                                    min_impurity_decrease=0.0,
                                                    min_samples_leaf=1,
                                                    min_samples_split=2,
                                                    min_weight_fraction_leaf=0.0,
                                                    monotonic_cst=None,
                                                    random_state=7470,
                                                    splitter='best'),
                   learning_rate=1.0, n_estimators=10, random_state=7470)
2024-05-04 16:48:23,079:INFO:ensemble_model() successfully completed......................................
2024-05-04 16:48:32,232:INFO:Initializing blend_models()
2024-05-04 16:48:32,233:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator_list=[DummyClassifier(constant=None, random_state=123, strategy='prior'), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-05-04 16:48:32,233:INFO:Checking exceptions
2024-05-04 16:48:32,234:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2024-05-04 16:48:32,245:INFO:Importing libraries
2024-05-04 16:48:32,246:INFO:Copying training dataset
2024-05-04 16:48:32,248:INFO:Getting model names
2024-05-04 16:48:32,250:INFO:SubProcess create_model() called ==================================
2024-05-04 16:48:32,251:INFO:Initializing create_model()
2024-05-04 16:48:32,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=VotingClassifier(estimators=[('Dummy Classifier',
                              DummyClassifier(constant=None, random_state=123,
                                              strategy='prior')),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=None,
                                              copy_X=True, fit_intercept=True,
                                              max_iter=None, positive=False,
                                              random_state=123, solver='auto',
                                              tol=0.0001)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x316dc3490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:48:32,251:INFO:Checking exceptions
2024-05-04 16:48:32,251:INFO:Importing libraries
2024-05-04 16:48:32,251:INFO:Copying training dataset
2024-05-04 16:48:32,263:INFO:Defining folds
2024-05-04 16:48:32,263:INFO:Declaring metric variables
2024-05-04 16:48:32,265:INFO:Importing untrained model
2024-05-04 16:48:32,265:INFO:Declaring custom model
2024-05-04 16:48:32,267:INFO:Voting Classifier Imported successfully
2024-05-04 16:48:32,270:INFO:Starting cross validation
2024-05-04 16:48:32,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:48:34,656:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:34,770:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:34,828:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:34,984:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:35,064:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:35,066:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:35,067:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:35,137:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:35,139:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:35,158:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:35,160:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:35,263:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:35,265:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:35,301:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:35,303:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:35,313:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:35,313:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:35,392:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:35,483:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:35,485:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:35,489:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:35,491:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:35,553:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:35,554:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:36,545:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:36,633:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:36,694:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:36,696:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:36,779:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-05-04 16:48:36,780:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:36,786:INFO:Calculating mean and std
2024-05-04 16:48:36,788:INFO:Creating metrics dataframe
2024-05-04 16:48:36,794:INFO:Finalizing model
2024-05-04 16:48:37,868:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:38,022:INFO:Uploading results into container
2024-05-04 16:48:38,022:INFO:Uploading model into container now
2024-05-04 16:48:38,023:INFO:_master_model_container: 29
2024-05-04 16:48:38,023:INFO:_display_container: 14
2024-05-04 16:48:38,024:INFO:VotingClassifier(estimators=[('Dummy Classifier',
                              DummyClassifier(constant=None, random_state=123,
                                              strategy='prior')),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=None,
                                              copy_X=True, fit_intercept=True,
                                              max_iter=None, positive=False,
                                              random_state=123, solver='auto',
                                              tol=0.0001)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-05-04 16:48:38,024:INFO:create_model() successfully completed......................................
2024-05-04 16:48:38,340:INFO:SubProcess create_model() end ==================================
2024-05-04 16:48:38,340:INFO:Creating Dashboard logs
2024-05-04 16:48:38,342:INFO:Model: Voting Classifier
2024-05-04 16:48:38,356:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'hard', 'weights': None, 'Dummy Classifier': DummyClassifier(constant=None, random_state=123, strategy='prior'), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), 'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), 'Dummy Classifier__constant': None, 'Dummy Classifier__random_state': 123, 'Dummy Classifier__strategy': 'prior', 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 123, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Quadratic Discriminant Analysis__priors': None, 'Quadratic Discriminant Analysis__reg_param': 0.0, 'Quadratic Discriminant Analysis__store_covariance': False, 'Quadratic Discriminant Analysis__tol': 0.0001}
2024-05-04 16:48:38,387:INFO:Initializing predict_model()
2024-05-04 16:48:38,387:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=VotingClassifier(estimators=[('Dummy Classifier',
                              DummyClassifier(constant=None, random_state=123,
                                              strategy='prior')),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=None,
                                              copy_X=True, fit_intercept=True,
                                              max_iter=None, positive=False,
                                              random_state=123, solver='auto',
                                              tol=0.0001)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x318125580>)
2024-05-04 16:48:38,387:INFO:Checking exceptions
2024-05-04 16:48:38,387:INFO:Preloading libraries
2024-05-04 16:48:39,639:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:48:39,641:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:40,238:INFO:_master_model_container: 29
2024-05-04 16:48:40,238:INFO:_display_container: 14
2024-05-04 16:48:40,239:INFO:VotingClassifier(estimators=[('Dummy Classifier',
                              DummyClassifier(constant=None, random_state=123,
                                              strategy='prior')),
                             ('Ridge Classifier',
                              RidgeClassifier(alpha=1.0, class_weight=None,
                                              copy_X=True, fit_intercept=True,
                                              max_iter=None, positive=False,
                                              random_state=123, solver='auto',
                                              tol=0.0001)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-05-04 16:48:40,239:INFO:blend_models() successfully completed......................................
2024-05-04 16:48:48,145:INFO:Initializing stack_models()
2024-05-04 16:48:48,146:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator_list=[DummyClassifier(constant=None, random_state=123, strategy='prior'), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-05-04 16:48:48,146:INFO:Checking exceptions
2024-05-04 16:48:48,151:INFO:Defining meta model
2024-05-04 16:48:48,162:INFO:Getting model names
2024-05-04 16:48:48,162:INFO:[('Dummy Classifier', DummyClassifier(constant=None, random_state=123, strategy='prior')), ('Ridge Classifier', RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)), ('Quadratic Discriminant Analysis', QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001))]
2024-05-04 16:48:48,165:INFO:SubProcess create_model() called ==================================
2024-05-04 16:48:48,167:INFO:Initializing create_model()
2024-05-04 16:48:48,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Dummy Classifier',
                                DummyClassifier(constant=None, random_state=123,
                                                strategy='prior')),
                               ('Ridge Classifier',
                                RidgeClassifier(alpha=1.0, class_weight=None,
                                                copy_X=True, fit_intercept=True,
                                                max_iter=None, positive=False,
                                                random_state=123, solver='auto',
                                                tol=0.0001)),
                               ('Quadratic Discriminant Analysis',
                                QuadraticDiscriminantAnalysis...
                                                              reg_param=0.0,
                                                              store_covariance=False,
                                                              tol=0.0001))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=7470,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x334539110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:48:48,167:INFO:Checking exceptions
2024-05-04 16:48:48,167:INFO:Importing libraries
2024-05-04 16:48:48,167:INFO:Copying training dataset
2024-05-04 16:48:48,180:INFO:Defining folds
2024-05-04 16:48:48,180:INFO:Declaring metric variables
2024-05-04 16:48:48,182:INFO:Importing untrained model
2024-05-04 16:48:48,182:INFO:Declaring custom model
2024-05-04 16:48:48,184:INFO:Stacking Classifier Imported successfully
2024-05-04 16:48:48,187:INFO:Starting cross validation
2024-05-04 16:48:48,193:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 16:48:50,134:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,246:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,271:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,332:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,366:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,369:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,399:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,439:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,454:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,456:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,478:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,525:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,529:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,540:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,567:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,568:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,579:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,580:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,617:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,617:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,628:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,660:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,665:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,675:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,689:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,689:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,691:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,707:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,713:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,734:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,751:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,764:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,770:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,778:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,781:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,787:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,809:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,812:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,814:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,814:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,831:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,852:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,857:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,882:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,892:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,906:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,912:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,916:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,919:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,944:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,968:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,984:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:50,985:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,015:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,029:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:51,031:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:51,049:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,064:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,085:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:51,087:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:51,124:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:51,127:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:51,164:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,176:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,197:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:51,199:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:51,224:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:51,227:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:51,251:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,282:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,290:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,309:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,331:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,333:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:51,336:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:51,377:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,413:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:51,415:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:51,424:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,468:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:51,630:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:51,632:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:52,398:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,470:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,476:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,492:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,496:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,524:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,560:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,566:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,570:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,585:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,612:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,616:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,655:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,659:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,700:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,749:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:52,877:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:52,879:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:52,940:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-04 16:48:52,942:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:52,949:INFO:Calculating mean and std
2024-05-04 16:48:52,952:INFO:Creating metrics dataframe
2024-05-04 16:48:52,964:INFO:Finalizing model
2024-05-04 16:48:54,169:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:54,403:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:54,443:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:54,446:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:54,448:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-04 16:48:54,612:INFO:Uploading results into container
2024-05-04 16:48:54,612:INFO:Uploading model into container now
2024-05-04 16:48:54,613:INFO:_master_model_container: 30
2024-05-04 16:48:54,613:INFO:_display_container: 15
2024-05-04 16:48:54,614:INFO:StackingClassifier(cv=5,
                   estimators=[('Dummy Classifier',
                                DummyClassifier(constant=None, random_state=123,
                                                strategy='prior')),
                               ('Ridge Classifier',
                                RidgeClassifier(alpha=1.0, class_weight=None,
                                                copy_X=True, fit_intercept=True,
                                                max_iter=None, positive=False,
                                                random_state=123, solver='auto',
                                                tol=0.0001)),
                               ('Quadratic Discriminant Analysis',
                                QuadraticDiscriminantAnalysis...
                                                              reg_param=0.0,
                                                              store_covariance=False,
                                                              tol=0.0001))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=7470,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-05-04 16:48:54,614:INFO:create_model() successfully completed......................................
2024-05-04 16:48:54,931:INFO:SubProcess create_model() end ==================================
2024-05-04 16:48:54,931:INFO:Creating Dashboard logs
2024-05-04 16:48:54,933:INFO:Model: Stacking Classifier
2024-05-04 16:48:54,948:INFO:Logged params: {'cv': 5, 'final_estimator__C': 1.0, 'final_estimator__class_weight': None, 'final_estimator__dual': False, 'final_estimator__fit_intercept': True, 'final_estimator__intercept_scaling': 1, 'final_estimator__l1_ratio': None, 'final_estimator__max_iter': 1000, 'final_estimator__multi_class': 'auto', 'final_estimator__n_jobs': None, 'final_estimator__penalty': 'l2', 'final_estimator__random_state': 7470, 'final_estimator__solver': 'lbfgs', 'final_estimator__tol': 0.0001, 'final_estimator__verbose': 0, 'final_estimator__warm_start': False, 'n_jobs': -1, 'passthrough': False, 'stack_method': 'auto', 'verbose': 0, 'Dummy Classifier': DummyClassifier(constant=None, random_state=123, strategy='prior'), 'Ridge Classifier': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), 'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), 'Dummy Classifier__constant': None, 'Dummy Classifier__random_state': 123, 'Dummy Classifier__strategy': 'prior', 'Ridge Classifier__alpha': 1.0, 'Ridge Classifier__class_weight': None, 'Ridge Classifier__copy_X': True, 'Ridge Classifier__fit_intercept': True, 'Ridge Classifier__max_iter': None, 'Ridge Classifier__positive': False, 'Ridge Classifier__random_state': 123, 'Ridge Classifier__solver': 'auto', 'Ridge Classifier__tol': 0.0001, 'Quadratic Discriminant Analysis__priors': None, 'Quadratic Discriminant Analysis__reg_param': 0.0, 'Quadratic Discriminant Analysis__store_covariance': False, 'Quadratic Discriminant Analysis__tol': 0.0001}
2024-05-04 16:48:54,985:INFO:Initializing predict_model()
2024-05-04 16:48:54,985:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Dummy Classifier',
                                DummyClassifier(constant=None, random_state=123,
                                                strategy='prior')),
                               ('Ridge Classifier',
                                RidgeClassifier(alpha=1.0, class_weight=None,
                                                copy_X=True, fit_intercept=True,
                                                max_iter=None, positive=False,
                                                random_state=123, solver='auto',
                                                tol=0.0001)),
                               ('Quadratic Discriminant Analysis',
                                QuadraticDiscriminantAnalysis...
                                                              reg_param=0.0,
                                                              store_covariance=False,
                                                              tol=0.0001))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=7470,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x3181258a0>)
2024-05-04 16:48:54,985:INFO:Checking exceptions
2024-05-04 16:48:54,985:INFO:Preloading libraries
2024-05-04 16:48:56,244:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py:585: UserWarning: Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/utils/generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 706, in _multiclass_roc_auc_score
    if not np.allclose(1, y_score.sum(axis=1)):
                          ^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/numpy/core/_methods.py", line 49, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(traceback.format_exc())

2024-05-04 16:48:56,246:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:48:56,863:INFO:_master_model_container: 30
2024-05-04 16:48:56,863:INFO:_display_container: 15
2024-05-04 16:48:56,864:INFO:StackingClassifier(cv=5,
                   estimators=[('Dummy Classifier',
                                DummyClassifier(constant=None, random_state=123,
                                                strategy='prior')),
                               ('Ridge Classifier',
                                RidgeClassifier(alpha=1.0, class_weight=None,
                                                copy_X=True, fit_intercept=True,
                                                max_iter=None, positive=False,
                                                random_state=123, solver='auto',
                                                tol=0.0001)),
                               ('Quadratic Discriminant Analysis',
                                QuadraticDiscriminantAnalysis...
                                                              reg_param=0.0,
                                                              store_covariance=False,
                                                              tol=0.0001))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=7470,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-05-04 16:48:56,864:INFO:stack_models() successfully completed......................................
2024-05-04 16:49:09,728:INFO:Initializing plot_model()
2024-05-04 16:49:09,728:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7470, solver='auto',
                tol=0.0001), plot=class_report, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 16:49:09,729:INFO:Checking exceptions
2024-05-04 16:49:09,735:INFO:Preloading libraries
2024-05-04 16:49:09,735:INFO:Copying training dataset
2024-05-04 16:49:09,735:INFO:Plot type: class_report
2024-05-04 16:49:12,233:INFO:Fitting Model
2024-05-04 16:49:12,233:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-05-04 16:49:12,234:INFO:Scoring test/hold-out set
2024-05-04 16:49:12,238:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:49:12,317:INFO:Visual Rendered Successfully
2024-05-04 16:49:12,539:INFO:plot_model() successfully completed......................................
2024-05-04 16:49:20,383:INFO:Initializing plot_model()
2024-05-04 16:49:20,383:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7470, solver='auto',
                tol=0.0001), plot=class_report, scale=2, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 16:49:20,383:INFO:Checking exceptions
2024-05-04 16:49:20,388:INFO:Preloading libraries
2024-05-04 16:49:20,388:INFO:Copying training dataset
2024-05-04 16:49:20,389:INFO:Plot type: class_report
2024-05-04 16:49:22,813:INFO:Fitting Model
2024-05-04 16:49:22,814:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-05-04 16:49:22,814:INFO:Scoring test/hold-out set
2024-05-04 16:49:22,818:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:49:22,925:INFO:Visual Rendered Successfully
2024-05-04 16:49:23,135:INFO:plot_model() successfully completed......................................
2024-05-04 16:49:31,355:INFO:Initializing plot_model()
2024-05-04 16:49:31,355:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7470, solver='auto',
                tol=0.0001), plot=class_report, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 16:49:31,355:INFO:Checking exceptions
2024-05-04 16:49:31,362:INFO:Preloading libraries
2024-05-04 16:49:31,362:INFO:Copying training dataset
2024-05-04 16:49:31,362:INFO:Plot type: class_report
2024-05-04 16:49:33,807:INFO:Fitting Model
2024-05-04 16:49:33,807:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-05-04 16:49:33,808:INFO:Scoring test/hold-out set
2024-05-04 16:49:33,811:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-04 16:49:33,825:INFO:Saving 'Class Report.png'
2024-05-04 16:49:33,905:INFO:Visual Rendered Successfully
2024-05-04 16:49:34,118:INFO:plot_model() successfully completed......................................
2024-05-04 16:49:40,598:INFO:Initializing create_model()
2024-05-04 16:49:40,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3344b97d0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 16:49:40,598:INFO:Checking exceptions
2024-05-04 16:49:40,604:INFO:Importing libraries
2024-05-04 16:49:40,605:INFO:Copying training dataset
2024-05-04 16:49:40,616:INFO:Defining folds
2024-05-04 16:49:40,616:INFO:Declaring metric variables
2024-05-04 16:49:40,618:INFO:Importing untrained model
2024-05-04 16:49:40,620:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 16:49:40,623:INFO:Starting cross validation
2024-05-04 16:49:40,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:20:07,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 17:20:07,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 17:20:07,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 17:20:07,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 17:20:07,333:INFO:PyCaret RegressionExperiment
2024-05-04 17:20:07,333:INFO:Logging name: reg-default-name
2024-05-04 17:20:07,333:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 17:20:07,333:INFO:version 3.3.2
2024-05-04 17:20:07,333:INFO:Initializing setup()
2024-05-04 17:20:07,333:INFO:self.USI: f555
2024-05-04 17:20:07,333:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 17:20:07,333:INFO:Checking environment
2024-05-04 17:20:07,333:INFO:python_version: 3.11.8
2024-05-04 17:20:07,333:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 17:20:07,333:INFO:machine: arm64
2024-05-04 17:20:07,333:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:20:07,333:INFO:Memory: svmem(total=17179869184, available=4538548224, percent=73.6, used=6264569856, free=22347776, active=4521771008, inactive=4438966272, wired=1742798848)
2024-05-04 17:20:07,333:INFO:Physical Core: 8
2024-05-04 17:20:07,333:INFO:Logical Core: 8
2024-05-04 17:20:07,333:INFO:Checking libraries
2024-05-04 17:20:07,333:INFO:System:
2024-05-04 17:20:07,333:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 17:20:07,333:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 17:20:07,333:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:20:07,333:INFO:PyCaret required dependencies:
2024-05-04 17:20:07,806:INFO:                 pip: 24.0
2024-05-04 17:20:07,807:INFO:          setuptools: 69.2.0
2024-05-04 17:20:07,807:INFO:             pycaret: 3.3.2
2024-05-04 17:20:07,807:INFO:             IPython: 8.22.2
2024-05-04 17:20:07,807:INFO:          ipywidgets: 8.1.2
2024-05-04 17:20:07,807:INFO:                tqdm: 4.66.2
2024-05-04 17:20:07,807:INFO:               numpy: 1.26.4
2024-05-04 17:20:07,807:INFO:              pandas: 2.1.4
2024-05-04 17:20:07,807:INFO:              jinja2: 3.1.3
2024-05-04 17:20:07,807:INFO:               scipy: 1.11.4
2024-05-04 17:20:07,807:INFO:              joblib: 1.3.2
2024-05-04 17:20:07,807:INFO:             sklearn: 1.4.1.post1
2024-05-04 17:20:07,807:INFO:                pyod: 1.1.3
2024-05-04 17:20:07,807:INFO:            imblearn: 0.12.2
2024-05-04 17:20:07,807:INFO:   category_encoders: 2.6.3
2024-05-04 17:20:07,807:INFO:            lightgbm: 4.3.0
2024-05-04 17:20:07,807:INFO:               numba: 0.59.1
2024-05-04 17:20:07,807:INFO:            requests: 2.31.0
2024-05-04 17:20:07,807:INFO:          matplotlib: 3.7.5
2024-05-04 17:20:07,807:INFO:          scikitplot: 0.3.7
2024-05-04 17:20:07,807:INFO:         yellowbrick: 1.5
2024-05-04 17:20:07,807:INFO:              plotly: 5.19.0
2024-05-04 17:20:07,807:INFO:    plotly-resampler: Not installed
2024-05-04 17:20:07,807:INFO:             kaleido: 0.2.1
2024-05-04 17:20:07,807:INFO:           schemdraw: 0.15
2024-05-04 17:20:07,807:INFO:         statsmodels: 0.14.1
2024-05-04 17:20:07,807:INFO:              sktime: 0.26.0
2024-05-04 17:20:07,807:INFO:               tbats: 1.1.3
2024-05-04 17:20:07,807:INFO:            pmdarima: 2.0.4
2024-05-04 17:20:07,807:INFO:              psutil: 5.9.8
2024-05-04 17:20:07,807:INFO:          markupsafe: 2.1.5
2024-05-04 17:20:07,807:INFO:             pickle5: Not installed
2024-05-04 17:20:07,807:INFO:         cloudpickle: 3.0.0
2024-05-04 17:20:07,807:INFO:         deprecation: 2.1.0
2024-05-04 17:20:07,807:INFO:              xxhash: 3.4.1
2024-05-04 17:20:07,807:INFO:           wurlitzer: 3.0.3
2024-05-04 17:20:07,807:INFO:PyCaret optional dependencies:
2024-05-04 17:20:08,801:INFO:                shap: 0.44.1
2024-05-04 17:20:08,801:INFO:           interpret: 0.6.1
2024-05-04 17:20:08,801:INFO:                umap: 0.5.6
2024-05-04 17:20:08,801:INFO:     ydata_profiling: 4.7.0
2024-05-04 17:20:08,801:INFO:  explainerdashboard: 0.4.7
2024-05-04 17:20:08,801:INFO:             autoviz: Not installed
2024-05-04 17:20:08,801:INFO:           fairlearn: 0.7.0
2024-05-04 17:20:08,801:INFO:          deepchecks: Not installed
2024-05-04 17:20:08,801:INFO:             xgboost: Not installed
2024-05-04 17:20:08,801:INFO:            catboost: Not installed
2024-05-04 17:20:08,801:INFO:              kmodes: Not installed
2024-05-04 17:20:08,801:INFO:             mlxtend: 0.23.1
2024-05-04 17:20:08,801:INFO:       statsforecast: Not installed
2024-05-04 17:20:08,801:INFO:        tune_sklearn: Not installed
2024-05-04 17:20:08,801:INFO:                 ray: Not installed
2024-05-04 17:20:08,801:INFO:            hyperopt: 0.2.7
2024-05-04 17:20:08,801:INFO:              optuna: 3.6.1
2024-05-04 17:20:08,801:INFO:               skopt: 0.10.1
2024-05-04 17:20:08,801:INFO:              mlflow: 2.12.1
2024-05-04 17:20:08,801:INFO:              gradio: 4.29.0
2024-05-04 17:20:08,801:INFO:             fastapi: 0.111.0
2024-05-04 17:20:08,801:INFO:             uvicorn: 0.29.0
2024-05-04 17:20:08,801:INFO:              m2cgen: 0.10.0
2024-05-04 17:20:08,801:INFO:           evidently: 0.4.20
2024-05-04 17:20:08,801:INFO:               fugue: 0.8.7
2024-05-04 17:20:08,801:INFO:           streamlit: 1.33.0
2024-05-04 17:20:08,801:INFO:             prophet: Not installed
2024-05-04 17:20:08,801:INFO:None
2024-05-04 17:20:08,801:INFO:Set up data.
2024-05-04 17:20:09,278:INFO:Set up folding strategy.
2024-05-04 17:20:09,279:INFO:Set up train/test split.
2024-05-04 17:20:09,447:INFO:Set up index.
2024-05-04 17:20:09,448:INFO:Assigning column types.
2024-05-04 17:20:09,453:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 17:20:09,453:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,455:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,457:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,495:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,520:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,521:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,523:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,525:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,577:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 17:20:09,579:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,636:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,638:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,669:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,689:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,689:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,689:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 17:20:09,693:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,723:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,742:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,746:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,775:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,794:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 17:20:09,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,879:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,898:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,898:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 17:20:09,931:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:09,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:09,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:20:10,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:10,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:10,002:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 17:20:10,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:10,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:10,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:10,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:20:10,106:INFO:Preparing preprocessing pipeline...
2024-05-04 17:20:10,106:INFO:Set up simple imputation.
2024-05-04 17:20:10,115:INFO:Set up encoding of categorical features.
2024-05-04 17:22:12,139:INFO:PyCaret RegressionExperiment
2024-05-04 17:22:12,139:INFO:Logging name: reg-default-name
2024-05-04 17:22:12,139:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 17:22:12,139:INFO:version 3.3.2
2024-05-04 17:22:12,139:INFO:Initializing setup()
2024-05-04 17:22:12,139:INFO:self.USI: a03e
2024-05-04 17:22:12,139:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 17:22:12,139:INFO:Checking environment
2024-05-04 17:22:12,139:INFO:python_version: 3.11.8
2024-05-04 17:22:12,139:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 17:22:12,139:INFO:machine: arm64
2024-05-04 17:22:12,139:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:22:12,139:INFO:Memory: svmem(total=17179869184, available=4314955776, percent=74.9, used=6053347328, free=217022464, active=4103831552, inactive=4093280256, wired=1949515776)
2024-05-04 17:22:12,139:INFO:Physical Core: 8
2024-05-04 17:22:12,139:INFO:Logical Core: 8
2024-05-04 17:22:12,139:INFO:Checking libraries
2024-05-04 17:22:12,139:INFO:System:
2024-05-04 17:22:12,139:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 17:22:12,139:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 17:22:12,140:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:22:12,140:INFO:PyCaret required dependencies:
2024-05-04 17:22:12,140:INFO:                 pip: 24.0
2024-05-04 17:22:12,140:INFO:          setuptools: 69.2.0
2024-05-04 17:22:12,140:INFO:             pycaret: 3.3.2
2024-05-04 17:22:12,140:INFO:             IPython: 8.22.2
2024-05-04 17:22:12,140:INFO:          ipywidgets: 8.1.2
2024-05-04 17:22:12,140:INFO:                tqdm: 4.66.2
2024-05-04 17:22:12,140:INFO:               numpy: 1.26.4
2024-05-04 17:22:12,140:INFO:              pandas: 2.1.4
2024-05-04 17:22:12,140:INFO:              jinja2: 3.1.3
2024-05-04 17:22:12,140:INFO:               scipy: 1.11.4
2024-05-04 17:22:12,140:INFO:              joblib: 1.3.2
2024-05-04 17:22:12,140:INFO:             sklearn: 1.4.1.post1
2024-05-04 17:22:12,140:INFO:                pyod: 1.1.3
2024-05-04 17:22:12,140:INFO:            imblearn: 0.12.2
2024-05-04 17:22:12,140:INFO:   category_encoders: 2.6.3
2024-05-04 17:22:12,140:INFO:            lightgbm: 4.3.0
2024-05-04 17:22:12,140:INFO:               numba: 0.59.1
2024-05-04 17:22:12,140:INFO:            requests: 2.31.0
2024-05-04 17:22:12,140:INFO:          matplotlib: 3.7.5
2024-05-04 17:22:12,140:INFO:          scikitplot: 0.3.7
2024-05-04 17:22:12,140:INFO:         yellowbrick: 1.5
2024-05-04 17:22:12,140:INFO:              plotly: 5.19.0
2024-05-04 17:22:12,140:INFO:    plotly-resampler: Not installed
2024-05-04 17:22:12,140:INFO:             kaleido: 0.2.1
2024-05-04 17:22:12,140:INFO:           schemdraw: 0.15
2024-05-04 17:22:12,140:INFO:         statsmodels: 0.14.1
2024-05-04 17:22:12,140:INFO:              sktime: 0.26.0
2024-05-04 17:22:12,140:INFO:               tbats: 1.1.3
2024-05-04 17:22:12,140:INFO:            pmdarima: 2.0.4
2024-05-04 17:22:12,140:INFO:              psutil: 5.9.8
2024-05-04 17:22:12,140:INFO:          markupsafe: 2.1.5
2024-05-04 17:22:12,140:INFO:             pickle5: Not installed
2024-05-04 17:22:12,140:INFO:         cloudpickle: 3.0.0
2024-05-04 17:22:12,140:INFO:         deprecation: 2.1.0
2024-05-04 17:22:12,140:INFO:              xxhash: 3.4.1
2024-05-04 17:22:12,140:INFO:           wurlitzer: 3.0.3
2024-05-04 17:22:12,140:INFO:PyCaret optional dependencies:
2024-05-04 17:22:12,140:INFO:                shap: 0.44.1
2024-05-04 17:22:12,140:INFO:           interpret: 0.6.1
2024-05-04 17:22:12,140:INFO:                umap: 0.5.6
2024-05-04 17:22:12,140:INFO:     ydata_profiling: 4.7.0
2024-05-04 17:22:12,140:INFO:  explainerdashboard: 0.4.7
2024-05-04 17:22:12,140:INFO:             autoviz: Not installed
2024-05-04 17:22:12,140:INFO:           fairlearn: 0.7.0
2024-05-04 17:22:12,140:INFO:          deepchecks: Not installed
2024-05-04 17:22:12,140:INFO:             xgboost: Not installed
2024-05-04 17:22:12,140:INFO:            catboost: Not installed
2024-05-04 17:22:12,140:INFO:              kmodes: Not installed
2024-05-04 17:22:12,140:INFO:             mlxtend: 0.23.1
2024-05-04 17:22:12,140:INFO:       statsforecast: Not installed
2024-05-04 17:22:12,140:INFO:        tune_sklearn: Not installed
2024-05-04 17:22:12,140:INFO:                 ray: Not installed
2024-05-04 17:22:12,140:INFO:            hyperopt: 0.2.7
2024-05-04 17:22:12,140:INFO:              optuna: 3.6.1
2024-05-04 17:22:12,140:INFO:               skopt: 0.10.1
2024-05-04 17:22:12,140:INFO:              mlflow: 2.12.1
2024-05-04 17:22:12,140:INFO:              gradio: 4.29.0
2024-05-04 17:22:12,140:INFO:             fastapi: 0.111.0
2024-05-04 17:22:12,140:INFO:             uvicorn: 0.29.0
2024-05-04 17:22:12,140:INFO:              m2cgen: 0.10.0
2024-05-04 17:22:12,140:INFO:           evidently: 0.4.20
2024-05-04 17:22:12,140:INFO:               fugue: 0.8.7
2024-05-04 17:22:12,140:INFO:           streamlit: 1.33.0
2024-05-04 17:22:12,140:INFO:             prophet: Not installed
2024-05-04 17:22:12,141:INFO:None
2024-05-04 17:22:12,141:INFO:Set up data.
2024-05-04 17:22:12,615:INFO:Set up folding strategy.
2024-05-04 17:22:12,616:INFO:Set up train/test split.
2024-05-04 17:22:12,793:INFO:Set up index.
2024-05-04 17:22:12,794:INFO:Assigning column types.
2024-05-04 17:22:12,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 17:22:12,799:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,801:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,803:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,833:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:12,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:12,853:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,855:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,857:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,887:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:12,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:12,906:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 17:22:12,908:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,910:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:12,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:12,961:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,963:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:12,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,010:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 17:22:13,014:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,066:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,115:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 17:22:13,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,203:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,223:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,223:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 17:22:13,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,480:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:13,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,500:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 17:22:13,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:13,610:INFO:Preparing preprocessing pipeline...
2024-05-04 17:22:13,610:INFO:Set up simple imputation.
2024-05-04 17:22:13,620:INFO:Set up encoding of categorical features.
2024-05-04 17:22:56,314:INFO:PyCaret RegressionExperiment
2024-05-04 17:22:56,314:INFO:Logging name: reg-default-name
2024-05-04 17:22:56,314:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 17:22:56,314:INFO:version 3.3.2
2024-05-04 17:22:56,314:INFO:Initializing setup()
2024-05-04 17:22:56,314:INFO:self.USI: 9b0e
2024-05-04 17:22:56,314:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 17:22:56,314:INFO:Checking environment
2024-05-04 17:22:56,314:INFO:python_version: 3.11.8
2024-05-04 17:22:56,314:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 17:22:56,314:INFO:machine: arm64
2024-05-04 17:22:56,314:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:22:56,314:INFO:Memory: svmem(total=17179869184, available=4220665856, percent=75.4, used=5990498304, free=170967040, active=4048633856, inactive=4044783616, wired=1941864448)
2024-05-04 17:22:56,314:INFO:Physical Core: 8
2024-05-04 17:22:56,314:INFO:Logical Core: 8
2024-05-04 17:22:56,314:INFO:Checking libraries
2024-05-04 17:22:56,314:INFO:System:
2024-05-04 17:22:56,314:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 17:22:56,314:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 17:22:56,314:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:22:56,314:INFO:PyCaret required dependencies:
2024-05-04 17:22:56,314:INFO:                 pip: 24.0
2024-05-04 17:22:56,314:INFO:          setuptools: 69.2.0
2024-05-04 17:22:56,314:INFO:             pycaret: 3.3.2
2024-05-04 17:22:56,314:INFO:             IPython: 8.22.2
2024-05-04 17:22:56,314:INFO:          ipywidgets: 8.1.2
2024-05-04 17:22:56,314:INFO:                tqdm: 4.66.2
2024-05-04 17:22:56,314:INFO:               numpy: 1.26.4
2024-05-04 17:22:56,314:INFO:              pandas: 2.1.4
2024-05-04 17:22:56,314:INFO:              jinja2: 3.1.3
2024-05-04 17:22:56,314:INFO:               scipy: 1.11.4
2024-05-04 17:22:56,314:INFO:              joblib: 1.3.2
2024-05-04 17:22:56,314:INFO:             sklearn: 1.4.1.post1
2024-05-04 17:22:56,315:INFO:                pyod: 1.1.3
2024-05-04 17:22:56,315:INFO:            imblearn: 0.12.2
2024-05-04 17:22:56,315:INFO:   category_encoders: 2.6.3
2024-05-04 17:22:56,315:INFO:            lightgbm: 4.3.0
2024-05-04 17:22:56,315:INFO:               numba: 0.59.1
2024-05-04 17:22:56,315:INFO:            requests: 2.31.0
2024-05-04 17:22:56,315:INFO:          matplotlib: 3.7.5
2024-05-04 17:22:56,315:INFO:          scikitplot: 0.3.7
2024-05-04 17:22:56,315:INFO:         yellowbrick: 1.5
2024-05-04 17:22:56,315:INFO:              plotly: 5.19.0
2024-05-04 17:22:56,315:INFO:    plotly-resampler: Not installed
2024-05-04 17:22:56,315:INFO:             kaleido: 0.2.1
2024-05-04 17:22:56,315:INFO:           schemdraw: 0.15
2024-05-04 17:22:56,315:INFO:         statsmodels: 0.14.1
2024-05-04 17:22:56,315:INFO:              sktime: 0.26.0
2024-05-04 17:22:56,315:INFO:               tbats: 1.1.3
2024-05-04 17:22:56,315:INFO:            pmdarima: 2.0.4
2024-05-04 17:22:56,315:INFO:              psutil: 5.9.8
2024-05-04 17:22:56,315:INFO:          markupsafe: 2.1.5
2024-05-04 17:22:56,315:INFO:             pickle5: Not installed
2024-05-04 17:22:56,315:INFO:         cloudpickle: 3.0.0
2024-05-04 17:22:56,315:INFO:         deprecation: 2.1.0
2024-05-04 17:22:56,315:INFO:              xxhash: 3.4.1
2024-05-04 17:22:56,315:INFO:           wurlitzer: 3.0.3
2024-05-04 17:22:56,315:INFO:PyCaret optional dependencies:
2024-05-04 17:22:56,315:INFO:                shap: 0.44.1
2024-05-04 17:22:56,315:INFO:           interpret: 0.6.1
2024-05-04 17:22:56,315:INFO:                umap: 0.5.6
2024-05-04 17:22:56,315:INFO:     ydata_profiling: 4.7.0
2024-05-04 17:22:56,315:INFO:  explainerdashboard: 0.4.7
2024-05-04 17:22:56,315:INFO:             autoviz: Not installed
2024-05-04 17:22:56,315:INFO:           fairlearn: 0.7.0
2024-05-04 17:22:56,315:INFO:          deepchecks: Not installed
2024-05-04 17:22:56,315:INFO:             xgboost: Not installed
2024-05-04 17:22:56,315:INFO:            catboost: Not installed
2024-05-04 17:22:56,315:INFO:              kmodes: Not installed
2024-05-04 17:22:56,315:INFO:             mlxtend: 0.23.1
2024-05-04 17:22:56,315:INFO:       statsforecast: Not installed
2024-05-04 17:22:56,315:INFO:        tune_sklearn: Not installed
2024-05-04 17:22:56,315:INFO:                 ray: Not installed
2024-05-04 17:22:56,315:INFO:            hyperopt: 0.2.7
2024-05-04 17:22:56,315:INFO:              optuna: 3.6.1
2024-05-04 17:22:56,315:INFO:               skopt: 0.10.1
2024-05-04 17:22:56,315:INFO:              mlflow: 2.12.1
2024-05-04 17:22:56,315:INFO:              gradio: 4.29.0
2024-05-04 17:22:56,315:INFO:             fastapi: 0.111.0
2024-05-04 17:22:56,315:INFO:             uvicorn: 0.29.0
2024-05-04 17:22:56,315:INFO:              m2cgen: 0.10.0
2024-05-04 17:22:56,315:INFO:           evidently: 0.4.20
2024-05-04 17:22:56,315:INFO:               fugue: 0.8.7
2024-05-04 17:22:56,315:INFO:           streamlit: 1.33.0
2024-05-04 17:22:56,315:INFO:             prophet: Not installed
2024-05-04 17:22:56,315:INFO:None
2024-05-04 17:22:56,315:INFO:Set up data.
2024-05-04 17:22:56,333:INFO:Set up folding strategy.
2024-05-04 17:22:56,334:INFO:Set up train/test split.
2024-05-04 17:22:56,350:INFO:Set up index.
2024-05-04 17:22:56,350:INFO:Assigning column types.
2024-05-04 17:22:56,364:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 17:22:56,364:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,366:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,368:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,424:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,424:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,426:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,428:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,485:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 17:22:56,487:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,489:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,548:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,550:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,607:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,607:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 17:22:56,611:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,672:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,728:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,729:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,729:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 17:22:56,769:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,849:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 17:22:56,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:22:56,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:56,969:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 17:22:57,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:57,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:57,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:57,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:57,090:INFO:Preparing preprocessing pipeline...
2024-05-04 17:22:57,090:INFO:Set up simple imputation.
2024-05-04 17:22:57,135:INFO:Finished creating preprocessing pipeline.
2024-05-04 17:22:57,136:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group', 'I1', 'I2', 'I3', 'I4',
                                             'I5', 'I6', 'I7', 'I8', 'I9',
                                             'I10', 'I11', 'I12', 'I13', 'I14',
                                             'I15', 'I16', 'I17', 'I18', 'I19',
                                             'I20', 'I21', 'I22', 'I23', 'I24',
                                             'I25', 'I26', 'I27', 'I28', 'I29', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-05-04 17:22:57,137:INFO:Creating final display dataframe.
2024-05-04 17:22:57,276:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Perform
2                   Target type        Regression
3           Original data shape       (8000, 118)
4        Transformed data shape       (8000, 118)
5   Transformed train set shape       (5600, 118)
6    Transformed test set shape       (2400, 118)
7              Numeric features               117
8      Rows with missing values             35.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator             KFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  reg-default-name
19                          USI              9b0e
2024-05-04 17:22:57,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:57,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:57,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:57,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:22:57,402:INFO:setup() successfully completed in 1.09s...............
2024-05-04 17:23:21,160:INFO:PyCaret RegressionExperiment
2024-05-04 17:23:21,160:INFO:Logging name: reg-default-name
2024-05-04 17:23:21,160:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 17:23:21,160:INFO:version 3.3.2
2024-05-04 17:23:21,160:INFO:Initializing setup()
2024-05-04 17:23:21,160:INFO:self.USI: 7e3b
2024-05-04 17:23:21,160:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 17:23:21,160:INFO:Checking environment
2024-05-04 17:23:21,160:INFO:python_version: 3.11.8
2024-05-04 17:23:21,160:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 17:23:21,160:INFO:machine: arm64
2024-05-04 17:23:21,160:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:23:21,160:INFO:Memory: svmem(total=17179869184, available=4197220352, percent=75.6, used=6005932032, free=66813952, active=4136222720, inactive=4105437184, wired=1869709312)
2024-05-04 17:23:21,160:INFO:Physical Core: 8
2024-05-04 17:23:21,160:INFO:Logical Core: 8
2024-05-04 17:23:21,160:INFO:Checking libraries
2024-05-04 17:23:21,160:INFO:System:
2024-05-04 17:23:21,160:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 17:23:21,160:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 17:23:21,160:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:23:21,160:INFO:PyCaret required dependencies:
2024-05-04 17:23:21,161:INFO:                 pip: 24.0
2024-05-04 17:23:21,161:INFO:          setuptools: 69.2.0
2024-05-04 17:23:21,161:INFO:             pycaret: 3.3.2
2024-05-04 17:23:21,161:INFO:             IPython: 8.22.2
2024-05-04 17:23:21,161:INFO:          ipywidgets: 8.1.2
2024-05-04 17:23:21,161:INFO:                tqdm: 4.66.2
2024-05-04 17:23:21,161:INFO:               numpy: 1.26.4
2024-05-04 17:23:21,161:INFO:              pandas: 2.1.4
2024-05-04 17:23:21,161:INFO:              jinja2: 3.1.3
2024-05-04 17:23:21,161:INFO:               scipy: 1.11.4
2024-05-04 17:23:21,161:INFO:              joblib: 1.3.2
2024-05-04 17:23:21,161:INFO:             sklearn: 1.4.1.post1
2024-05-04 17:23:21,161:INFO:                pyod: 1.1.3
2024-05-04 17:23:21,161:INFO:            imblearn: 0.12.2
2024-05-04 17:23:21,161:INFO:   category_encoders: 2.6.3
2024-05-04 17:23:21,161:INFO:            lightgbm: 4.3.0
2024-05-04 17:23:21,161:INFO:               numba: 0.59.1
2024-05-04 17:23:21,161:INFO:            requests: 2.31.0
2024-05-04 17:23:21,161:INFO:          matplotlib: 3.7.5
2024-05-04 17:23:21,161:INFO:          scikitplot: 0.3.7
2024-05-04 17:23:21,161:INFO:         yellowbrick: 1.5
2024-05-04 17:23:21,161:INFO:              plotly: 5.19.0
2024-05-04 17:23:21,161:INFO:    plotly-resampler: Not installed
2024-05-04 17:23:21,161:INFO:             kaleido: 0.2.1
2024-05-04 17:23:21,161:INFO:           schemdraw: 0.15
2024-05-04 17:23:21,161:INFO:         statsmodels: 0.14.1
2024-05-04 17:23:21,161:INFO:              sktime: 0.26.0
2024-05-04 17:23:21,161:INFO:               tbats: 1.1.3
2024-05-04 17:23:21,161:INFO:            pmdarima: 2.0.4
2024-05-04 17:23:21,161:INFO:              psutil: 5.9.8
2024-05-04 17:23:21,161:INFO:          markupsafe: 2.1.5
2024-05-04 17:23:21,161:INFO:             pickle5: Not installed
2024-05-04 17:23:21,161:INFO:         cloudpickle: 3.0.0
2024-05-04 17:23:21,161:INFO:         deprecation: 2.1.0
2024-05-04 17:23:21,161:INFO:              xxhash: 3.4.1
2024-05-04 17:23:21,161:INFO:           wurlitzer: 3.0.3
2024-05-04 17:23:21,161:INFO:PyCaret optional dependencies:
2024-05-04 17:23:21,161:INFO:                shap: 0.44.1
2024-05-04 17:23:21,161:INFO:           interpret: 0.6.1
2024-05-04 17:23:21,161:INFO:                umap: 0.5.6
2024-05-04 17:23:21,161:INFO:     ydata_profiling: 4.7.0
2024-05-04 17:23:21,161:INFO:  explainerdashboard: 0.4.7
2024-05-04 17:23:21,161:INFO:             autoviz: Not installed
2024-05-04 17:23:21,161:INFO:           fairlearn: 0.7.0
2024-05-04 17:23:21,161:INFO:          deepchecks: Not installed
2024-05-04 17:23:21,161:INFO:             xgboost: Not installed
2024-05-04 17:23:21,161:INFO:            catboost: Not installed
2024-05-04 17:23:21,162:INFO:              kmodes: Not installed
2024-05-04 17:23:21,162:INFO:             mlxtend: 0.23.1
2024-05-04 17:23:21,162:INFO:       statsforecast: Not installed
2024-05-04 17:23:21,162:INFO:        tune_sklearn: Not installed
2024-05-04 17:23:21,162:INFO:                 ray: Not installed
2024-05-04 17:23:21,162:INFO:            hyperopt: 0.2.7
2024-05-04 17:23:21,162:INFO:              optuna: 3.6.1
2024-05-04 17:23:21,162:INFO:               skopt: 0.10.1
2024-05-04 17:23:21,162:INFO:              mlflow: 2.12.1
2024-05-04 17:23:21,162:INFO:              gradio: 4.29.0
2024-05-04 17:23:21,162:INFO:             fastapi: 0.111.0
2024-05-04 17:23:21,162:INFO:             uvicorn: 0.29.0
2024-05-04 17:23:21,162:INFO:              m2cgen: 0.10.0
2024-05-04 17:23:21,162:INFO:           evidently: 0.4.20
2024-05-04 17:23:21,162:INFO:               fugue: 0.8.7
2024-05-04 17:23:21,162:INFO:           streamlit: 1.33.0
2024-05-04 17:23:21,162:INFO:             prophet: Not installed
2024-05-04 17:23:21,162:INFO:None
2024-05-04 17:23:21,162:INFO:Set up data.
2024-05-04 17:23:27,814:INFO:PyCaret RegressionExperiment
2024-05-04 17:23:27,814:INFO:Logging name: reg-default-name
2024-05-04 17:23:27,814:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 17:23:27,814:INFO:version 3.3.2
2024-05-04 17:23:27,814:INFO:Initializing setup()
2024-05-04 17:23:27,814:INFO:self.USI: f994
2024-05-04 17:23:27,814:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 17:23:27,814:INFO:Checking environment
2024-05-04 17:23:27,814:INFO:python_version: 3.11.8
2024-05-04 17:23:27,814:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 17:23:27,814:INFO:machine: arm64
2024-05-04 17:23:27,814:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:23:27,814:INFO:Memory: svmem(total=17179869184, available=4142186496, percent=75.9, used=6066257920, free=81625088, active=4080091136, inactive=4035051520, wired=1986166784)
2024-05-04 17:23:27,814:INFO:Physical Core: 8
2024-05-04 17:23:27,814:INFO:Logical Core: 8
2024-05-04 17:23:27,814:INFO:Checking libraries
2024-05-04 17:23:27,814:INFO:System:
2024-05-04 17:23:27,814:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 17:23:27,814:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 17:23:27,814:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:23:27,814:INFO:PyCaret required dependencies:
2024-05-04 17:23:27,814:INFO:                 pip: 24.0
2024-05-04 17:23:27,814:INFO:          setuptools: 69.2.0
2024-05-04 17:23:27,814:INFO:             pycaret: 3.3.2
2024-05-04 17:23:27,814:INFO:             IPython: 8.22.2
2024-05-04 17:23:27,814:INFO:          ipywidgets: 8.1.2
2024-05-04 17:23:27,814:INFO:                tqdm: 4.66.2
2024-05-04 17:23:27,814:INFO:               numpy: 1.26.4
2024-05-04 17:23:27,814:INFO:              pandas: 2.1.4
2024-05-04 17:23:27,814:INFO:              jinja2: 3.1.3
2024-05-04 17:23:27,814:INFO:               scipy: 1.11.4
2024-05-04 17:23:27,814:INFO:              joblib: 1.3.2
2024-05-04 17:23:27,814:INFO:             sklearn: 1.4.1.post1
2024-05-04 17:23:27,814:INFO:                pyod: 1.1.3
2024-05-04 17:23:27,814:INFO:            imblearn: 0.12.2
2024-05-04 17:23:27,814:INFO:   category_encoders: 2.6.3
2024-05-04 17:23:27,814:INFO:            lightgbm: 4.3.0
2024-05-04 17:23:27,814:INFO:               numba: 0.59.1
2024-05-04 17:23:27,814:INFO:            requests: 2.31.0
2024-05-04 17:23:27,814:INFO:          matplotlib: 3.7.5
2024-05-04 17:23:27,814:INFO:          scikitplot: 0.3.7
2024-05-04 17:23:27,814:INFO:         yellowbrick: 1.5
2024-05-04 17:23:27,814:INFO:              plotly: 5.19.0
2024-05-04 17:23:27,814:INFO:    plotly-resampler: Not installed
2024-05-04 17:23:27,814:INFO:             kaleido: 0.2.1
2024-05-04 17:23:27,814:INFO:           schemdraw: 0.15
2024-05-04 17:23:27,814:INFO:         statsmodels: 0.14.1
2024-05-04 17:23:27,814:INFO:              sktime: 0.26.0
2024-05-04 17:23:27,814:INFO:               tbats: 1.1.3
2024-05-04 17:23:27,814:INFO:            pmdarima: 2.0.4
2024-05-04 17:23:27,814:INFO:              psutil: 5.9.8
2024-05-04 17:23:27,814:INFO:          markupsafe: 2.1.5
2024-05-04 17:23:27,814:INFO:             pickle5: Not installed
2024-05-04 17:23:27,814:INFO:         cloudpickle: 3.0.0
2024-05-04 17:23:27,814:INFO:         deprecation: 2.1.0
2024-05-04 17:23:27,814:INFO:              xxhash: 3.4.1
2024-05-04 17:23:27,814:INFO:           wurlitzer: 3.0.3
2024-05-04 17:23:27,814:INFO:PyCaret optional dependencies:
2024-05-04 17:23:27,815:INFO:                shap: 0.44.1
2024-05-04 17:23:27,815:INFO:           interpret: 0.6.1
2024-05-04 17:23:27,815:INFO:                umap: 0.5.6
2024-05-04 17:23:27,815:INFO:     ydata_profiling: 4.7.0
2024-05-04 17:23:27,815:INFO:  explainerdashboard: 0.4.7
2024-05-04 17:23:27,815:INFO:             autoviz: Not installed
2024-05-04 17:23:27,815:INFO:           fairlearn: 0.7.0
2024-05-04 17:23:27,815:INFO:          deepchecks: Not installed
2024-05-04 17:23:27,815:INFO:             xgboost: Not installed
2024-05-04 17:23:27,815:INFO:            catboost: Not installed
2024-05-04 17:23:27,815:INFO:              kmodes: Not installed
2024-05-04 17:23:27,815:INFO:             mlxtend: 0.23.1
2024-05-04 17:23:27,815:INFO:       statsforecast: Not installed
2024-05-04 17:23:27,815:INFO:        tune_sklearn: Not installed
2024-05-04 17:23:27,815:INFO:                 ray: Not installed
2024-05-04 17:23:27,815:INFO:            hyperopt: 0.2.7
2024-05-04 17:23:27,815:INFO:              optuna: 3.6.1
2024-05-04 17:23:27,815:INFO:               skopt: 0.10.1
2024-05-04 17:23:27,815:INFO:              mlflow: 2.12.1
2024-05-04 17:23:27,815:INFO:              gradio: 4.29.0
2024-05-04 17:23:27,815:INFO:             fastapi: 0.111.0
2024-05-04 17:23:27,815:INFO:             uvicorn: 0.29.0
2024-05-04 17:23:27,815:INFO:              m2cgen: 0.10.0
2024-05-04 17:23:27,815:INFO:           evidently: 0.4.20
2024-05-04 17:23:27,815:INFO:               fugue: 0.8.7
2024-05-04 17:23:27,815:INFO:           streamlit: 1.33.0
2024-05-04 17:23:27,815:INFO:             prophet: Not installed
2024-05-04 17:23:27,815:INFO:None
2024-05-04 17:23:27,815:INFO:Set up data.
2024-05-04 17:23:27,830:INFO:Set up folding strategy.
2024-05-04 17:23:27,830:INFO:Set up train/test split.
2024-05-04 17:23:27,847:INFO:Set up index.
2024-05-04 17:23:27,848:INFO:Assigning column types.
2024-05-04 17:23:27,868:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 17:23:27,869:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:23:27,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:23:27,875:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:23:27,941:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:27,961:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:23:27,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:27,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:27,962:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:23:27,964:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:23:27,966:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,005:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,027:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,027:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 17:23:28,029:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,031:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,071:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,093:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,095:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,153:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 17:23:28,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,216:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,272:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,272:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 17:23:28,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,331:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,392:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 17:23:28,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,493:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:23:28,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,513:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 17:23:28,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,634:INFO:Preparing preprocessing pipeline...
2024-05-04 17:23:28,634:INFO:Set up simple imputation.
2024-05-04 17:23:28,674:INFO:Finished creating preprocessing pipeline.
2024-05-04 17:23:28,676:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group', 'I1', 'I2', 'I3', 'I4',
                                             'I5', 'I6', 'I7', 'I8', 'I9',
                                             'I10', 'I11', 'I12', 'I13', 'I14',
                                             'I15', 'I16', 'I17', 'I18', 'I19',
                                             'I20', 'I21', 'I22', 'I23', 'I24',
                                             'I25', 'I26', 'I27', 'I28', 'I29', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-05-04 17:23:28,676:INFO:Creating final display dataframe.
2024-05-04 17:23:28,806:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Perform
2                   Target type        Regression
3           Original data shape       (8000, 118)
4        Transformed data shape       (8000, 118)
5   Transformed train set shape       (5600, 118)
6    Transformed test set shape       (2400, 118)
7              Numeric features               117
8      Rows with missing values             35.1%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator             KFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  reg-default-name
19                          USI              f994
2024-05-04 17:23:28,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:23:28,932:INFO:setup() successfully completed in 1.12s...............
2024-05-04 17:23:33,535:INFO:Initializing compare_models()
2024-05-04 17:23:33,535:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-04 17:23:33,535:INFO:Checking exceptions
2024-05-04 17:23:33,547:INFO:Preparing display monitor
2024-05-04 17:23:33,588:INFO:Initializing Linear Regression
2024-05-04 17:23:33,588:INFO:Total runtime is 3.2027562459309896e-06 minutes
2024-05-04 17:23:33,590:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:33,590:INFO:Initializing create_model()
2024-05-04 17:23:33,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:33,590:INFO:Checking exceptions
2024-05-04 17:23:33,590:INFO:Importing libraries
2024-05-04 17:23:33,590:INFO:Copying training dataset
2024-05-04 17:23:33,614:INFO:Defining folds
2024-05-04 17:23:33,614:INFO:Declaring metric variables
2024-05-04 17:23:33,615:INFO:Importing untrained model
2024-05-04 17:23:33,617:INFO:Linear Regression Imported successfully
2024-05-04 17:23:33,619:INFO:Starting cross validation
2024-05-04 17:23:33,626:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:36,607:INFO:Calculating mean and std
2024-05-04 17:23:36,609:INFO:Creating metrics dataframe
2024-05-04 17:23:36,612:INFO:Uploading results into container
2024-05-04 17:23:36,612:INFO:Uploading model into container now
2024-05-04 17:23:36,613:INFO:_master_model_container: 1
2024-05-04 17:23:36,613:INFO:_display_container: 2
2024-05-04 17:23:36,613:INFO:LinearRegression(n_jobs=-1)
2024-05-04 17:23:36,613:INFO:create_model() successfully completed......................................
2024-05-04 17:23:36,918:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:36,918:INFO:Creating metrics dataframe
2024-05-04 17:23:36,921:INFO:Initializing Lasso Regression
2024-05-04 17:23:36,921:INFO:Total runtime is 0.05554911692937215 minutes
2024-05-04 17:23:36,922:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:36,923:INFO:Initializing create_model()
2024-05-04 17:23:36,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:36,923:INFO:Checking exceptions
2024-05-04 17:23:36,923:INFO:Importing libraries
2024-05-04 17:23:36,923:INFO:Copying training dataset
2024-05-04 17:23:36,944:INFO:Defining folds
2024-05-04 17:23:36,944:INFO:Declaring metric variables
2024-05-04 17:23:36,945:INFO:Importing untrained model
2024-05-04 17:23:36,947:INFO:Lasso Regression Imported successfully
2024-05-04 17:23:36,950:INFO:Starting cross validation
2024-05-04 17:23:36,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:37,080:INFO:Calculating mean and std
2024-05-04 17:23:37,081:INFO:Creating metrics dataframe
2024-05-04 17:23:37,082:INFO:Uploading results into container
2024-05-04 17:23:37,082:INFO:Uploading model into container now
2024-05-04 17:23:37,082:INFO:_master_model_container: 2
2024-05-04 17:23:37,082:INFO:_display_container: 2
2024-05-04 17:23:37,083:INFO:Lasso(random_state=123)
2024-05-04 17:23:37,083:INFO:create_model() successfully completed......................................
2024-05-04 17:23:37,200:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:37,200:INFO:Creating metrics dataframe
2024-05-04 17:23:37,203:INFO:Initializing Ridge Regression
2024-05-04 17:23:37,203:INFO:Total runtime is 0.06024073362350464 minutes
2024-05-04 17:23:37,204:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:37,204:INFO:Initializing create_model()
2024-05-04 17:23:37,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:37,204:INFO:Checking exceptions
2024-05-04 17:23:37,204:INFO:Importing libraries
2024-05-04 17:23:37,204:INFO:Copying training dataset
2024-05-04 17:23:37,225:INFO:Defining folds
2024-05-04 17:23:37,225:INFO:Declaring metric variables
2024-05-04 17:23:37,227:INFO:Importing untrained model
2024-05-04 17:23:37,229:INFO:Ridge Regression Imported successfully
2024-05-04 17:23:37,232:INFO:Starting cross validation
2024-05-04 17:23:37,232:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:37,369:INFO:Calculating mean and std
2024-05-04 17:23:37,370:INFO:Creating metrics dataframe
2024-05-04 17:23:37,371:INFO:Uploading results into container
2024-05-04 17:23:37,371:INFO:Uploading model into container now
2024-05-04 17:23:37,371:INFO:_master_model_container: 3
2024-05-04 17:23:37,371:INFO:_display_container: 2
2024-05-04 17:23:37,371:INFO:Ridge(random_state=123)
2024-05-04 17:23:37,371:INFO:create_model() successfully completed......................................
2024-05-04 17:23:37,493:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:37,493:INFO:Creating metrics dataframe
2024-05-04 17:23:37,496:INFO:Initializing Elastic Net
2024-05-04 17:23:37,496:INFO:Total runtime is 0.06512701511383057 minutes
2024-05-04 17:23:37,497:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:37,497:INFO:Initializing create_model()
2024-05-04 17:23:37,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:37,497:INFO:Checking exceptions
2024-05-04 17:23:37,497:INFO:Importing libraries
2024-05-04 17:23:37,497:INFO:Copying training dataset
2024-05-04 17:23:37,518:INFO:Defining folds
2024-05-04 17:23:37,518:INFO:Declaring metric variables
2024-05-04 17:23:37,520:INFO:Importing untrained model
2024-05-04 17:23:37,521:INFO:Elastic Net Imported successfully
2024-05-04 17:23:37,524:INFO:Starting cross validation
2024-05-04 17:23:37,525:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:37,654:INFO:Calculating mean and std
2024-05-04 17:23:37,654:INFO:Creating metrics dataframe
2024-05-04 17:23:37,655:INFO:Uploading results into container
2024-05-04 17:23:37,655:INFO:Uploading model into container now
2024-05-04 17:23:37,656:INFO:_master_model_container: 4
2024-05-04 17:23:37,656:INFO:_display_container: 2
2024-05-04 17:23:37,656:INFO:ElasticNet(random_state=123)
2024-05-04 17:23:37,656:INFO:create_model() successfully completed......................................
2024-05-04 17:23:37,772:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:37,772:INFO:Creating metrics dataframe
2024-05-04 17:23:37,775:INFO:Initializing Least Angle Regression
2024-05-04 17:23:37,775:INFO:Total runtime is 0.06977611780166626 minutes
2024-05-04 17:23:37,776:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:37,776:INFO:Initializing create_model()
2024-05-04 17:23:37,776:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:37,776:INFO:Checking exceptions
2024-05-04 17:23:37,776:INFO:Importing libraries
2024-05-04 17:23:37,777:INFO:Copying training dataset
2024-05-04 17:23:37,796:INFO:Defining folds
2024-05-04 17:23:37,796:INFO:Declaring metric variables
2024-05-04 17:23:37,797:INFO:Importing untrained model
2024-05-04 17:23:37,799:INFO:Least Angle Regression Imported successfully
2024-05-04 17:23:37,801:INFO:Starting cross validation
2024-05-04 17:23:37,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:37,841:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.891e-04, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:23:37,843:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=7.537e-05, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:23:37,843:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=3.965e-05, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:23:37,843:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=3.811e-05, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:23:37,844:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.048e-06, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:23:37,915:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.567e-04, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:23:37,915:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=7.282e-05, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:23:37,916:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=9.612e-05, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:23:37,932:INFO:Calculating mean and std
2024-05-04 17:23:37,933:INFO:Creating metrics dataframe
2024-05-04 17:23:37,933:INFO:Uploading results into container
2024-05-04 17:23:37,934:INFO:Uploading model into container now
2024-05-04 17:23:37,934:INFO:_master_model_container: 5
2024-05-04 17:23:37,934:INFO:_display_container: 2
2024-05-04 17:23:37,934:INFO:Lars(random_state=123)
2024-05-04 17:23:37,934:INFO:create_model() successfully completed......................................
2024-05-04 17:23:38,048:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:38,048:INFO:Creating metrics dataframe
2024-05-04 17:23:38,051:INFO:Initializing Lasso Least Angle Regression
2024-05-04 17:23:38,052:INFO:Total runtime is 0.07438888152440389 minutes
2024-05-04 17:23:38,053:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:38,053:INFO:Initializing create_model()
2024-05-04 17:23:38,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:38,053:INFO:Checking exceptions
2024-05-04 17:23:38,054:INFO:Importing libraries
2024-05-04 17:23:38,054:INFO:Copying training dataset
2024-05-04 17:23:38,073:INFO:Defining folds
2024-05-04 17:23:38,074:INFO:Declaring metric variables
2024-05-04 17:23:38,075:INFO:Importing untrained model
2024-05-04 17:23:38,077:INFO:Lasso Least Angle Regression Imported successfully
2024-05-04 17:23:38,080:INFO:Starting cross validation
2024-05-04 17:23:38,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:38,198:INFO:Calculating mean and std
2024-05-04 17:23:38,198:INFO:Creating metrics dataframe
2024-05-04 17:23:38,199:INFO:Uploading results into container
2024-05-04 17:23:38,199:INFO:Uploading model into container now
2024-05-04 17:23:38,200:INFO:_master_model_container: 6
2024-05-04 17:23:38,200:INFO:_display_container: 2
2024-05-04 17:23:38,200:INFO:LassoLars(random_state=123)
2024-05-04 17:23:38,200:INFO:create_model() successfully completed......................................
2024-05-04 17:23:38,318:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:38,318:INFO:Creating metrics dataframe
2024-05-04 17:23:38,322:INFO:Initializing Orthogonal Matching Pursuit
2024-05-04 17:23:38,322:INFO:Total runtime is 0.07888948520024618 minutes
2024-05-04 17:23:38,323:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:38,323:INFO:Initializing create_model()
2024-05-04 17:23:38,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:38,323:INFO:Checking exceptions
2024-05-04 17:23:38,323:INFO:Importing libraries
2024-05-04 17:23:38,323:INFO:Copying training dataset
2024-05-04 17:23:38,343:INFO:Defining folds
2024-05-04 17:23:38,343:INFO:Declaring metric variables
2024-05-04 17:23:38,345:INFO:Importing untrained model
2024-05-04 17:23:38,346:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-04 17:23:38,348:INFO:Starting cross validation
2024-05-04 17:23:38,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:38,468:INFO:Calculating mean and std
2024-05-04 17:23:38,469:INFO:Creating metrics dataframe
2024-05-04 17:23:38,470:INFO:Uploading results into container
2024-05-04 17:23:38,470:INFO:Uploading model into container now
2024-05-04 17:23:38,470:INFO:_master_model_container: 7
2024-05-04 17:23:38,470:INFO:_display_container: 2
2024-05-04 17:23:38,470:INFO:OrthogonalMatchingPursuit()
2024-05-04 17:23:38,470:INFO:create_model() successfully completed......................................
2024-05-04 17:23:38,586:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:38,586:INFO:Creating metrics dataframe
2024-05-04 17:23:38,589:INFO:Initializing Bayesian Ridge
2024-05-04 17:23:38,589:INFO:Total runtime is 0.0833523154258728 minutes
2024-05-04 17:23:38,591:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:38,591:INFO:Initializing create_model()
2024-05-04 17:23:38,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:38,591:INFO:Checking exceptions
2024-05-04 17:23:38,591:INFO:Importing libraries
2024-05-04 17:23:38,592:INFO:Copying training dataset
2024-05-04 17:23:38,611:INFO:Defining folds
2024-05-04 17:23:38,611:INFO:Declaring metric variables
2024-05-04 17:23:38,612:INFO:Importing untrained model
2024-05-04 17:23:38,614:INFO:Bayesian Ridge Imported successfully
2024-05-04 17:23:38,617:INFO:Starting cross validation
2024-05-04 17:23:38,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:38,761:INFO:Calculating mean and std
2024-05-04 17:23:38,762:INFO:Creating metrics dataframe
2024-05-04 17:23:38,763:INFO:Uploading results into container
2024-05-04 17:23:38,763:INFO:Uploading model into container now
2024-05-04 17:23:38,763:INFO:_master_model_container: 8
2024-05-04 17:23:38,763:INFO:_display_container: 2
2024-05-04 17:23:38,763:INFO:BayesianRidge()
2024-05-04 17:23:38,763:INFO:create_model() successfully completed......................................
2024-05-04 17:23:38,880:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:38,880:INFO:Creating metrics dataframe
2024-05-04 17:23:38,883:INFO:Initializing Passive Aggressive Regressor
2024-05-04 17:23:38,883:INFO:Total runtime is 0.08824703296025595 minutes
2024-05-04 17:23:38,884:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:38,885:INFO:Initializing create_model()
2024-05-04 17:23:38,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:38,885:INFO:Checking exceptions
2024-05-04 17:23:38,885:INFO:Importing libraries
2024-05-04 17:23:38,885:INFO:Copying training dataset
2024-05-04 17:23:38,905:INFO:Defining folds
2024-05-04 17:23:38,905:INFO:Declaring metric variables
2024-05-04 17:23:38,907:INFO:Importing untrained model
2024-05-04 17:23:38,909:INFO:Passive Aggressive Regressor Imported successfully
2024-05-04 17:23:38,912:INFO:Starting cross validation
2024-05-04 17:23:38,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:39,034:INFO:Calculating mean and std
2024-05-04 17:23:39,034:INFO:Creating metrics dataframe
2024-05-04 17:23:39,035:INFO:Uploading results into container
2024-05-04 17:23:39,035:INFO:Uploading model into container now
2024-05-04 17:23:39,035:INFO:_master_model_container: 9
2024-05-04 17:23:39,036:INFO:_display_container: 2
2024-05-04 17:23:39,036:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-04 17:23:39,036:INFO:create_model() successfully completed......................................
2024-05-04 17:23:39,153:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:39,153:INFO:Creating metrics dataframe
2024-05-04 17:23:39,156:INFO:Initializing Huber Regressor
2024-05-04 17:23:39,156:INFO:Total runtime is 0.092801566918691 minutes
2024-05-04 17:23:39,158:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:39,158:INFO:Initializing create_model()
2024-05-04 17:23:39,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:39,158:INFO:Checking exceptions
2024-05-04 17:23:39,158:INFO:Importing libraries
2024-05-04 17:23:39,158:INFO:Copying training dataset
2024-05-04 17:23:39,178:INFO:Defining folds
2024-05-04 17:23:39,178:INFO:Declaring metric variables
2024-05-04 17:23:39,180:INFO:Importing untrained model
2024-05-04 17:23:39,181:INFO:Huber Regressor Imported successfully
2024-05-04 17:23:39,183:INFO:Starting cross validation
2024-05-04 17:23:39,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:39,673:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:39,682:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:39,689:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:39,721:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:39,722:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:39,760:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:39,761:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:39,778:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:39,981:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:39,989:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:23:40,003:INFO:Calculating mean and std
2024-05-04 17:23:40,003:INFO:Creating metrics dataframe
2024-05-04 17:23:40,004:INFO:Uploading results into container
2024-05-04 17:23:40,004:INFO:Uploading model into container now
2024-05-04 17:23:40,004:INFO:_master_model_container: 10
2024-05-04 17:23:40,005:INFO:_display_container: 2
2024-05-04 17:23:40,005:INFO:HuberRegressor()
2024-05-04 17:23:40,005:INFO:create_model() successfully completed......................................
2024-05-04 17:23:40,127:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:40,127:INFO:Creating metrics dataframe
2024-05-04 17:23:40,130:INFO:Initializing K Neighbors Regressor
2024-05-04 17:23:40,130:INFO:Total runtime is 0.10903326670328777 minutes
2024-05-04 17:23:40,131:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:40,132:INFO:Initializing create_model()
2024-05-04 17:23:40,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:40,132:INFO:Checking exceptions
2024-05-04 17:23:40,132:INFO:Importing libraries
2024-05-04 17:23:40,132:INFO:Copying training dataset
2024-05-04 17:23:40,151:INFO:Defining folds
2024-05-04 17:23:40,151:INFO:Declaring metric variables
2024-05-04 17:23:40,153:INFO:Importing untrained model
2024-05-04 17:23:40,154:INFO:K Neighbors Regressor Imported successfully
2024-05-04 17:23:40,157:INFO:Starting cross validation
2024-05-04 17:23:40,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:40,325:INFO:Calculating mean and std
2024-05-04 17:23:40,326:INFO:Creating metrics dataframe
2024-05-04 17:23:40,327:INFO:Uploading results into container
2024-05-04 17:23:40,327:INFO:Uploading model into container now
2024-05-04 17:23:40,327:INFO:_master_model_container: 11
2024-05-04 17:23:40,327:INFO:_display_container: 2
2024-05-04 17:23:40,327:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-04 17:23:40,327:INFO:create_model() successfully completed......................................
2024-05-04 17:23:40,444:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:40,444:INFO:Creating metrics dataframe
2024-05-04 17:23:40,448:INFO:Initializing Decision Tree Regressor
2024-05-04 17:23:40,448:INFO:Total runtime is 0.11432848374048869 minutes
2024-05-04 17:23:40,449:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:40,449:INFO:Initializing create_model()
2024-05-04 17:23:40,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:40,450:INFO:Checking exceptions
2024-05-04 17:23:40,450:INFO:Importing libraries
2024-05-04 17:23:40,450:INFO:Copying training dataset
2024-05-04 17:23:40,494:INFO:Defining folds
2024-05-04 17:23:40,494:INFO:Declaring metric variables
2024-05-04 17:23:40,505:INFO:Importing untrained model
2024-05-04 17:23:40,530:INFO:Decision Tree Regressor Imported successfully
2024-05-04 17:23:40,555:INFO:Starting cross validation
2024-05-04 17:23:40,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:23:42,494:INFO:Calculating mean and std
2024-05-04 17:23:42,495:INFO:Creating metrics dataframe
2024-05-04 17:23:42,496:INFO:Uploading results into container
2024-05-04 17:23:42,496:INFO:Uploading model into container now
2024-05-04 17:23:42,497:INFO:_master_model_container: 12
2024-05-04 17:23:42,497:INFO:_display_container: 2
2024-05-04 17:23:42,497:INFO:DecisionTreeRegressor(random_state=123)
2024-05-04 17:23:42,497:INFO:create_model() successfully completed......................................
2024-05-04 17:23:42,616:INFO:SubProcess create_model() end ==================================
2024-05-04 17:23:42,616:INFO:Creating metrics dataframe
2024-05-04 17:23:42,620:INFO:Initializing Random Forest Regressor
2024-05-04 17:23:42,620:INFO:Total runtime is 0.1505336324373881 minutes
2024-05-04 17:23:42,622:INFO:SubProcess create_model() called ==================================
2024-05-04 17:23:42,622:INFO:Initializing create_model()
2024-05-04 17:23:42,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:23:42,622:INFO:Checking exceptions
2024-05-04 17:23:42,622:INFO:Importing libraries
2024-05-04 17:23:42,622:INFO:Copying training dataset
2024-05-04 17:23:42,642:INFO:Defining folds
2024-05-04 17:23:42,642:INFO:Declaring metric variables
2024-05-04 17:23:42,643:INFO:Importing untrained model
2024-05-04 17:23:42,645:INFO:Random Forest Regressor Imported successfully
2024-05-04 17:23:42,647:INFO:Starting cross validation
2024-05-04 17:23:42,648:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:24:49,707:INFO:Calculating mean and std
2024-05-04 17:24:49,709:INFO:Creating metrics dataframe
2024-05-04 17:24:49,712:INFO:Uploading results into container
2024-05-04 17:24:49,712:INFO:Uploading model into container now
2024-05-04 17:24:49,713:INFO:_master_model_container: 13
2024-05-04 17:24:49,713:INFO:_display_container: 2
2024-05-04 17:24:49,713:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-04 17:24:49,713:INFO:create_model() successfully completed......................................
2024-05-04 17:24:49,955:INFO:SubProcess create_model() end ==================================
2024-05-04 17:24:49,955:INFO:Creating metrics dataframe
2024-05-04 17:24:49,959:INFO:Initializing Extra Trees Regressor
2024-05-04 17:24:49,959:INFO:Total runtime is 1.2728487173716228 minutes
2024-05-04 17:24:49,961:INFO:SubProcess create_model() called ==================================
2024-05-04 17:24:49,961:INFO:Initializing create_model()
2024-05-04 17:24:49,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:24:49,961:INFO:Checking exceptions
2024-05-04 17:24:49,961:INFO:Importing libraries
2024-05-04 17:24:49,961:INFO:Copying training dataset
2024-05-04 17:24:49,993:INFO:Defining folds
2024-05-04 17:24:49,993:INFO:Declaring metric variables
2024-05-04 17:24:49,995:INFO:Importing untrained model
2024-05-04 17:24:49,996:INFO:Extra Trees Regressor Imported successfully
2024-05-04 17:24:50,000:INFO:Starting cross validation
2024-05-04 17:24:50,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:25:05,171:INFO:Calculating mean and std
2024-05-04 17:25:05,173:INFO:Creating metrics dataframe
2024-05-04 17:25:05,176:INFO:Uploading results into container
2024-05-04 17:25:05,177:INFO:Uploading model into container now
2024-05-04 17:25:05,178:INFO:_master_model_container: 14
2024-05-04 17:25:05,178:INFO:_display_container: 2
2024-05-04 17:25:05,178:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-04 17:25:05,178:INFO:create_model() successfully completed......................................
2024-05-04 17:25:05,443:INFO:SubProcess create_model() end ==================================
2024-05-04 17:25:05,443:INFO:Creating metrics dataframe
2024-05-04 17:25:05,447:INFO:Initializing AdaBoost Regressor
2024-05-04 17:25:05,447:INFO:Total runtime is 1.5309844652811686 minutes
2024-05-04 17:25:05,449:INFO:SubProcess create_model() called ==================================
2024-05-04 17:25:05,449:INFO:Initializing create_model()
2024-05-04 17:25:05,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:25:05,449:INFO:Checking exceptions
2024-05-04 17:25:05,449:INFO:Importing libraries
2024-05-04 17:25:05,449:INFO:Copying training dataset
2024-05-04 17:25:05,482:INFO:Defining folds
2024-05-04 17:25:05,482:INFO:Declaring metric variables
2024-05-04 17:25:05,484:INFO:Importing untrained model
2024-05-04 17:25:05,485:INFO:AdaBoost Regressor Imported successfully
2024-05-04 17:25:05,488:INFO:Starting cross validation
2024-05-04 17:25:05,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:25:14,311:INFO:Calculating mean and std
2024-05-04 17:25:14,312:INFO:Creating metrics dataframe
2024-05-04 17:25:14,312:INFO:Uploading results into container
2024-05-04 17:25:14,313:INFO:Uploading model into container now
2024-05-04 17:25:14,313:INFO:_master_model_container: 15
2024-05-04 17:25:14,313:INFO:_display_container: 2
2024-05-04 17:25:14,313:INFO:AdaBoostRegressor(random_state=123)
2024-05-04 17:25:14,313:INFO:create_model() successfully completed......................................
2024-05-04 17:25:14,436:INFO:SubProcess create_model() end ==================================
2024-05-04 17:25:14,436:INFO:Creating metrics dataframe
2024-05-04 17:25:14,440:INFO:Initializing Gradient Boosting Regressor
2024-05-04 17:25:14,440:INFO:Total runtime is 1.6808679858843485 minutes
2024-05-04 17:25:14,441:INFO:SubProcess create_model() called ==================================
2024-05-04 17:25:14,442:INFO:Initializing create_model()
2024-05-04 17:25:14,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:25:14,442:INFO:Checking exceptions
2024-05-04 17:25:14,442:INFO:Importing libraries
2024-05-04 17:25:14,442:INFO:Copying training dataset
2024-05-04 17:25:14,462:INFO:Defining folds
2024-05-04 17:25:14,462:INFO:Declaring metric variables
2024-05-04 17:25:14,464:INFO:Importing untrained model
2024-05-04 17:25:14,465:INFO:Gradient Boosting Regressor Imported successfully
2024-05-04 17:25:14,468:INFO:Starting cross validation
2024-05-04 17:25:14,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:25:49,250:INFO:Calculating mean and std
2024-05-04 17:25:49,252:INFO:Creating metrics dataframe
2024-05-04 17:25:49,254:INFO:Uploading results into container
2024-05-04 17:25:49,254:INFO:Uploading model into container now
2024-05-04 17:25:49,255:INFO:_master_model_container: 16
2024-05-04 17:25:49,255:INFO:_display_container: 2
2024-05-04 17:25:49,255:INFO:GradientBoostingRegressor(random_state=123)
2024-05-04 17:25:49,255:INFO:create_model() successfully completed......................................
2024-05-04 17:25:49,453:INFO:SubProcess create_model() end ==================================
2024-05-04 17:25:49,454:INFO:Creating metrics dataframe
2024-05-04 17:25:49,458:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 17:25:49,458:INFO:Total runtime is 2.26450221935908 minutes
2024-05-04 17:25:49,460:INFO:SubProcess create_model() called ==================================
2024-05-04 17:25:49,460:INFO:Initializing create_model()
2024-05-04 17:25:49,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:25:49,460:INFO:Checking exceptions
2024-05-04 17:25:49,460:INFO:Importing libraries
2024-05-04 17:25:49,460:INFO:Copying training dataset
2024-05-04 17:25:49,483:INFO:Defining folds
2024-05-04 17:25:49,483:INFO:Declaring metric variables
2024-05-04 17:25:49,485:INFO:Importing untrained model
2024-05-04 17:25:49,486:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 17:25:49,489:INFO:Starting cross validation
2024-05-04 17:25:49,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:25:50,437:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 17:25:50,443:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 17:25:50,443:INFO:Initializing create_model()
2024-05-04 17:25:50,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:25:50,443:INFO:Checking exceptions
2024-05-04 17:25:50,443:INFO:Importing libraries
2024-05-04 17:25:50,443:INFO:Copying training dataset
2024-05-04 17:25:50,463:INFO:Defining folds
2024-05-04 17:25:50,463:INFO:Declaring metric variables
2024-05-04 17:25:50,465:INFO:Importing untrained model
2024-05-04 17:25:50,466:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 17:25:50,469:INFO:Starting cross validation
2024-05-04 17:25:50,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:25:54,155:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 17:25:54,157:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 17:25:54,157:INFO:Initializing Dummy Regressor
2024-05-04 17:25:54,157:INFO:Total runtime is 2.342813948790232 minutes
2024-05-04 17:25:54,160:INFO:SubProcess create_model() called ==================================
2024-05-04 17:25:54,160:INFO:Initializing create_model()
2024-05-04 17:25:54,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x31f718710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:25:54,161:INFO:Checking exceptions
2024-05-04 17:25:54,161:INFO:Importing libraries
2024-05-04 17:25:54,161:INFO:Copying training dataset
2024-05-04 17:25:54,182:INFO:Defining folds
2024-05-04 17:25:54,183:INFO:Declaring metric variables
2024-05-04 17:25:54,184:INFO:Importing untrained model
2024-05-04 17:25:54,186:INFO:Dummy Regressor Imported successfully
2024-05-04 17:25:54,189:INFO:Starting cross validation
2024-05-04 17:25:54,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:25:56,413:INFO:Calculating mean and std
2024-05-04 17:25:56,414:INFO:Creating metrics dataframe
2024-05-04 17:25:56,416:INFO:Uploading results into container
2024-05-04 17:25:56,416:INFO:Uploading model into container now
2024-05-04 17:25:56,417:INFO:_master_model_container: 17
2024-05-04 17:25:56,417:INFO:_display_container: 2
2024-05-04 17:25:56,417:INFO:DummyRegressor()
2024-05-04 17:25:56,417:INFO:create_model() successfully completed......................................
2024-05-04 17:25:56,560:INFO:SubProcess create_model() end ==================================
2024-05-04 17:25:56,560:INFO:Creating metrics dataframe
2024-05-04 17:25:56,565:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 17:25:56,569:INFO:Initializing create_model()
2024-05-04 17:25:56,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:25:56,569:INFO:Checking exceptions
2024-05-04 17:25:56,570:INFO:Importing libraries
2024-05-04 17:25:56,570:INFO:Copying training dataset
2024-05-04 17:25:56,591:INFO:Defining folds
2024-05-04 17:25:56,591:INFO:Declaring metric variables
2024-05-04 17:25:56,591:INFO:Importing untrained model
2024-05-04 17:25:56,591:INFO:Declaring custom model
2024-05-04 17:25:56,591:INFO:Bayesian Ridge Imported successfully
2024-05-04 17:25:56,592:INFO:Cross validation set to False
2024-05-04 17:25:56,592:INFO:Fitting Model
2024-05-04 17:25:56,693:INFO:BayesianRidge()
2024-05-04 17:25:56,693:INFO:create_model() successfully completed......................................
2024-05-04 17:25:56,934:INFO:_master_model_container: 17
2024-05-04 17:25:56,935:INFO:_display_container: 2
2024-05-04 17:25:56,935:INFO:BayesianRidge()
2024-05-04 17:25:56,935:INFO:compare_models() successfully completed......................................
2024-05-04 17:26:18,799:INFO:Initializing plot_model()
2024-05-04 17:26:18,800:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 17:26:18,800:INFO:Checking exceptions
2024-05-04 17:26:18,813:INFO:Preloading libraries
2024-05-04 17:26:18,814:INFO:Copying training dataset
2024-05-04 17:26:18,814:INFO:Plot type: residuals
2024-05-04 17:26:19,014:INFO:Fitting Model
2024-05-04 17:26:19,016:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2024-05-04 17:26:19,032:INFO:Scoring test/hold-out set
2024-05-04 17:26:19,253:INFO:Visual Rendered Successfully
2024-05-04 17:26:19,438:INFO:plot_model() successfully completed......................................
2024-05-04 17:26:34,184:INFO:Initializing plot_model()
2024-05-04 17:26:34,185:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 17:26:34,185:INFO:Checking exceptions
2024-05-04 17:26:34,194:INFO:Preloading libraries
2024-05-04 17:26:34,195:INFO:Copying training dataset
2024-05-04 17:26:34,195:INFO:Plot type: error
2024-05-04 17:26:34,355:INFO:Fitting Model
2024-05-04 17:26:34,355:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2024-05-04 17:26:34,355:INFO:Scoring test/hold-out set
2024-05-04 17:26:34,455:INFO:Visual Rendered Successfully
2024-05-04 17:26:34,579:INFO:plot_model() successfully completed......................................
2024-05-04 17:26:44,331:INFO:Initializing plot_model()
2024-05-04 17:26:44,331:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 17:26:44,332:INFO:Checking exceptions
2024-05-04 17:26:44,344:INFO:Preloading libraries
2024-05-04 17:26:44,344:INFO:Copying training dataset
2024-05-04 17:26:44,344:INFO:Plot type: feature
2024-05-04 17:26:44,491:INFO:Visual Rendered Successfully
2024-05-04 17:26:44,615:INFO:plot_model() successfully completed......................................
2024-05-04 17:26:48,471:INFO:Initializing evaluate_model()
2024-05-04 17:26:48,471:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-04 17:26:48,488:INFO:Initializing plot_model()
2024-05-04 17:26:48,488:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 17:26:48,488:INFO:Checking exceptions
2024-05-04 17:26:48,497:INFO:Preloading libraries
2024-05-04 17:26:48,497:INFO:Copying training dataset
2024-05-04 17:26:48,497:INFO:Plot type: pipeline
2024-05-04 17:26:48,544:INFO:Visual Rendered Successfully
2024-05-04 17:26:48,663:INFO:plot_model() successfully completed......................................
2024-05-04 17:26:51,038:INFO:Initializing plot_model()
2024-05-04 17:26:51,038:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 17:26:51,038:INFO:Checking exceptions
2024-05-04 17:26:51,052:INFO:Preloading libraries
2024-05-04 17:26:51,052:INFO:Copying training dataset
2024-05-04 17:26:51,052:INFO:Plot type: parameter
2024-05-04 17:26:51,054:INFO:Visual Rendered Successfully
2024-05-04 17:26:51,198:INFO:plot_model() successfully completed......................................
2024-05-04 17:26:53,085:INFO:Initializing plot_model()
2024-05-04 17:26:53,086:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 17:26:53,086:INFO:Checking exceptions
2024-05-04 17:26:53,101:INFO:Preloading libraries
2024-05-04 17:26:53,101:INFO:Copying training dataset
2024-05-04 17:26:53,101:INFO:Plot type: residuals
2024-05-04 17:26:53,260:INFO:Fitting Model
2024-05-04 17:26:53,261:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2024-05-04 17:26:53,275:INFO:Scoring test/hold-out set
2024-05-04 17:26:53,425:INFO:Visual Rendered Successfully
2024-05-04 17:26:53,552:INFO:plot_model() successfully completed......................................
2024-05-04 17:26:54,696:INFO:Initializing plot_model()
2024-05-04 17:26:54,697:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 17:26:54,697:INFO:Checking exceptions
2024-05-04 17:26:54,712:INFO:Preloading libraries
2024-05-04 17:26:54,712:INFO:Copying training dataset
2024-05-04 17:26:54,712:INFO:Plot type: error
2024-05-04 17:26:54,863:INFO:Fitting Model
2024-05-04 17:26:54,863:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2024-05-04 17:26:54,863:INFO:Scoring test/hold-out set
2024-05-04 17:26:54,950:INFO:Visual Rendered Successfully
2024-05-04 17:26:55,072:INFO:plot_model() successfully completed......................................
2024-05-04 17:26:55,786:INFO:Initializing plot_model()
2024-05-04 17:26:55,787:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=cooks, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 17:26:55,787:INFO:Checking exceptions
2024-05-04 17:26:55,802:INFO:Preloading libraries
2024-05-04 17:26:55,803:INFO:Copying training dataset
2024-05-04 17:26:55,803:INFO:Plot type: cooks
2024-05-04 17:26:55,954:INFO:Fitting Model
2024-05-04 17:26:56,300:INFO:Visual Rendered Successfully
2024-05-04 17:26:56,465:INFO:plot_model() successfully completed......................................
2024-05-04 17:26:56,848:INFO:Initializing plot_model()
2024-05-04 17:26:56,848:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=rfe, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 17:26:56,849:INFO:Checking exceptions
2024-05-04 17:26:56,859:INFO:Preloading libraries
2024-05-04 17:26:56,859:INFO:Copying training dataset
2024-05-04 17:26:56,859:INFO:Plot type: rfe
2024-05-04 17:26:57,006:INFO:Fitting Model
2024-05-04 17:28:42,513:INFO:Initializing predict_model()
2024-05-04 17:28:42,513:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x324e6cae0>)
2024-05-04 17:28:42,513:INFO:Checking exceptions
2024-05-04 17:28:42,513:INFO:Preloading libraries
2024-05-04 17:28:42,620:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-04 17:28:42,835:INFO:Initializing plot_model()
2024-05-04 17:28:42,835:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 17:28:42,836:INFO:Checking exceptions
2024-05-04 17:28:42,845:INFO:Preloading libraries
2024-05-04 17:28:42,845:INFO:Copying training dataset
2024-05-04 17:28:42,845:INFO:Plot type: pipeline
2024-05-04 17:28:42,887:INFO:Visual Rendered Successfully
2024-05-04 17:28:43,086:INFO:plot_model() successfully completed......................................
2024-05-04 17:29:07,968:INFO:Initializing plot_model()
2024-05-04 17:29:07,968:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-05-04 17:29:07,968:INFO:Checking exceptions
2024-05-04 17:29:07,982:INFO:Preloading libraries
2024-05-04 17:29:07,982:INFO:Copying training dataset
2024-05-04 17:29:07,982:INFO:Plot type: residuals
2024-05-04 17:29:08,146:INFO:Fitting Model
2024-05-04 17:29:08,146:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2024-05-04 17:29:08,160:INFO:Scoring test/hold-out set
2024-05-04 17:29:08,318:INFO:Visual Rendered Successfully
2024-05-04 17:29:08,459:INFO:plot_model() successfully completed......................................
2024-05-04 17:29:17,307:INFO:Initializing predict_model()
2024-05-04 17:29:17,307:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x32658e5c0>)
2024-05-04 17:29:17,307:INFO:Checking exceptions
2024-05-04 17:29:17,307:INFO:Preloading libraries
2024-05-04 17:29:17,388:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-04 17:30:16,069:INFO:Initializing compare_models()
2024-05-04 17:30:16,070:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-04 17:30:16,070:INFO:Checking exceptions
2024-05-04 17:30:16,082:INFO:Preparing display monitor
2024-05-04 17:30:16,104:INFO:Initializing Linear Regression
2024-05-04 17:30:16,104:INFO:Total runtime is 2.8491020202636717e-06 minutes
2024-05-04 17:30:16,106:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:16,106:INFO:Initializing create_model()
2024-05-04 17:30:16,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:16,106:INFO:Checking exceptions
2024-05-04 17:30:16,107:INFO:Importing libraries
2024-05-04 17:30:16,107:INFO:Copying training dataset
2024-05-04 17:30:16,130:INFO:Defining folds
2024-05-04 17:30:16,131:INFO:Declaring metric variables
2024-05-04 17:30:16,132:INFO:Importing untrained model
2024-05-04 17:30:16,134:INFO:Linear Regression Imported successfully
2024-05-04 17:30:16,136:INFO:Starting cross validation
2024-05-04 17:30:16,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:16,476:INFO:Calculating mean and std
2024-05-04 17:30:16,477:INFO:Creating metrics dataframe
2024-05-04 17:30:16,478:INFO:Uploading results into container
2024-05-04 17:30:16,478:INFO:Uploading model into container now
2024-05-04 17:30:16,478:INFO:_master_model_container: 18
2024-05-04 17:30:16,478:INFO:_display_container: 5
2024-05-04 17:30:16,478:INFO:LinearRegression(n_jobs=-1)
2024-05-04 17:30:16,478:INFO:create_model() successfully completed......................................
2024-05-04 17:30:16,684:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:16,684:INFO:Creating metrics dataframe
2024-05-04 17:30:16,687:INFO:Initializing Lasso Regression
2024-05-04 17:30:16,687:INFO:Total runtime is 0.009712052345275878 minutes
2024-05-04 17:30:16,688:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:16,688:INFO:Initializing create_model()
2024-05-04 17:30:16,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:16,689:INFO:Checking exceptions
2024-05-04 17:30:16,689:INFO:Importing libraries
2024-05-04 17:30:16,689:INFO:Copying training dataset
2024-05-04 17:30:16,709:INFO:Defining folds
2024-05-04 17:30:16,709:INFO:Declaring metric variables
2024-05-04 17:30:16,711:INFO:Importing untrained model
2024-05-04 17:30:16,712:INFO:Lasso Regression Imported successfully
2024-05-04 17:30:16,715:INFO:Starting cross validation
2024-05-04 17:30:16,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:16,853:INFO:Calculating mean and std
2024-05-04 17:30:16,853:INFO:Creating metrics dataframe
2024-05-04 17:30:16,853:INFO:Uploading results into container
2024-05-04 17:30:16,854:INFO:Uploading model into container now
2024-05-04 17:30:16,854:INFO:_master_model_container: 19
2024-05-04 17:30:16,854:INFO:_display_container: 5
2024-05-04 17:30:16,854:INFO:Lasso(random_state=123)
2024-05-04 17:30:16,854:INFO:create_model() successfully completed......................................
2024-05-04 17:30:16,986:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:16,986:INFO:Creating metrics dataframe
2024-05-04 17:30:16,989:INFO:Initializing Ridge Regression
2024-05-04 17:30:16,989:INFO:Total runtime is 0.014751501878102619 minutes
2024-05-04 17:30:16,991:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:16,991:INFO:Initializing create_model()
2024-05-04 17:30:16,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:16,991:INFO:Checking exceptions
2024-05-04 17:30:16,991:INFO:Importing libraries
2024-05-04 17:30:16,991:INFO:Copying training dataset
2024-05-04 17:30:17,010:INFO:Defining folds
2024-05-04 17:30:17,010:INFO:Declaring metric variables
2024-05-04 17:30:17,012:INFO:Importing untrained model
2024-05-04 17:30:17,013:INFO:Ridge Regression Imported successfully
2024-05-04 17:30:17,016:INFO:Starting cross validation
2024-05-04 17:30:17,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:17,151:INFO:Calculating mean and std
2024-05-04 17:30:17,151:INFO:Creating metrics dataframe
2024-05-04 17:30:17,152:INFO:Uploading results into container
2024-05-04 17:30:17,152:INFO:Uploading model into container now
2024-05-04 17:30:17,153:INFO:_master_model_container: 20
2024-05-04 17:30:17,153:INFO:_display_container: 5
2024-05-04 17:30:17,153:INFO:Ridge(random_state=123)
2024-05-04 17:30:17,153:INFO:create_model() successfully completed......................................
2024-05-04 17:30:17,287:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:17,287:INFO:Creating metrics dataframe
2024-05-04 17:30:17,290:INFO:Initializing Elastic Net
2024-05-04 17:30:17,290:INFO:Total runtime is 0.019770201047261553 minutes
2024-05-04 17:30:17,292:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:17,292:INFO:Initializing create_model()
2024-05-04 17:30:17,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:17,292:INFO:Checking exceptions
2024-05-04 17:30:17,292:INFO:Importing libraries
2024-05-04 17:30:17,292:INFO:Copying training dataset
2024-05-04 17:30:17,319:INFO:Defining folds
2024-05-04 17:30:17,319:INFO:Declaring metric variables
2024-05-04 17:30:17,322:INFO:Importing untrained model
2024-05-04 17:30:17,325:INFO:Elastic Net Imported successfully
2024-05-04 17:30:17,328:INFO:Starting cross validation
2024-05-04 17:30:17,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:17,508:INFO:Calculating mean and std
2024-05-04 17:30:17,508:INFO:Creating metrics dataframe
2024-05-04 17:30:17,509:INFO:Uploading results into container
2024-05-04 17:30:17,509:INFO:Uploading model into container now
2024-05-04 17:30:17,510:INFO:_master_model_container: 21
2024-05-04 17:30:17,510:INFO:_display_container: 5
2024-05-04 17:30:17,510:INFO:ElasticNet(random_state=123)
2024-05-04 17:30:17,510:INFO:create_model() successfully completed......................................
2024-05-04 17:30:17,646:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:17,646:INFO:Creating metrics dataframe
2024-05-04 17:30:17,649:INFO:Initializing Least Angle Regression
2024-05-04 17:30:17,649:INFO:Total runtime is 0.02575089931488037 minutes
2024-05-04 17:30:17,651:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:17,651:INFO:Initializing create_model()
2024-05-04 17:30:17,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:17,651:INFO:Checking exceptions
2024-05-04 17:30:17,651:INFO:Importing libraries
2024-05-04 17:30:17,651:INFO:Copying training dataset
2024-05-04 17:30:17,672:INFO:Defining folds
2024-05-04 17:30:17,672:INFO:Declaring metric variables
2024-05-04 17:30:17,673:INFO:Importing untrained model
2024-05-04 17:30:17,675:INFO:Least Angle Regression Imported successfully
2024-05-04 17:30:17,678:INFO:Starting cross validation
2024-05-04 17:30:17,678:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:17,722:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.891e-04, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:30:17,726:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=7.537e-05, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:30:17,727:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=3.965e-05, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:30:17,727:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=3.811e-05, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:30:17,727:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.048e-06, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:30:17,797:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.567e-04, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:30:17,798:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=7.282e-05, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:30:17,798:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=9.612e-05, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:30:17,810:INFO:Calculating mean and std
2024-05-04 17:30:17,811:INFO:Creating metrics dataframe
2024-05-04 17:30:17,812:INFO:Uploading results into container
2024-05-04 17:30:17,812:INFO:Uploading model into container now
2024-05-04 17:30:17,813:INFO:_master_model_container: 22
2024-05-04 17:30:17,813:INFO:_display_container: 5
2024-05-04 17:30:17,813:INFO:Lars(random_state=123)
2024-05-04 17:30:17,813:INFO:create_model() successfully completed......................................
2024-05-04 17:30:17,947:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:17,947:INFO:Creating metrics dataframe
2024-05-04 17:30:17,951:INFO:Initializing Lasso Least Angle Regression
2024-05-04 17:30:17,951:INFO:Total runtime is 0.030775467554728188 minutes
2024-05-04 17:30:17,952:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:17,952:INFO:Initializing create_model()
2024-05-04 17:30:17,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:17,952:INFO:Checking exceptions
2024-05-04 17:30:17,952:INFO:Importing libraries
2024-05-04 17:30:17,952:INFO:Copying training dataset
2024-05-04 17:30:17,973:INFO:Defining folds
2024-05-04 17:30:17,973:INFO:Declaring metric variables
2024-05-04 17:30:17,975:INFO:Importing untrained model
2024-05-04 17:30:17,976:INFO:Lasso Least Angle Regression Imported successfully
2024-05-04 17:30:17,979:INFO:Starting cross validation
2024-05-04 17:30:17,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:18,087:INFO:Calculating mean and std
2024-05-04 17:30:18,088:INFO:Creating metrics dataframe
2024-05-04 17:30:18,088:INFO:Uploading results into container
2024-05-04 17:30:18,088:INFO:Uploading model into container now
2024-05-04 17:30:18,089:INFO:_master_model_container: 23
2024-05-04 17:30:18,089:INFO:_display_container: 5
2024-05-04 17:30:18,089:INFO:LassoLars(random_state=123)
2024-05-04 17:30:18,089:INFO:create_model() successfully completed......................................
2024-05-04 17:30:18,221:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:18,221:INFO:Creating metrics dataframe
2024-05-04 17:30:18,225:INFO:Initializing Orthogonal Matching Pursuit
2024-05-04 17:30:18,225:INFO:Total runtime is 0.0353457490603129 minutes
2024-05-04 17:30:18,226:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:18,226:INFO:Initializing create_model()
2024-05-04 17:30:18,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:18,227:INFO:Checking exceptions
2024-05-04 17:30:18,227:INFO:Importing libraries
2024-05-04 17:30:18,227:INFO:Copying training dataset
2024-05-04 17:30:18,247:INFO:Defining folds
2024-05-04 17:30:18,247:INFO:Declaring metric variables
2024-05-04 17:30:18,248:INFO:Importing untrained model
2024-05-04 17:30:18,250:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-04 17:30:18,253:INFO:Starting cross validation
2024-05-04 17:30:18,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:18,373:INFO:Calculating mean and std
2024-05-04 17:30:18,373:INFO:Creating metrics dataframe
2024-05-04 17:30:18,374:INFO:Uploading results into container
2024-05-04 17:30:18,375:INFO:Uploading model into container now
2024-05-04 17:30:18,375:INFO:_master_model_container: 24
2024-05-04 17:30:18,375:INFO:_display_container: 5
2024-05-04 17:30:18,375:INFO:OrthogonalMatchingPursuit()
2024-05-04 17:30:18,375:INFO:create_model() successfully completed......................................
2024-05-04 17:30:18,508:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:18,508:INFO:Creating metrics dataframe
2024-05-04 17:30:18,511:INFO:Initializing Bayesian Ridge
2024-05-04 17:30:18,511:INFO:Total runtime is 0.04011118412017822 minutes
2024-05-04 17:30:18,512:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:18,513:INFO:Initializing create_model()
2024-05-04 17:30:18,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:18,513:INFO:Checking exceptions
2024-05-04 17:30:18,513:INFO:Importing libraries
2024-05-04 17:30:18,513:INFO:Copying training dataset
2024-05-04 17:30:18,534:INFO:Defining folds
2024-05-04 17:30:18,534:INFO:Declaring metric variables
2024-05-04 17:30:18,536:INFO:Importing untrained model
2024-05-04 17:30:18,538:INFO:Bayesian Ridge Imported successfully
2024-05-04 17:30:18,540:INFO:Starting cross validation
2024-05-04 17:30:18,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:18,684:INFO:Calculating mean and std
2024-05-04 17:30:18,684:INFO:Creating metrics dataframe
2024-05-04 17:30:18,685:INFO:Uploading results into container
2024-05-04 17:30:18,685:INFO:Uploading model into container now
2024-05-04 17:30:18,685:INFO:_master_model_container: 25
2024-05-04 17:30:18,686:INFO:_display_container: 5
2024-05-04 17:30:18,686:INFO:BayesianRidge()
2024-05-04 17:30:18,686:INFO:create_model() successfully completed......................................
2024-05-04 17:30:18,818:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:18,818:INFO:Creating metrics dataframe
2024-05-04 17:30:18,822:INFO:Initializing Passive Aggressive Regressor
2024-05-04 17:30:18,822:INFO:Total runtime is 0.04529598156611125 minutes
2024-05-04 17:30:18,824:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:18,824:INFO:Initializing create_model()
2024-05-04 17:30:18,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:18,824:INFO:Checking exceptions
2024-05-04 17:30:18,824:INFO:Importing libraries
2024-05-04 17:30:18,824:INFO:Copying training dataset
2024-05-04 17:30:18,846:INFO:Defining folds
2024-05-04 17:30:18,846:INFO:Declaring metric variables
2024-05-04 17:30:18,848:INFO:Importing untrained model
2024-05-04 17:30:18,850:INFO:Passive Aggressive Regressor Imported successfully
2024-05-04 17:30:18,853:INFO:Starting cross validation
2024-05-04 17:30:18,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:18,972:INFO:Calculating mean and std
2024-05-04 17:30:18,972:INFO:Creating metrics dataframe
2024-05-04 17:30:18,973:INFO:Uploading results into container
2024-05-04 17:30:18,973:INFO:Uploading model into container now
2024-05-04 17:30:18,973:INFO:_master_model_container: 26
2024-05-04 17:30:18,973:INFO:_display_container: 5
2024-05-04 17:30:18,973:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-04 17:30:18,974:INFO:create_model() successfully completed......................................
2024-05-04 17:30:19,108:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:19,108:INFO:Creating metrics dataframe
2024-05-04 17:30:19,112:INFO:Initializing Huber Regressor
2024-05-04 17:30:19,112:INFO:Total runtime is 0.05012601613998413 minutes
2024-05-04 17:30:19,113:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:19,113:INFO:Initializing create_model()
2024-05-04 17:30:19,113:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:19,113:INFO:Checking exceptions
2024-05-04 17:30:19,113:INFO:Importing libraries
2024-05-04 17:30:19,113:INFO:Copying training dataset
2024-05-04 17:30:19,139:INFO:Defining folds
2024-05-04 17:30:19,139:INFO:Declaring metric variables
2024-05-04 17:30:19,146:INFO:Importing untrained model
2024-05-04 17:30:19,150:INFO:Huber Regressor Imported successfully
2024-05-04 17:30:19,157:INFO:Starting cross validation
2024-05-04 17:30:19,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:19,773:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:19,779:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:19,815:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:19,863:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:19,866:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:19,919:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:19,930:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:19,945:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:20,157:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:20,184:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:30:20,192:INFO:Calculating mean and std
2024-05-04 17:30:20,193:INFO:Creating metrics dataframe
2024-05-04 17:30:20,194:INFO:Uploading results into container
2024-05-04 17:30:20,194:INFO:Uploading model into container now
2024-05-04 17:30:20,195:INFO:_master_model_container: 27
2024-05-04 17:30:20,195:INFO:_display_container: 5
2024-05-04 17:30:20,195:INFO:HuberRegressor()
2024-05-04 17:30:20,195:INFO:create_model() successfully completed......................................
2024-05-04 17:30:20,387:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:20,387:INFO:Creating metrics dataframe
2024-05-04 17:30:20,391:INFO:Initializing K Neighbors Regressor
2024-05-04 17:30:20,392:INFO:Total runtime is 0.07145417133967082 minutes
2024-05-04 17:30:20,393:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:20,393:INFO:Initializing create_model()
2024-05-04 17:30:20,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:20,393:INFO:Checking exceptions
2024-05-04 17:30:20,393:INFO:Importing libraries
2024-05-04 17:30:20,394:INFO:Copying training dataset
2024-05-04 17:30:20,414:INFO:Defining folds
2024-05-04 17:30:20,414:INFO:Declaring metric variables
2024-05-04 17:30:20,416:INFO:Importing untrained model
2024-05-04 17:30:20,417:INFO:K Neighbors Regressor Imported successfully
2024-05-04 17:30:20,421:INFO:Starting cross validation
2024-05-04 17:30:20,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:20,618:INFO:Calculating mean and std
2024-05-04 17:30:20,618:INFO:Creating metrics dataframe
2024-05-04 17:30:20,620:INFO:Uploading results into container
2024-05-04 17:30:20,620:INFO:Uploading model into container now
2024-05-04 17:30:20,620:INFO:_master_model_container: 28
2024-05-04 17:30:20,620:INFO:_display_container: 5
2024-05-04 17:30:20,620:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-04 17:30:20,621:INFO:create_model() successfully completed......................................
2024-05-04 17:30:20,754:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:20,754:INFO:Creating metrics dataframe
2024-05-04 17:30:20,758:INFO:Initializing Decision Tree Regressor
2024-05-04 17:30:20,758:INFO:Total runtime is 0.07756043672561645 minutes
2024-05-04 17:30:20,759:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:20,759:INFO:Initializing create_model()
2024-05-04 17:30:20,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:20,760:INFO:Checking exceptions
2024-05-04 17:30:20,760:INFO:Importing libraries
2024-05-04 17:30:20,760:INFO:Copying training dataset
2024-05-04 17:30:20,779:INFO:Defining folds
2024-05-04 17:30:20,779:INFO:Declaring metric variables
2024-05-04 17:30:20,780:INFO:Importing untrained model
2024-05-04 17:30:20,782:INFO:Decision Tree Regressor Imported successfully
2024-05-04 17:30:20,784:INFO:Starting cross validation
2024-05-04 17:30:20,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:30:22,752:INFO:Calculating mean and std
2024-05-04 17:30:22,752:INFO:Creating metrics dataframe
2024-05-04 17:30:22,753:INFO:Uploading results into container
2024-05-04 17:30:22,754:INFO:Uploading model into container now
2024-05-04 17:30:22,754:INFO:_master_model_container: 29
2024-05-04 17:30:22,754:INFO:_display_container: 5
2024-05-04 17:30:22,754:INFO:DecisionTreeRegressor(random_state=123)
2024-05-04 17:30:22,754:INFO:create_model() successfully completed......................................
2024-05-04 17:30:22,888:INFO:SubProcess create_model() end ==================================
2024-05-04 17:30:22,889:INFO:Creating metrics dataframe
2024-05-04 17:30:22,892:INFO:Initializing Random Forest Regressor
2024-05-04 17:30:22,892:INFO:Total runtime is 0.1131369153658549 minutes
2024-05-04 17:30:22,894:INFO:SubProcess create_model() called ==================================
2024-05-04 17:30:22,894:INFO:Initializing create_model()
2024-05-04 17:30:22,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:30:22,894:INFO:Checking exceptions
2024-05-04 17:30:22,894:INFO:Importing libraries
2024-05-04 17:30:22,894:INFO:Copying training dataset
2024-05-04 17:30:22,914:INFO:Defining folds
2024-05-04 17:30:22,914:INFO:Declaring metric variables
2024-05-04 17:30:22,915:INFO:Importing untrained model
2024-05-04 17:30:22,917:INFO:Random Forest Regressor Imported successfully
2024-05-04 17:30:22,920:INFO:Starting cross validation
2024-05-04 17:30:22,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:31:30,699:INFO:Calculating mean and std
2024-05-04 17:31:30,701:INFO:Creating metrics dataframe
2024-05-04 17:31:30,703:INFO:Uploading results into container
2024-05-04 17:31:30,704:INFO:Uploading model into container now
2024-05-04 17:31:30,704:INFO:_master_model_container: 30
2024-05-04 17:31:30,704:INFO:_display_container: 5
2024-05-04 17:31:30,705:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-04 17:31:30,705:INFO:create_model() successfully completed......................................
2024-05-04 17:31:30,946:INFO:SubProcess create_model() end ==================================
2024-05-04 17:31:30,946:INFO:Creating metrics dataframe
2024-05-04 17:31:30,950:INFO:Initializing Extra Trees Regressor
2024-05-04 17:31:30,950:INFO:Total runtime is 1.2474305192629496 minutes
2024-05-04 17:31:30,951:INFO:SubProcess create_model() called ==================================
2024-05-04 17:31:30,951:INFO:Initializing create_model()
2024-05-04 17:31:30,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:31:30,952:INFO:Checking exceptions
2024-05-04 17:31:30,952:INFO:Importing libraries
2024-05-04 17:31:30,952:INFO:Copying training dataset
2024-05-04 17:31:30,978:INFO:Defining folds
2024-05-04 17:31:30,978:INFO:Declaring metric variables
2024-05-04 17:31:30,979:INFO:Importing untrained model
2024-05-04 17:31:30,981:INFO:Extra Trees Regressor Imported successfully
2024-05-04 17:31:30,984:INFO:Starting cross validation
2024-05-04 17:31:30,985:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:31:46,907:INFO:Calculating mean and std
2024-05-04 17:31:46,909:INFO:Creating metrics dataframe
2024-05-04 17:31:46,912:INFO:Uploading results into container
2024-05-04 17:31:46,913:INFO:Uploading model into container now
2024-05-04 17:31:46,914:INFO:_master_model_container: 31
2024-05-04 17:31:46,914:INFO:_display_container: 5
2024-05-04 17:31:46,915:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-04 17:31:46,916:INFO:create_model() successfully completed......................................
2024-05-04 17:31:47,146:INFO:SubProcess create_model() end ==================================
2024-05-04 17:31:47,146:INFO:Creating metrics dataframe
2024-05-04 17:31:47,150:INFO:Initializing AdaBoost Regressor
2024-05-04 17:31:47,150:INFO:Total runtime is 1.5174342354138692 minutes
2024-05-04 17:31:47,152:INFO:SubProcess create_model() called ==================================
2024-05-04 17:31:47,152:INFO:Initializing create_model()
2024-05-04 17:31:47,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:31:47,152:INFO:Checking exceptions
2024-05-04 17:31:47,152:INFO:Importing libraries
2024-05-04 17:31:47,152:INFO:Copying training dataset
2024-05-04 17:31:47,177:INFO:Defining folds
2024-05-04 17:31:47,178:INFO:Declaring metric variables
2024-05-04 17:31:47,179:INFO:Importing untrained model
2024-05-04 17:31:47,181:INFO:AdaBoost Regressor Imported successfully
2024-05-04 17:31:47,183:INFO:Starting cross validation
2024-05-04 17:31:47,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:31:56,275:INFO:Calculating mean and std
2024-05-04 17:31:56,275:INFO:Creating metrics dataframe
2024-05-04 17:31:56,276:INFO:Uploading results into container
2024-05-04 17:31:56,276:INFO:Uploading model into container now
2024-05-04 17:31:56,276:INFO:_master_model_container: 32
2024-05-04 17:31:56,276:INFO:_display_container: 5
2024-05-04 17:31:56,277:INFO:AdaBoostRegressor(random_state=123)
2024-05-04 17:31:56,277:INFO:create_model() successfully completed......................................
2024-05-04 17:31:56,413:INFO:SubProcess create_model() end ==================================
2024-05-04 17:31:56,414:INFO:Creating metrics dataframe
2024-05-04 17:31:56,418:INFO:Initializing Gradient Boosting Regressor
2024-05-04 17:31:56,418:INFO:Total runtime is 1.671898849805196 minutes
2024-05-04 17:31:56,420:INFO:SubProcess create_model() called ==================================
2024-05-04 17:31:56,420:INFO:Initializing create_model()
2024-05-04 17:31:56,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:31:56,420:INFO:Checking exceptions
2024-05-04 17:31:56,420:INFO:Importing libraries
2024-05-04 17:31:56,420:INFO:Copying training dataset
2024-05-04 17:31:56,443:INFO:Defining folds
2024-05-04 17:31:56,443:INFO:Declaring metric variables
2024-05-04 17:31:56,445:INFO:Importing untrained model
2024-05-04 17:31:56,447:INFO:Gradient Boosting Regressor Imported successfully
2024-05-04 17:31:56,449:INFO:Starting cross validation
2024-05-04 17:31:56,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:32:33,479:INFO:Calculating mean and std
2024-05-04 17:32:33,483:INFO:Creating metrics dataframe
2024-05-04 17:32:33,487:INFO:Uploading results into container
2024-05-04 17:32:33,488:INFO:Uploading model into container now
2024-05-04 17:32:33,488:INFO:_master_model_container: 33
2024-05-04 17:32:33,488:INFO:_display_container: 5
2024-05-04 17:32:33,489:INFO:GradientBoostingRegressor(random_state=123)
2024-05-04 17:32:33,489:INFO:create_model() successfully completed......................................
2024-05-04 17:32:33,771:INFO:SubProcess create_model() end ==================================
2024-05-04 17:32:33,771:INFO:Creating metrics dataframe
2024-05-04 17:32:33,775:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 17:32:33,776:INFO:Total runtime is 2.2945229172706605 minutes
2024-05-04 17:32:33,777:INFO:SubProcess create_model() called ==================================
2024-05-04 17:32:33,778:INFO:Initializing create_model()
2024-05-04 17:32:33,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:32:33,778:INFO:Checking exceptions
2024-05-04 17:32:33,778:INFO:Importing libraries
2024-05-04 17:32:33,778:INFO:Copying training dataset
2024-05-04 17:32:33,805:INFO:Defining folds
2024-05-04 17:32:33,805:INFO:Declaring metric variables
2024-05-04 17:32:33,807:INFO:Importing untrained model
2024-05-04 17:32:33,809:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 17:32:33,813:INFO:Starting cross validation
2024-05-04 17:32:33,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:32:34,865:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 17:32:34,867:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 17:32:34,867:INFO:Initializing create_model()
2024-05-04 17:32:34,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:32:34,868:INFO:Checking exceptions
2024-05-04 17:32:34,868:INFO:Importing libraries
2024-05-04 17:32:34,868:INFO:Copying training dataset
2024-05-04 17:32:34,891:INFO:Defining folds
2024-05-04 17:32:34,891:INFO:Declaring metric variables
2024-05-04 17:32:34,893:INFO:Importing untrained model
2024-05-04 17:32:34,897:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 17:32:34,903:INFO:Starting cross validation
2024-05-04 17:32:34,904:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:32:38,713:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 17:32:38,715:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 17:32:38,715:INFO:Initializing Dummy Regressor
2024-05-04 17:32:38,715:INFO:Total runtime is 2.3768436511357627 minutes
2024-05-04 17:32:38,717:INFO:SubProcess create_model() called ==================================
2024-05-04 17:32:38,718:INFO:Initializing create_model()
2024-05-04 17:32:38,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3264b8710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:32:38,718:INFO:Checking exceptions
2024-05-04 17:32:38,718:INFO:Importing libraries
2024-05-04 17:32:38,718:INFO:Copying training dataset
2024-05-04 17:32:38,739:INFO:Defining folds
2024-05-04 17:32:38,739:INFO:Declaring metric variables
2024-05-04 17:32:38,741:INFO:Importing untrained model
2024-05-04 17:32:38,742:INFO:Dummy Regressor Imported successfully
2024-05-04 17:32:38,744:INFO:Starting cross validation
2024-05-04 17:32:38,745:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:32:41,145:INFO:Calculating mean and std
2024-05-04 17:32:41,147:INFO:Creating metrics dataframe
2024-05-04 17:32:41,150:INFO:Uploading results into container
2024-05-04 17:32:41,150:INFO:Uploading model into container now
2024-05-04 17:32:41,150:INFO:_master_model_container: 34
2024-05-04 17:32:41,150:INFO:_display_container: 5
2024-05-04 17:32:41,151:INFO:DummyRegressor()
2024-05-04 17:32:41,151:INFO:create_model() successfully completed......................................
2024-05-04 17:32:41,361:INFO:SubProcess create_model() end ==================================
2024-05-04 17:32:41,362:INFO:Creating metrics dataframe
2024-05-04 17:32:41,369:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 17:32:41,399:INFO:Initializing create_model()
2024-05-04 17:32:41,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x31a424690>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:32:41,399:INFO:Checking exceptions
2024-05-04 17:32:41,400:INFO:Importing libraries
2024-05-04 17:32:41,400:INFO:Copying training dataset
2024-05-04 17:32:41,435:INFO:Defining folds
2024-05-04 17:32:41,435:INFO:Declaring metric variables
2024-05-04 17:32:41,435:INFO:Importing untrained model
2024-05-04 17:32:41,435:INFO:Declaring custom model
2024-05-04 17:32:41,436:INFO:Bayesian Ridge Imported successfully
2024-05-04 17:32:41,440:INFO:Cross validation set to False
2024-05-04 17:32:41,440:INFO:Fitting Model
2024-05-04 17:32:42,477:INFO:BayesianRidge()
2024-05-04 17:32:42,477:INFO:create_model() successfully completed......................................
2024-05-04 17:32:42,727:INFO:_master_model_container: 34
2024-05-04 17:32:42,728:INFO:_display_container: 5
2024-05-04 17:32:42,728:INFO:BayesianRidge()
2024-05-04 17:32:42,728:INFO:compare_models() successfully completed......................................
2024-05-04 17:33:03,465:INFO:PyCaret RegressionExperiment
2024-05-04 17:33:03,465:INFO:Logging name: reg-default-name
2024-05-04 17:33:03,465:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 17:33:03,465:INFO:version 3.3.2
2024-05-04 17:33:03,465:INFO:Initializing setup()
2024-05-04 17:33:03,465:INFO:self.USI: 95bd
2024-05-04 17:33:03,465:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 17:33:03,465:INFO:Checking environment
2024-05-04 17:33:03,465:INFO:python_version: 3.11.8
2024-05-04 17:33:03,465:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 17:33:03,465:INFO:machine: arm64
2024-05-04 17:33:03,465:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:33:03,465:INFO:Memory: svmem(total=17179869184, available=3905273856, percent=77.3, used=5803786240, free=109887488, active=3811164160, inactive=3792617472, wired=1992622080)
2024-05-04 17:33:03,466:INFO:Physical Core: 8
2024-05-04 17:33:03,466:INFO:Logical Core: 8
2024-05-04 17:33:03,466:INFO:Checking libraries
2024-05-04 17:33:03,466:INFO:System:
2024-05-04 17:33:03,466:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 17:33:03,466:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 17:33:03,466:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:33:03,466:INFO:PyCaret required dependencies:
2024-05-04 17:33:03,466:INFO:                 pip: 24.0
2024-05-04 17:33:03,466:INFO:          setuptools: 69.2.0
2024-05-04 17:33:03,466:INFO:             pycaret: 3.3.2
2024-05-04 17:33:03,466:INFO:             IPython: 8.22.2
2024-05-04 17:33:03,466:INFO:          ipywidgets: 8.1.2
2024-05-04 17:33:03,466:INFO:                tqdm: 4.66.2
2024-05-04 17:33:03,466:INFO:               numpy: 1.26.4
2024-05-04 17:33:03,466:INFO:              pandas: 2.1.4
2024-05-04 17:33:03,466:INFO:              jinja2: 3.1.3
2024-05-04 17:33:03,466:INFO:               scipy: 1.11.4
2024-05-04 17:33:03,466:INFO:              joblib: 1.3.2
2024-05-04 17:33:03,466:INFO:             sklearn: 1.4.1.post1
2024-05-04 17:33:03,466:INFO:                pyod: 1.1.3
2024-05-04 17:33:03,466:INFO:            imblearn: 0.12.2
2024-05-04 17:33:03,466:INFO:   category_encoders: 2.6.3
2024-05-04 17:33:03,466:INFO:            lightgbm: 4.3.0
2024-05-04 17:33:03,466:INFO:               numba: 0.59.1
2024-05-04 17:33:03,466:INFO:            requests: 2.31.0
2024-05-04 17:33:03,466:INFO:          matplotlib: 3.7.5
2024-05-04 17:33:03,466:INFO:          scikitplot: 0.3.7
2024-05-04 17:33:03,466:INFO:         yellowbrick: 1.5
2024-05-04 17:33:03,466:INFO:              plotly: 5.19.0
2024-05-04 17:33:03,466:INFO:    plotly-resampler: Not installed
2024-05-04 17:33:03,466:INFO:             kaleido: 0.2.1
2024-05-04 17:33:03,466:INFO:           schemdraw: 0.15
2024-05-04 17:33:03,466:INFO:         statsmodels: 0.14.1
2024-05-04 17:33:03,466:INFO:              sktime: 0.26.0
2024-05-04 17:33:03,466:INFO:               tbats: 1.1.3
2024-05-04 17:33:03,466:INFO:            pmdarima: 2.0.4
2024-05-04 17:33:03,466:INFO:              psutil: 5.9.8
2024-05-04 17:33:03,466:INFO:          markupsafe: 2.1.5
2024-05-04 17:33:03,466:INFO:             pickle5: Not installed
2024-05-04 17:33:03,466:INFO:         cloudpickle: 3.0.0
2024-05-04 17:33:03,466:INFO:         deprecation: 2.1.0
2024-05-04 17:33:03,466:INFO:              xxhash: 3.4.1
2024-05-04 17:33:03,466:INFO:           wurlitzer: 3.0.3
2024-05-04 17:33:03,466:INFO:PyCaret optional dependencies:
2024-05-04 17:33:03,466:INFO:                shap: 0.44.1
2024-05-04 17:33:03,466:INFO:           interpret: 0.6.1
2024-05-04 17:33:03,466:INFO:                umap: 0.5.6
2024-05-04 17:33:03,466:INFO:     ydata_profiling: 4.7.0
2024-05-04 17:33:03,466:INFO:  explainerdashboard: 0.4.7
2024-05-04 17:33:03,466:INFO:             autoviz: Not installed
2024-05-04 17:33:03,466:INFO:           fairlearn: 0.7.0
2024-05-04 17:33:03,466:INFO:          deepchecks: Not installed
2024-05-04 17:33:03,466:INFO:             xgboost: Not installed
2024-05-04 17:33:03,466:INFO:            catboost: Not installed
2024-05-04 17:33:03,466:INFO:              kmodes: Not installed
2024-05-04 17:33:03,466:INFO:             mlxtend: 0.23.1
2024-05-04 17:33:03,466:INFO:       statsforecast: Not installed
2024-05-04 17:33:03,466:INFO:        tune_sklearn: Not installed
2024-05-04 17:33:03,466:INFO:                 ray: Not installed
2024-05-04 17:33:03,467:INFO:            hyperopt: 0.2.7
2024-05-04 17:33:03,467:INFO:              optuna: 3.6.1
2024-05-04 17:33:03,467:INFO:               skopt: 0.10.1
2024-05-04 17:33:03,467:INFO:              mlflow: 2.12.1
2024-05-04 17:33:03,467:INFO:              gradio: 4.29.0
2024-05-04 17:33:03,467:INFO:             fastapi: 0.111.0
2024-05-04 17:33:03,467:INFO:             uvicorn: 0.29.0
2024-05-04 17:33:03,467:INFO:              m2cgen: 0.10.0
2024-05-04 17:33:03,467:INFO:           evidently: 0.4.20
2024-05-04 17:33:03,467:INFO:               fugue: 0.8.7
2024-05-04 17:33:03,467:INFO:           streamlit: 1.33.0
2024-05-04 17:33:03,467:INFO:             prophet: Not installed
2024-05-04 17:33:03,467:INFO:None
2024-05-04 17:33:03,467:INFO:Set up data.
2024-05-04 17:33:03,477:INFO:Set up folding strategy.
2024-05-04 17:33:03,477:INFO:Set up train/test split.
2024-05-04 17:33:03,486:INFO:Set up index.
2024-05-04 17:33:03,486:INFO:Assigning column types.
2024-05-04 17:33:03,497:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 17:33:03,498:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,500:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,502:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,556:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,556:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,558:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,560:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,611:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 17:33:03,613:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,615:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,647:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,669:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,671:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,723:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,724:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 17:33:03,728:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,760:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,779:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,784:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,816:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,835:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,836:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 17:33:03,872:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,892:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,928:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:03,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:03,948:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 17:33:03,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:04,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,040:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:04,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,060:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 17:33:04,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,174:INFO:Preparing preprocessing pipeline...
2024-05-04 17:33:04,174:INFO:Set up simple imputation.
2024-05-04 17:33:04,202:INFO:Finished creating preprocessing pipeline.
2024-05-04 17:33:04,203:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group', 'I1', 'I2', 'I3', 'I5',
                                             'I6', 'I7', 'I8', 'I9', 'I10',
                                             'I11', 'I19', 'I20', 'I25', 'I29',
                                             'I30', 'I31', 'I33', 'I34', 'I35',
                                             'I36', 'I37', 'I38', 'I39', 'I40',
                                             'I41', 'I42', 'I43', 'I47', 'I53', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-05-04 17:33:04,203:INFO:Creating final display dataframe.
2024-05-04 17:33:04,286:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Perform
2                   Target type        Regression
3           Original data shape        (8000, 61)
4        Transformed data shape        (8000, 61)
5   Transformed train set shape        (5600, 61)
6    Transformed test set shape        (2400, 61)
7              Numeric features                60
8      Rows with missing values              1.2%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator             KFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  reg-default-name
19                          USI              95bd
2024-05-04 17:33:04,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:04,403:INFO:setup() successfully completed in 0.94s...............
2024-05-04 17:33:12,399:INFO:PyCaret RegressionExperiment
2024-05-04 17:33:12,399:INFO:Logging name: reg-default-name
2024-05-04 17:33:12,399:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 17:33:12,399:INFO:version 3.3.2
2024-05-04 17:33:12,399:INFO:Initializing setup()
2024-05-04 17:33:12,399:INFO:self.USI: 93fd
2024-05-04 17:33:12,399:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 17:33:12,399:INFO:Checking environment
2024-05-04 17:33:12,399:INFO:python_version: 3.11.8
2024-05-04 17:33:12,399:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 17:33:12,399:INFO:machine: arm64
2024-05-04 17:33:12,399:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:33:12,399:INFO:Memory: svmem(total=17179869184, available=3884810240, percent=77.4, used=5872648192, free=58753024, active=3836149760, inactive=3819896832, wired=2036498432)
2024-05-04 17:33:12,399:INFO:Physical Core: 8
2024-05-04 17:33:12,399:INFO:Logical Core: 8
2024-05-04 17:33:12,399:INFO:Checking libraries
2024-05-04 17:33:12,399:INFO:System:
2024-05-04 17:33:12,399:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 17:33:12,399:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 17:33:12,399:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 17:33:12,399:INFO:PyCaret required dependencies:
2024-05-04 17:33:12,399:INFO:                 pip: 24.0
2024-05-04 17:33:12,399:INFO:          setuptools: 69.2.0
2024-05-04 17:33:12,399:INFO:             pycaret: 3.3.2
2024-05-04 17:33:12,399:INFO:             IPython: 8.22.2
2024-05-04 17:33:12,399:INFO:          ipywidgets: 8.1.2
2024-05-04 17:33:12,399:INFO:                tqdm: 4.66.2
2024-05-04 17:33:12,399:INFO:               numpy: 1.26.4
2024-05-04 17:33:12,399:INFO:              pandas: 2.1.4
2024-05-04 17:33:12,399:INFO:              jinja2: 3.1.3
2024-05-04 17:33:12,399:INFO:               scipy: 1.11.4
2024-05-04 17:33:12,399:INFO:              joblib: 1.3.2
2024-05-04 17:33:12,399:INFO:             sklearn: 1.4.1.post1
2024-05-04 17:33:12,399:INFO:                pyod: 1.1.3
2024-05-04 17:33:12,399:INFO:            imblearn: 0.12.2
2024-05-04 17:33:12,399:INFO:   category_encoders: 2.6.3
2024-05-04 17:33:12,399:INFO:            lightgbm: 4.3.0
2024-05-04 17:33:12,399:INFO:               numba: 0.59.1
2024-05-04 17:33:12,399:INFO:            requests: 2.31.0
2024-05-04 17:33:12,399:INFO:          matplotlib: 3.7.5
2024-05-04 17:33:12,399:INFO:          scikitplot: 0.3.7
2024-05-04 17:33:12,399:INFO:         yellowbrick: 1.5
2024-05-04 17:33:12,399:INFO:              plotly: 5.19.0
2024-05-04 17:33:12,399:INFO:    plotly-resampler: Not installed
2024-05-04 17:33:12,399:INFO:             kaleido: 0.2.1
2024-05-04 17:33:12,399:INFO:           schemdraw: 0.15
2024-05-04 17:33:12,399:INFO:         statsmodels: 0.14.1
2024-05-04 17:33:12,399:INFO:              sktime: 0.26.0
2024-05-04 17:33:12,399:INFO:               tbats: 1.1.3
2024-05-04 17:33:12,400:INFO:            pmdarima: 2.0.4
2024-05-04 17:33:12,400:INFO:              psutil: 5.9.8
2024-05-04 17:33:12,400:INFO:          markupsafe: 2.1.5
2024-05-04 17:33:12,400:INFO:             pickle5: Not installed
2024-05-04 17:33:12,400:INFO:         cloudpickle: 3.0.0
2024-05-04 17:33:12,400:INFO:         deprecation: 2.1.0
2024-05-04 17:33:12,400:INFO:              xxhash: 3.4.1
2024-05-04 17:33:12,400:INFO:           wurlitzer: 3.0.3
2024-05-04 17:33:12,400:INFO:PyCaret optional dependencies:
2024-05-04 17:33:12,400:INFO:                shap: 0.44.1
2024-05-04 17:33:12,400:INFO:           interpret: 0.6.1
2024-05-04 17:33:12,400:INFO:                umap: 0.5.6
2024-05-04 17:33:12,400:INFO:     ydata_profiling: 4.7.0
2024-05-04 17:33:12,400:INFO:  explainerdashboard: 0.4.7
2024-05-04 17:33:12,400:INFO:             autoviz: Not installed
2024-05-04 17:33:12,400:INFO:           fairlearn: 0.7.0
2024-05-04 17:33:12,400:INFO:          deepchecks: Not installed
2024-05-04 17:33:12,400:INFO:             xgboost: Not installed
2024-05-04 17:33:12,400:INFO:            catboost: Not installed
2024-05-04 17:33:12,400:INFO:              kmodes: Not installed
2024-05-04 17:33:12,400:INFO:             mlxtend: 0.23.1
2024-05-04 17:33:12,400:INFO:       statsforecast: Not installed
2024-05-04 17:33:12,400:INFO:        tune_sklearn: Not installed
2024-05-04 17:33:12,400:INFO:                 ray: Not installed
2024-05-04 17:33:12,400:INFO:            hyperopt: 0.2.7
2024-05-04 17:33:12,400:INFO:              optuna: 3.6.1
2024-05-04 17:33:12,400:INFO:               skopt: 0.10.1
2024-05-04 17:33:12,400:INFO:              mlflow: 2.12.1
2024-05-04 17:33:12,400:INFO:              gradio: 4.29.0
2024-05-04 17:33:12,400:INFO:             fastapi: 0.111.0
2024-05-04 17:33:12,400:INFO:             uvicorn: 0.29.0
2024-05-04 17:33:12,400:INFO:              m2cgen: 0.10.0
2024-05-04 17:33:12,400:INFO:           evidently: 0.4.20
2024-05-04 17:33:12,400:INFO:               fugue: 0.8.7
2024-05-04 17:33:12,400:INFO:           streamlit: 1.33.0
2024-05-04 17:33:12,400:INFO:             prophet: Not installed
2024-05-04 17:33:12,400:INFO:None
2024-05-04 17:33:12,400:INFO:Set up data.
2024-05-04 17:33:12,410:INFO:Set up folding strategy.
2024-05-04 17:33:12,410:INFO:Set up train/test split.
2024-05-04 17:33:12,419:INFO:Set up index.
2024-05-04 17:33:12,420:INFO:Assigning column types.
2024-05-04 17:33:12,428:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 17:33:12,428:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,430:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,432:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,464:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,483:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,483:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,486:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,488:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,520:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,539:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 17:33:12,541:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,544:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,575:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,595:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,597:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,599:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,631:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,651:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 17:33:12,655:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,687:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,711:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,763:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 17:33:12,799:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,874:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,875:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 17:33:12,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 17:33:12,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:12,987:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 17:33:13,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:13,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:13,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:13,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:13,100:INFO:Preparing preprocessing pipeline...
2024-05-04 17:33:13,100:INFO:Set up simple imputation.
2024-05-04 17:33:13,125:INFO:Finished creating preprocessing pipeline.
2024-05-04 17:33:13,127:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group', 'I1', 'I2', 'I3', 'I5',
                                             'I6', 'I7', 'I8', 'I9', 'I10',
                                             'I11', 'I19', 'I20', 'I25', 'I29',
                                             'I30', 'I31', 'I33', 'I34', 'I35',
                                             'I36', 'I37', 'I38', 'I39', 'I40',
                                             'I41', 'I42', 'I43', 'I47', 'I53', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-05-04 17:33:13,127:INFO:Creating final display dataframe.
2024-05-04 17:33:13,207:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Perform
2                   Target type        Regression
3           Original data shape        (8000, 61)
4        Transformed data shape        (8000, 61)
5   Transformed train set shape        (5600, 61)
6    Transformed test set shape        (2400, 61)
7              Numeric features                60
8      Rows with missing values              1.2%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator             KFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  reg-default-name
19                          USI              93fd
2024-05-04 17:33:13,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:13,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:13,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:13,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 17:33:13,326:INFO:setup() successfully completed in 0.93s...............
2024-05-04 17:33:21,851:INFO:Initializing compare_models()
2024-05-04 17:33:21,851:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-04 17:33:21,851:INFO:Checking exceptions
2024-05-04 17:33:21,857:INFO:Preparing display monitor
2024-05-04 17:33:21,866:INFO:Initializing Linear Regression
2024-05-04 17:33:21,867:INFO:Total runtime is 3.6835670471191405e-06 minutes
2024-05-04 17:33:21,869:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:21,869:INFO:Initializing create_model()
2024-05-04 17:33:21,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:21,870:INFO:Checking exceptions
2024-05-04 17:33:21,870:INFO:Importing libraries
2024-05-04 17:33:21,870:INFO:Copying training dataset
2024-05-04 17:33:21,884:INFO:Defining folds
2024-05-04 17:33:21,884:INFO:Declaring metric variables
2024-05-04 17:33:21,885:INFO:Importing untrained model
2024-05-04 17:33:21,887:INFO:Linear Regression Imported successfully
2024-05-04 17:33:21,890:INFO:Starting cross validation
2024-05-04 17:33:21,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:22,071:INFO:Calculating mean and std
2024-05-04 17:33:22,072:INFO:Creating metrics dataframe
2024-05-04 17:33:22,073:INFO:Uploading results into container
2024-05-04 17:33:22,073:INFO:Uploading model into container now
2024-05-04 17:33:22,073:INFO:_master_model_container: 1
2024-05-04 17:33:22,073:INFO:_display_container: 2
2024-05-04 17:33:22,074:INFO:LinearRegression(n_jobs=-1)
2024-05-04 17:33:22,074:INFO:create_model() successfully completed......................................
2024-05-04 17:33:22,234:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:22,234:INFO:Creating metrics dataframe
2024-05-04 17:33:22,237:INFO:Initializing Lasso Regression
2024-05-04 17:33:22,237:INFO:Total runtime is 0.006170046329498291 minutes
2024-05-04 17:33:22,238:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:22,239:INFO:Initializing create_model()
2024-05-04 17:33:22,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:22,239:INFO:Checking exceptions
2024-05-04 17:33:22,239:INFO:Importing libraries
2024-05-04 17:33:22,239:INFO:Copying training dataset
2024-05-04 17:33:22,250:INFO:Defining folds
2024-05-04 17:33:22,250:INFO:Declaring metric variables
2024-05-04 17:33:22,251:INFO:Importing untrained model
2024-05-04 17:33:22,253:INFO:Lasso Regression Imported successfully
2024-05-04 17:33:22,256:INFO:Starting cross validation
2024-05-04 17:33:22,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:22,338:INFO:Calculating mean and std
2024-05-04 17:33:22,338:INFO:Creating metrics dataframe
2024-05-04 17:33:22,339:INFO:Uploading results into container
2024-05-04 17:33:22,339:INFO:Uploading model into container now
2024-05-04 17:33:22,340:INFO:_master_model_container: 2
2024-05-04 17:33:22,340:INFO:_display_container: 2
2024-05-04 17:33:22,340:INFO:Lasso(random_state=123)
2024-05-04 17:33:22,340:INFO:create_model() successfully completed......................................
2024-05-04 17:33:22,490:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:22,490:INFO:Creating metrics dataframe
2024-05-04 17:33:22,493:INFO:Initializing Ridge Regression
2024-05-04 17:33:22,493:INFO:Total runtime is 0.01043610175450643 minutes
2024-05-04 17:33:22,494:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:22,494:INFO:Initializing create_model()
2024-05-04 17:33:22,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:22,494:INFO:Checking exceptions
2024-05-04 17:33:22,494:INFO:Importing libraries
2024-05-04 17:33:22,495:INFO:Copying training dataset
2024-05-04 17:33:22,505:INFO:Defining folds
2024-05-04 17:33:22,505:INFO:Declaring metric variables
2024-05-04 17:33:22,507:INFO:Importing untrained model
2024-05-04 17:33:22,509:INFO:Ridge Regression Imported successfully
2024-05-04 17:33:22,512:INFO:Starting cross validation
2024-05-04 17:33:22,512:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:22,595:INFO:Calculating mean and std
2024-05-04 17:33:22,595:INFO:Creating metrics dataframe
2024-05-04 17:33:22,596:INFO:Uploading results into container
2024-05-04 17:33:22,596:INFO:Uploading model into container now
2024-05-04 17:33:22,596:INFO:_master_model_container: 3
2024-05-04 17:33:22,596:INFO:_display_container: 2
2024-05-04 17:33:22,596:INFO:Ridge(random_state=123)
2024-05-04 17:33:22,596:INFO:create_model() successfully completed......................................
2024-05-04 17:33:22,757:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:22,758:INFO:Creating metrics dataframe
2024-05-04 17:33:22,761:INFO:Initializing Elastic Net
2024-05-04 17:33:22,761:INFO:Total runtime is 0.014915831883748372 minutes
2024-05-04 17:33:22,763:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:22,763:INFO:Initializing create_model()
2024-05-04 17:33:22,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:22,763:INFO:Checking exceptions
2024-05-04 17:33:22,763:INFO:Importing libraries
2024-05-04 17:33:22,763:INFO:Copying training dataset
2024-05-04 17:33:22,775:INFO:Defining folds
2024-05-04 17:33:22,776:INFO:Declaring metric variables
2024-05-04 17:33:22,777:INFO:Importing untrained model
2024-05-04 17:33:22,779:INFO:Elastic Net Imported successfully
2024-05-04 17:33:22,782:INFO:Starting cross validation
2024-05-04 17:33:22,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:22,864:INFO:Calculating mean and std
2024-05-04 17:33:22,865:INFO:Creating metrics dataframe
2024-05-04 17:33:22,866:INFO:Uploading results into container
2024-05-04 17:33:22,866:INFO:Uploading model into container now
2024-05-04 17:33:22,866:INFO:_master_model_container: 4
2024-05-04 17:33:22,866:INFO:_display_container: 2
2024-05-04 17:33:22,866:INFO:ElasticNet(random_state=123)
2024-05-04 17:33:22,866:INFO:create_model() successfully completed......................................
2024-05-04 17:33:23,009:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:23,009:INFO:Creating metrics dataframe
2024-05-04 17:33:23,012:INFO:Initializing Least Angle Regression
2024-05-04 17:33:23,013:INFO:Total runtime is 0.01910159985224406 minutes
2024-05-04 17:33:23,014:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:23,014:INFO:Initializing create_model()
2024-05-04 17:33:23,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:23,014:INFO:Checking exceptions
2024-05-04 17:33:23,014:INFO:Importing libraries
2024-05-04 17:33:23,014:INFO:Copying training dataset
2024-05-04 17:33:23,026:INFO:Defining folds
2024-05-04 17:33:23,026:INFO:Declaring metric variables
2024-05-04 17:33:23,028:INFO:Importing untrained model
2024-05-04 17:33:23,029:INFO:Least Angle Regression Imported successfully
2024-05-04 17:33:23,032:INFO:Starting cross validation
2024-05-04 17:33:23,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:23,061:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.854e-05, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:33:23,061:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.853e-05, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:33:23,061:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.488e-06, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:33:23,078:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.831e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-04 17:33:23,116:INFO:Calculating mean and std
2024-05-04 17:33:23,116:INFO:Creating metrics dataframe
2024-05-04 17:33:23,117:INFO:Uploading results into container
2024-05-04 17:33:23,117:INFO:Uploading model into container now
2024-05-04 17:33:23,117:INFO:_master_model_container: 5
2024-05-04 17:33:23,117:INFO:_display_container: 2
2024-05-04 17:33:23,117:INFO:Lars(random_state=123)
2024-05-04 17:33:23,117:INFO:create_model() successfully completed......................................
2024-05-04 17:33:23,262:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:23,262:INFO:Creating metrics dataframe
2024-05-04 17:33:23,266:INFO:Initializing Lasso Least Angle Regression
2024-05-04 17:33:23,266:INFO:Total runtime is 0.023323829968770346 minutes
2024-05-04 17:33:23,268:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:23,268:INFO:Initializing create_model()
2024-05-04 17:33:23,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:23,268:INFO:Checking exceptions
2024-05-04 17:33:23,268:INFO:Importing libraries
2024-05-04 17:33:23,268:INFO:Copying training dataset
2024-05-04 17:33:23,280:INFO:Defining folds
2024-05-04 17:33:23,280:INFO:Declaring metric variables
2024-05-04 17:33:23,282:INFO:Importing untrained model
2024-05-04 17:33:23,283:INFO:Lasso Least Angle Regression Imported successfully
2024-05-04 17:33:23,286:INFO:Starting cross validation
2024-05-04 17:33:23,287:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:23,368:INFO:Calculating mean and std
2024-05-04 17:33:23,368:INFO:Creating metrics dataframe
2024-05-04 17:33:23,369:INFO:Uploading results into container
2024-05-04 17:33:23,369:INFO:Uploading model into container now
2024-05-04 17:33:23,370:INFO:_master_model_container: 6
2024-05-04 17:33:23,370:INFO:_display_container: 2
2024-05-04 17:33:23,370:INFO:LassoLars(random_state=123)
2024-05-04 17:33:23,370:INFO:create_model() successfully completed......................................
2024-05-04 17:33:23,514:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:23,514:INFO:Creating metrics dataframe
2024-05-04 17:33:23,518:INFO:Initializing Orthogonal Matching Pursuit
2024-05-04 17:33:23,518:INFO:Total runtime is 0.02752965291341146 minutes
2024-05-04 17:33:23,520:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:23,520:INFO:Initializing create_model()
2024-05-04 17:33:23,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:23,521:INFO:Checking exceptions
2024-05-04 17:33:23,521:INFO:Importing libraries
2024-05-04 17:33:23,521:INFO:Copying training dataset
2024-05-04 17:33:23,533:INFO:Defining folds
2024-05-04 17:33:23,533:INFO:Declaring metric variables
2024-05-04 17:33:23,535:INFO:Importing untrained model
2024-05-04 17:33:23,537:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-04 17:33:23,578:INFO:Starting cross validation
2024-05-04 17:33:23,579:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:23,740:INFO:Calculating mean and std
2024-05-04 17:33:23,740:INFO:Creating metrics dataframe
2024-05-04 17:33:23,741:INFO:Uploading results into container
2024-05-04 17:33:23,741:INFO:Uploading model into container now
2024-05-04 17:33:23,742:INFO:_master_model_container: 7
2024-05-04 17:33:23,742:INFO:_display_container: 2
2024-05-04 17:33:23,742:INFO:OrthogonalMatchingPursuit()
2024-05-04 17:33:23,742:INFO:create_model() successfully completed......................................
2024-05-04 17:33:23,885:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:23,885:INFO:Creating metrics dataframe
2024-05-04 17:33:23,889:INFO:Initializing Bayesian Ridge
2024-05-04 17:33:23,889:INFO:Total runtime is 0.03371139764785767 minutes
2024-05-04 17:33:23,891:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:23,891:INFO:Initializing create_model()
2024-05-04 17:33:23,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:23,891:INFO:Checking exceptions
2024-05-04 17:33:23,891:INFO:Importing libraries
2024-05-04 17:33:23,891:INFO:Copying training dataset
2024-05-04 17:33:23,903:INFO:Defining folds
2024-05-04 17:33:23,903:INFO:Declaring metric variables
2024-05-04 17:33:23,905:INFO:Importing untrained model
2024-05-04 17:33:23,907:INFO:Bayesian Ridge Imported successfully
2024-05-04 17:33:23,910:INFO:Starting cross validation
2024-05-04 17:33:23,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:24,012:INFO:Calculating mean and std
2024-05-04 17:33:24,012:INFO:Creating metrics dataframe
2024-05-04 17:33:24,013:INFO:Uploading results into container
2024-05-04 17:33:24,014:INFO:Uploading model into container now
2024-05-04 17:33:24,014:INFO:_master_model_container: 8
2024-05-04 17:33:24,014:INFO:_display_container: 2
2024-05-04 17:33:24,014:INFO:BayesianRidge()
2024-05-04 17:33:24,014:INFO:create_model() successfully completed......................................
2024-05-04 17:33:24,163:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:24,163:INFO:Creating metrics dataframe
2024-05-04 17:33:24,166:INFO:Initializing Passive Aggressive Regressor
2024-05-04 17:33:24,166:INFO:Total runtime is 0.0383309006690979 minutes
2024-05-04 17:33:24,168:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:24,169:INFO:Initializing create_model()
2024-05-04 17:33:24,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:24,169:INFO:Checking exceptions
2024-05-04 17:33:24,169:INFO:Importing libraries
2024-05-04 17:33:24,169:INFO:Copying training dataset
2024-05-04 17:33:24,180:INFO:Defining folds
2024-05-04 17:33:24,181:INFO:Declaring metric variables
2024-05-04 17:33:24,182:INFO:Importing untrained model
2024-05-04 17:33:24,184:INFO:Passive Aggressive Regressor Imported successfully
2024-05-04 17:33:24,188:INFO:Starting cross validation
2024-05-04 17:33:24,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:24,282:INFO:Calculating mean and std
2024-05-04 17:33:24,283:INFO:Creating metrics dataframe
2024-05-04 17:33:24,284:INFO:Uploading results into container
2024-05-04 17:33:24,284:INFO:Uploading model into container now
2024-05-04 17:33:24,284:INFO:_master_model_container: 9
2024-05-04 17:33:24,284:INFO:_display_container: 2
2024-05-04 17:33:24,284:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-04 17:33:24,285:INFO:create_model() successfully completed......................................
2024-05-04 17:33:24,426:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:24,426:INFO:Creating metrics dataframe
2024-05-04 17:33:24,430:INFO:Initializing Huber Regressor
2024-05-04 17:33:24,430:INFO:Total runtime is 0.0427228848139445 minutes
2024-05-04 17:33:24,431:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:24,431:INFO:Initializing create_model()
2024-05-04 17:33:24,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:24,431:INFO:Checking exceptions
2024-05-04 17:33:24,431:INFO:Importing libraries
2024-05-04 17:33:24,432:INFO:Copying training dataset
2024-05-04 17:33:24,443:INFO:Defining folds
2024-05-04 17:33:24,443:INFO:Declaring metric variables
2024-05-04 17:33:24,444:INFO:Importing untrained model
2024-05-04 17:33:24,446:INFO:Huber Regressor Imported successfully
2024-05-04 17:33:24,448:INFO:Starting cross validation
2024-05-04 17:33:24,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:24,716:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,725:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,734:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,737:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,765:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,767:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,777:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,820:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,896:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,897:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 17:33:24,904:INFO:Calculating mean and std
2024-05-04 17:33:24,904:INFO:Creating metrics dataframe
2024-05-04 17:33:24,905:INFO:Uploading results into container
2024-05-04 17:33:24,905:INFO:Uploading model into container now
2024-05-04 17:33:24,906:INFO:_master_model_container: 10
2024-05-04 17:33:24,906:INFO:_display_container: 2
2024-05-04 17:33:24,906:INFO:HuberRegressor()
2024-05-04 17:33:24,906:INFO:create_model() successfully completed......................................
2024-05-04 17:33:25,046:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:25,046:INFO:Creating metrics dataframe
2024-05-04 17:33:25,050:INFO:Initializing K Neighbors Regressor
2024-05-04 17:33:25,050:INFO:Total runtime is 0.05305626392364502 minutes
2024-05-04 17:33:25,052:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:25,052:INFO:Initializing create_model()
2024-05-04 17:33:25,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:25,052:INFO:Checking exceptions
2024-05-04 17:33:25,052:INFO:Importing libraries
2024-05-04 17:33:25,052:INFO:Copying training dataset
2024-05-04 17:33:25,063:INFO:Defining folds
2024-05-04 17:33:25,063:INFO:Declaring metric variables
2024-05-04 17:33:25,065:INFO:Importing untrained model
2024-05-04 17:33:25,066:INFO:K Neighbors Regressor Imported successfully
2024-05-04 17:33:25,069:INFO:Starting cross validation
2024-05-04 17:33:25,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:25,202:INFO:Calculating mean and std
2024-05-04 17:33:25,203:INFO:Creating metrics dataframe
2024-05-04 17:33:25,204:INFO:Uploading results into container
2024-05-04 17:33:25,204:INFO:Uploading model into container now
2024-05-04 17:33:25,204:INFO:_master_model_container: 11
2024-05-04 17:33:25,204:INFO:_display_container: 2
2024-05-04 17:33:25,204:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-04 17:33:25,204:INFO:create_model() successfully completed......................................
2024-05-04 17:33:25,342:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:25,342:INFO:Creating metrics dataframe
2024-05-04 17:33:25,346:INFO:Initializing Decision Tree Regressor
2024-05-04 17:33:25,346:INFO:Total runtime is 0.05799796581268311 minutes
2024-05-04 17:33:25,348:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:25,348:INFO:Initializing create_model()
2024-05-04 17:33:25,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:25,348:INFO:Checking exceptions
2024-05-04 17:33:25,348:INFO:Importing libraries
2024-05-04 17:33:25,348:INFO:Copying training dataset
2024-05-04 17:33:25,359:INFO:Defining folds
2024-05-04 17:33:25,359:INFO:Declaring metric variables
2024-05-04 17:33:25,361:INFO:Importing untrained model
2024-05-04 17:33:25,363:INFO:Decision Tree Regressor Imported successfully
2024-05-04 17:33:25,365:INFO:Starting cross validation
2024-05-04 17:33:25,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:33:26,312:INFO:Calculating mean and std
2024-05-04 17:33:26,312:INFO:Creating metrics dataframe
2024-05-04 17:33:26,313:INFO:Uploading results into container
2024-05-04 17:33:26,314:INFO:Uploading model into container now
2024-05-04 17:33:26,314:INFO:_master_model_container: 12
2024-05-04 17:33:26,314:INFO:_display_container: 2
2024-05-04 17:33:26,314:INFO:DecisionTreeRegressor(random_state=123)
2024-05-04 17:33:26,314:INFO:create_model() successfully completed......................................
2024-05-04 17:33:26,477:INFO:SubProcess create_model() end ==================================
2024-05-04 17:33:26,478:INFO:Creating metrics dataframe
2024-05-04 17:33:26,482:INFO:Initializing Random Forest Regressor
2024-05-04 17:33:26,482:INFO:Total runtime is 0.07692196766535442 minutes
2024-05-04 17:33:26,487:INFO:SubProcess create_model() called ==================================
2024-05-04 17:33:26,487:INFO:Initializing create_model()
2024-05-04 17:33:26,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:33:26,487:INFO:Checking exceptions
2024-05-04 17:33:26,488:INFO:Importing libraries
2024-05-04 17:33:26,488:INFO:Copying training dataset
2024-05-04 17:33:26,499:INFO:Defining folds
2024-05-04 17:33:26,500:INFO:Declaring metric variables
2024-05-04 17:33:26,501:INFO:Importing untrained model
2024-05-04 17:33:26,503:INFO:Random Forest Regressor Imported successfully
2024-05-04 17:33:26,506:INFO:Starting cross validation
2024-05-04 17:33:26,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:34:05,539:INFO:Calculating mean and std
2024-05-04 17:34:05,542:INFO:Creating metrics dataframe
2024-05-04 17:34:05,544:INFO:Uploading results into container
2024-05-04 17:34:05,545:INFO:Uploading model into container now
2024-05-04 17:34:05,546:INFO:_master_model_container: 13
2024-05-04 17:34:05,546:INFO:_display_container: 2
2024-05-04 17:34:05,546:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-04 17:34:05,546:INFO:create_model() successfully completed......................................
2024-05-04 17:34:05,825:INFO:SubProcess create_model() end ==================================
2024-05-04 17:34:05,825:INFO:Creating metrics dataframe
2024-05-04 17:34:05,830:INFO:Initializing Extra Trees Regressor
2024-05-04 17:34:05,830:INFO:Total runtime is 0.7327254017194113 minutes
2024-05-04 17:34:05,831:INFO:SubProcess create_model() called ==================================
2024-05-04 17:34:05,832:INFO:Initializing create_model()
2024-05-04 17:34:05,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:34:05,832:INFO:Checking exceptions
2024-05-04 17:34:05,832:INFO:Importing libraries
2024-05-04 17:34:05,832:INFO:Copying training dataset
2024-05-04 17:34:05,845:INFO:Defining folds
2024-05-04 17:34:05,845:INFO:Declaring metric variables
2024-05-04 17:34:05,846:INFO:Importing untrained model
2024-05-04 17:34:05,848:INFO:Extra Trees Regressor Imported successfully
2024-05-04 17:34:05,850:INFO:Starting cross validation
2024-05-04 17:34:05,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:34:14,343:INFO:Calculating mean and std
2024-05-04 17:34:14,346:INFO:Creating metrics dataframe
2024-05-04 17:34:14,349:INFO:Uploading results into container
2024-05-04 17:34:14,349:INFO:Uploading model into container now
2024-05-04 17:34:14,350:INFO:_master_model_container: 14
2024-05-04 17:34:14,350:INFO:_display_container: 2
2024-05-04 17:34:14,350:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-04 17:34:14,351:INFO:create_model() successfully completed......................................
2024-05-04 17:34:14,593:INFO:SubProcess create_model() end ==================================
2024-05-04 17:34:14,594:INFO:Creating metrics dataframe
2024-05-04 17:34:14,598:INFO:Initializing AdaBoost Regressor
2024-05-04 17:34:14,598:INFO:Total runtime is 0.8788637320200603 minutes
2024-05-04 17:34:14,600:INFO:SubProcess create_model() called ==================================
2024-05-04 17:34:14,600:INFO:Initializing create_model()
2024-05-04 17:34:14,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:34:14,601:INFO:Checking exceptions
2024-05-04 17:34:14,601:INFO:Importing libraries
2024-05-04 17:34:14,601:INFO:Copying training dataset
2024-05-04 17:34:14,616:INFO:Defining folds
2024-05-04 17:34:14,616:INFO:Declaring metric variables
2024-05-04 17:34:14,617:INFO:Importing untrained model
2024-05-04 17:34:14,619:INFO:AdaBoost Regressor Imported successfully
2024-05-04 17:34:14,622:INFO:Starting cross validation
2024-05-04 17:34:14,622:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:34:20,240:INFO:Calculating mean and std
2024-05-04 17:34:20,241:INFO:Creating metrics dataframe
2024-05-04 17:34:20,242:INFO:Uploading results into container
2024-05-04 17:34:20,243:INFO:Uploading model into container now
2024-05-04 17:34:20,243:INFO:_master_model_container: 15
2024-05-04 17:34:20,243:INFO:_display_container: 2
2024-05-04 17:34:20,243:INFO:AdaBoostRegressor(random_state=123)
2024-05-04 17:34:20,243:INFO:create_model() successfully completed......................................
2024-05-04 17:34:20,383:INFO:SubProcess create_model() end ==================================
2024-05-04 17:34:20,384:INFO:Creating metrics dataframe
2024-05-04 17:34:20,388:INFO:Initializing Gradient Boosting Regressor
2024-05-04 17:34:20,388:INFO:Total runtime is 0.9753582318623861 minutes
2024-05-04 17:34:20,389:INFO:SubProcess create_model() called ==================================
2024-05-04 17:34:20,389:INFO:Initializing create_model()
2024-05-04 17:34:20,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:34:20,389:INFO:Checking exceptions
2024-05-04 17:34:20,389:INFO:Importing libraries
2024-05-04 17:34:20,390:INFO:Copying training dataset
2024-05-04 17:34:20,401:INFO:Defining folds
2024-05-04 17:34:20,402:INFO:Declaring metric variables
2024-05-04 17:34:20,403:INFO:Importing untrained model
2024-05-04 17:34:20,405:INFO:Gradient Boosting Regressor Imported successfully
2024-05-04 17:34:20,408:INFO:Starting cross validation
2024-05-04 17:34:20,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:34:40,655:INFO:Calculating mean and std
2024-05-04 17:34:40,657:INFO:Creating metrics dataframe
2024-05-04 17:34:40,658:INFO:Uploading results into container
2024-05-04 17:34:40,658:INFO:Uploading model into container now
2024-05-04 17:34:40,658:INFO:_master_model_container: 16
2024-05-04 17:34:40,658:INFO:_display_container: 2
2024-05-04 17:34:40,659:INFO:GradientBoostingRegressor(random_state=123)
2024-05-04 17:34:40,659:INFO:create_model() successfully completed......................................
2024-05-04 17:34:40,899:INFO:SubProcess create_model() end ==================================
2024-05-04 17:34:40,899:INFO:Creating metrics dataframe
2024-05-04 17:34:40,904:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 17:34:40,904:INFO:Total runtime is 1.3172898809115092 minutes
2024-05-04 17:34:40,905:INFO:SubProcess create_model() called ==================================
2024-05-04 17:34:40,906:INFO:Initializing create_model()
2024-05-04 17:34:40,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:34:40,906:INFO:Checking exceptions
2024-05-04 17:34:40,906:INFO:Importing libraries
2024-05-04 17:34:40,906:INFO:Copying training dataset
2024-05-04 17:34:40,920:INFO:Defining folds
2024-05-04 17:34:40,921:INFO:Declaring metric variables
2024-05-04 17:34:40,922:INFO:Importing untrained model
2024-05-04 17:34:40,923:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 17:34:40,926:INFO:Starting cross validation
2024-05-04 17:34:40,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:34:41,826:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 17:34:41,828:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 17:34:41,828:INFO:Initializing create_model()
2024-05-04 17:34:41,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:34:41,828:INFO:Checking exceptions
2024-05-04 17:34:41,828:INFO:Importing libraries
2024-05-04 17:34:41,828:INFO:Copying training dataset
2024-05-04 17:34:41,840:INFO:Defining folds
2024-05-04 17:34:41,840:INFO:Declaring metric variables
2024-05-04 17:34:41,841:INFO:Importing untrained model
2024-05-04 17:34:41,843:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 17:34:41,845:INFO:Starting cross validation
2024-05-04 17:34:41,846:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:34:45,755:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 17:34:45,757:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 17:34:45,757:INFO:Initializing Dummy Regressor
2024-05-04 17:34:45,757:INFO:Total runtime is 1.3981743137041729 minutes
2024-05-04 17:34:45,761:INFO:SubProcess create_model() called ==================================
2024-05-04 17:34:45,761:INFO:Initializing create_model()
2024-05-04 17:34:45,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3246bc3d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:34:45,762:INFO:Checking exceptions
2024-05-04 17:34:45,762:INFO:Importing libraries
2024-05-04 17:34:45,762:INFO:Copying training dataset
2024-05-04 17:34:45,774:INFO:Defining folds
2024-05-04 17:34:45,774:INFO:Declaring metric variables
2024-05-04 17:34:45,776:INFO:Importing untrained model
2024-05-04 17:34:45,778:INFO:Dummy Regressor Imported successfully
2024-05-04 17:34:45,780:INFO:Starting cross validation
2024-05-04 17:34:45,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 17:34:48,079:INFO:Calculating mean and std
2024-05-04 17:34:48,081:INFO:Creating metrics dataframe
2024-05-04 17:34:48,083:INFO:Uploading results into container
2024-05-04 17:34:48,084:INFO:Uploading model into container now
2024-05-04 17:34:48,084:INFO:_master_model_container: 17
2024-05-04 17:34:48,084:INFO:_display_container: 2
2024-05-04 17:34:48,084:INFO:DummyRegressor()
2024-05-04 17:34:48,084:INFO:create_model() successfully completed......................................
2024-05-04 17:34:48,314:INFO:SubProcess create_model() end ==================================
2024-05-04 17:34:48,315:INFO:Creating metrics dataframe
2024-05-04 17:34:48,320:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 17:34:48,324:INFO:Initializing create_model()
2024-05-04 17:34:48,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x3246ef090>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 17:34:48,324:INFO:Checking exceptions
2024-05-04 17:34:48,325:INFO:Importing libraries
2024-05-04 17:34:48,325:INFO:Copying training dataset
2024-05-04 17:34:48,338:INFO:Defining folds
2024-05-04 17:34:48,338:INFO:Declaring metric variables
2024-05-04 17:34:48,338:INFO:Importing untrained model
2024-05-04 17:34:48,338:INFO:Declaring custom model
2024-05-04 17:34:48,338:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-04 17:34:48,339:INFO:Cross validation set to False
2024-05-04 17:34:48,339:INFO:Fitting Model
2024-05-04 17:34:48,349:INFO:OrthogonalMatchingPursuit()
2024-05-04 17:34:48,349:INFO:create_model() successfully completed......................................
2024-05-04 17:34:48,508:INFO:_master_model_container: 17
2024-05-04 17:34:48,508:INFO:_display_container: 2
2024-05-04 17:34:48,508:INFO:OrthogonalMatchingPursuit()
2024-05-04 17:34:48,508:INFO:compare_models() successfully completed......................................
2024-05-04 18:30:30,391:INFO:PyCaret RegressionExperiment
2024-05-04 18:30:30,391:INFO:Logging name: reg-default-name
2024-05-04 18:30:30,391:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 18:30:30,391:INFO:version 3.3.2
2024-05-04 18:30:30,391:INFO:Initializing setup()
2024-05-04 18:30:30,391:INFO:self.USI: 1472
2024-05-04 18:30:30,391:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 18:30:30,391:INFO:Checking environment
2024-05-04 18:30:30,391:INFO:python_version: 3.11.8
2024-05-04 18:30:30,391:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 18:30:30,391:INFO:machine: arm64
2024-05-04 18:30:30,391:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:30:30,391:INFO:Memory: svmem(total=17179869184, available=3805511680, percent=77.8, used=5817073664, free=53460992, active=3770187776, inactive=3747889152, wired=2046885888)
2024-05-04 18:30:30,391:INFO:Physical Core: 8
2024-05-04 18:30:30,391:INFO:Logical Core: 8
2024-05-04 18:30:30,391:INFO:Checking libraries
2024-05-04 18:30:30,391:INFO:System:
2024-05-04 18:30:30,392:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 18:30:30,392:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 18:30:30,392:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:30:30,392:INFO:PyCaret required dependencies:
2024-05-04 18:30:30,392:INFO:                 pip: 24.0
2024-05-04 18:30:30,392:INFO:          setuptools: 69.2.0
2024-05-04 18:30:30,392:INFO:             pycaret: 3.3.2
2024-05-04 18:30:30,392:INFO:             IPython: 8.22.2
2024-05-04 18:30:30,392:INFO:          ipywidgets: 8.1.2
2024-05-04 18:30:30,392:INFO:                tqdm: 4.66.2
2024-05-04 18:30:30,392:INFO:               numpy: 1.26.4
2024-05-04 18:30:30,392:INFO:              pandas: 2.1.4
2024-05-04 18:30:30,392:INFO:              jinja2: 3.1.3
2024-05-04 18:30:30,392:INFO:               scipy: 1.11.4
2024-05-04 18:30:30,392:INFO:              joblib: 1.3.2
2024-05-04 18:30:30,392:INFO:             sklearn: 1.4.1.post1
2024-05-04 18:30:30,392:INFO:                pyod: 1.1.3
2024-05-04 18:30:30,392:INFO:            imblearn: 0.12.2
2024-05-04 18:30:30,392:INFO:   category_encoders: 2.6.3
2024-05-04 18:30:30,392:INFO:            lightgbm: 4.3.0
2024-05-04 18:30:30,392:INFO:               numba: 0.59.1
2024-05-04 18:30:30,392:INFO:            requests: 2.31.0
2024-05-04 18:30:30,392:INFO:          matplotlib: 3.7.5
2024-05-04 18:30:30,392:INFO:          scikitplot: 0.3.7
2024-05-04 18:30:30,392:INFO:         yellowbrick: 1.5
2024-05-04 18:30:30,392:INFO:              plotly: 5.19.0
2024-05-04 18:30:30,392:INFO:    plotly-resampler: Not installed
2024-05-04 18:30:30,392:INFO:             kaleido: 0.2.1
2024-05-04 18:30:30,392:INFO:           schemdraw: 0.15
2024-05-04 18:30:30,392:INFO:         statsmodels: 0.14.1
2024-05-04 18:30:30,392:INFO:              sktime: 0.26.0
2024-05-04 18:30:30,392:INFO:               tbats: 1.1.3
2024-05-04 18:30:30,392:INFO:            pmdarima: 2.0.4
2024-05-04 18:30:30,392:INFO:              psutil: 5.9.8
2024-05-04 18:30:30,392:INFO:          markupsafe: 2.1.5
2024-05-04 18:30:30,392:INFO:             pickle5: Not installed
2024-05-04 18:30:30,392:INFO:         cloudpickle: 3.0.0
2024-05-04 18:30:30,392:INFO:         deprecation: 2.1.0
2024-05-04 18:30:30,392:INFO:              xxhash: 3.4.1
2024-05-04 18:30:30,392:INFO:           wurlitzer: 3.0.3
2024-05-04 18:30:30,392:INFO:PyCaret optional dependencies:
2024-05-04 18:30:30,392:INFO:                shap: 0.44.1
2024-05-04 18:30:30,392:INFO:           interpret: 0.6.1
2024-05-04 18:30:30,392:INFO:                umap: 0.5.6
2024-05-04 18:30:30,392:INFO:     ydata_profiling: 4.7.0
2024-05-04 18:30:30,392:INFO:  explainerdashboard: 0.4.7
2024-05-04 18:30:30,392:INFO:             autoviz: Not installed
2024-05-04 18:30:30,392:INFO:           fairlearn: 0.7.0
2024-05-04 18:30:30,392:INFO:          deepchecks: Not installed
2024-05-04 18:30:30,392:INFO:             xgboost: Not installed
2024-05-04 18:30:30,392:INFO:            catboost: Not installed
2024-05-04 18:30:30,392:INFO:              kmodes: Not installed
2024-05-04 18:30:30,392:INFO:             mlxtend: 0.23.1
2024-05-04 18:30:30,392:INFO:       statsforecast: Not installed
2024-05-04 18:30:30,392:INFO:        tune_sklearn: Not installed
2024-05-04 18:30:30,392:INFO:                 ray: Not installed
2024-05-04 18:30:30,392:INFO:            hyperopt: 0.2.7
2024-05-04 18:30:30,392:INFO:              optuna: 3.6.1
2024-05-04 18:30:30,392:INFO:               skopt: 0.10.1
2024-05-04 18:30:30,393:INFO:              mlflow: 2.12.1
2024-05-04 18:30:30,393:INFO:              gradio: 4.29.0
2024-05-04 18:30:30,393:INFO:             fastapi: 0.111.0
2024-05-04 18:30:30,393:INFO:             uvicorn: 0.29.0
2024-05-04 18:30:30,393:INFO:              m2cgen: 0.10.0
2024-05-04 18:30:30,393:INFO:           evidently: 0.4.20
2024-05-04 18:30:30,393:INFO:               fugue: 0.8.7
2024-05-04 18:30:30,393:INFO:           streamlit: 1.33.0
2024-05-04 18:30:30,393:INFO:             prophet: Not installed
2024-05-04 18:30:30,393:INFO:None
2024-05-04 18:30:30,393:INFO:Set up data.
2024-05-04 18:30:56,408:INFO:PyCaret RegressionExperiment
2024-05-04 18:30:56,408:INFO:Logging name: reg-default-name
2024-05-04 18:30:56,408:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 18:30:56,408:INFO:version 3.3.2
2024-05-04 18:30:56,408:INFO:Initializing setup()
2024-05-04 18:30:56,408:INFO:self.USI: e3c5
2024-05-04 18:30:56,408:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 18:30:56,408:INFO:Checking environment
2024-05-04 18:30:56,408:INFO:python_version: 3.11.8
2024-05-04 18:30:56,408:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 18:30:56,408:INFO:machine: arm64
2024-05-04 18:30:56,408:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:30:56,408:INFO:Memory: svmem(total=17179869184, available=3644604416, percent=78.8, used=5833998336, free=48545792, active=3605020672, inactive=3590979584, wired=2228977664)
2024-05-04 18:30:56,408:INFO:Physical Core: 8
2024-05-04 18:30:56,408:INFO:Logical Core: 8
2024-05-04 18:30:56,408:INFO:Checking libraries
2024-05-04 18:30:56,408:INFO:System:
2024-05-04 18:30:56,408:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 18:30:56,408:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 18:30:56,408:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:30:56,408:INFO:PyCaret required dependencies:
2024-05-04 18:30:56,409:INFO:                 pip: 24.0
2024-05-04 18:30:56,409:INFO:          setuptools: 69.2.0
2024-05-04 18:30:56,409:INFO:             pycaret: 3.3.2
2024-05-04 18:30:56,409:INFO:             IPython: 8.22.2
2024-05-04 18:30:56,409:INFO:          ipywidgets: 8.1.2
2024-05-04 18:30:56,409:INFO:                tqdm: 4.66.2
2024-05-04 18:30:56,409:INFO:               numpy: 1.26.4
2024-05-04 18:30:56,409:INFO:              pandas: 2.1.4
2024-05-04 18:30:56,409:INFO:              jinja2: 3.1.3
2024-05-04 18:30:56,409:INFO:               scipy: 1.11.4
2024-05-04 18:30:56,409:INFO:              joblib: 1.3.2
2024-05-04 18:30:56,409:INFO:             sklearn: 1.4.1.post1
2024-05-04 18:30:56,409:INFO:                pyod: 1.1.3
2024-05-04 18:30:56,409:INFO:            imblearn: 0.12.2
2024-05-04 18:30:56,409:INFO:   category_encoders: 2.6.3
2024-05-04 18:30:56,409:INFO:            lightgbm: 4.3.0
2024-05-04 18:30:56,409:INFO:               numba: 0.59.1
2024-05-04 18:30:56,409:INFO:            requests: 2.31.0
2024-05-04 18:30:56,409:INFO:          matplotlib: 3.7.5
2024-05-04 18:30:56,409:INFO:          scikitplot: 0.3.7
2024-05-04 18:30:56,409:INFO:         yellowbrick: 1.5
2024-05-04 18:30:56,409:INFO:              plotly: 5.19.0
2024-05-04 18:30:56,409:INFO:    plotly-resampler: Not installed
2024-05-04 18:30:56,409:INFO:             kaleido: 0.2.1
2024-05-04 18:30:56,409:INFO:           schemdraw: 0.15
2024-05-04 18:30:56,409:INFO:         statsmodels: 0.14.1
2024-05-04 18:30:56,409:INFO:              sktime: 0.26.0
2024-05-04 18:30:56,409:INFO:               tbats: 1.1.3
2024-05-04 18:30:56,409:INFO:            pmdarima: 2.0.4
2024-05-04 18:30:56,409:INFO:              psutil: 5.9.8
2024-05-04 18:30:56,409:INFO:          markupsafe: 2.1.5
2024-05-04 18:30:56,409:INFO:             pickle5: Not installed
2024-05-04 18:30:56,409:INFO:         cloudpickle: 3.0.0
2024-05-04 18:30:56,409:INFO:         deprecation: 2.1.0
2024-05-04 18:30:56,409:INFO:              xxhash: 3.4.1
2024-05-04 18:30:56,409:INFO:           wurlitzer: 3.0.3
2024-05-04 18:30:56,409:INFO:PyCaret optional dependencies:
2024-05-04 18:30:56,409:INFO:                shap: 0.44.1
2024-05-04 18:30:56,409:INFO:           interpret: 0.6.1
2024-05-04 18:30:56,409:INFO:                umap: 0.5.6
2024-05-04 18:30:56,409:INFO:     ydata_profiling: 4.7.0
2024-05-04 18:30:56,409:INFO:  explainerdashboard: 0.4.7
2024-05-04 18:30:56,409:INFO:             autoviz: Not installed
2024-05-04 18:30:56,409:INFO:           fairlearn: 0.7.0
2024-05-04 18:30:56,409:INFO:          deepchecks: Not installed
2024-05-04 18:30:56,409:INFO:             xgboost: Not installed
2024-05-04 18:30:56,409:INFO:            catboost: Not installed
2024-05-04 18:30:56,409:INFO:              kmodes: Not installed
2024-05-04 18:30:56,409:INFO:             mlxtend: 0.23.1
2024-05-04 18:30:56,409:INFO:       statsforecast: Not installed
2024-05-04 18:30:56,409:INFO:        tune_sklearn: Not installed
2024-05-04 18:30:56,409:INFO:                 ray: Not installed
2024-05-04 18:30:56,409:INFO:            hyperopt: 0.2.7
2024-05-04 18:30:56,409:INFO:              optuna: 3.6.1
2024-05-04 18:30:56,409:INFO:               skopt: 0.10.1
2024-05-04 18:30:56,409:INFO:              mlflow: 2.12.1
2024-05-04 18:30:56,409:INFO:              gradio: 4.29.0
2024-05-04 18:30:56,409:INFO:             fastapi: 0.111.0
2024-05-04 18:30:56,409:INFO:             uvicorn: 0.29.0
2024-05-04 18:30:56,409:INFO:              m2cgen: 0.10.0
2024-05-04 18:30:56,409:INFO:           evidently: 0.4.20
2024-05-04 18:30:56,409:INFO:               fugue: 0.8.7
2024-05-04 18:30:56,409:INFO:           streamlit: 1.33.0
2024-05-04 18:30:56,409:INFO:             prophet: Not installed
2024-05-04 18:30:56,409:INFO:None
2024-05-04 18:30:56,409:INFO:Set up data.
2024-05-04 18:30:56,416:INFO:Set up folding strategy.
2024-05-04 18:30:56,416:INFO:Set up train/test split.
2024-05-04 18:30:56,424:INFO:Set up index.
2024-05-04 18:30:56,425:INFO:Assigning column types.
2024-05-04 18:30:56,432:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 18:30:56,432:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,435:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,437:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,486:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,487:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,489:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,519:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,539:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 18:30:56,541:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,543:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,572:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,594:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,595:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,624:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,644:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 18:30:56,648:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,699:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,747:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 18:30:56,778:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,797:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 18:30:56,881:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,935:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:30:56,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:56,955:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 18:30:57,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:57,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:57,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:57,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:57,061:INFO:Preparing preprocessing pipeline...
2024-05-04 18:30:57,061:INFO:Set up simple imputation.
2024-05-04 18:30:57,064:INFO:Set up encoding of categorical features.
2024-05-04 18:30:57,097:INFO:Finished creating preprocessing pipeline.
2024-05-04 18:30:57,099:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['I1', 'I2', 'I3', 'I5', 'I6', 'I7',
                                             'I8', 'I9', 'I10', 'I11', 'I19',
                                             'I20', 'I25', 'I29', 'I30', 'I31',
                                             'I33', 'I34', 'I35', 'I36', 'I37',
                                             'I38', 'I39', 'I40', 'I41', 'I42',
                                             'I43', 'I47', 'I53', 'I54', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Group'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Group'],
                                    transformer=OneHotEncoder(cols=['Group'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2024-05-04 18:30:57,099:INFO:Creating final display dataframe.
2024-05-04 18:30:57,193:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Perform
2                   Target type        Regression
3           Original data shape        (8000, 33)
4        Transformed data shape        (8000, 43)
5   Transformed train set shape        (5600, 43)
6    Transformed test set shape        (2400, 43)
7              Numeric features                31
8          Categorical features                 1
9      Rows with missing values              1.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              e3c5
2024-05-04 18:30:57,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:57,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:57,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:57,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:30:57,311:INFO:setup() successfully completed in 0.91s...............
2024-05-04 18:34:42,819:INFO:PyCaret RegressionExperiment
2024-05-04 18:34:42,819:INFO:Logging name: reg-default-name
2024-05-04 18:34:42,820:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 18:34:42,820:INFO:version 3.3.2
2024-05-04 18:34:42,820:INFO:Initializing setup()
2024-05-04 18:34:42,820:INFO:self.USI: 4344
2024-05-04 18:34:42,820:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'USI', 'gpu_param', '_available_plots', 'X', 'target_param', 'seed', 'fold_shuffle_param', 'memory', 'transform_target_param', 'fold_generator', 'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'n_jobs_param', 'X_test', 'fold_groups_param', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'y', 'pipeline', 'y_train'}
2024-05-04 18:34:42,820:INFO:Checking environment
2024-05-04 18:34:42,820:INFO:python_version: 3.11.8
2024-05-04 18:34:42,820:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 18:34:42,820:INFO:machine: arm64
2024-05-04 18:34:42,820:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:34:42,820:INFO:Memory: svmem(total=17179869184, available=3896524800, percent=77.3, used=5915443200, free=50249728, active=3857612800, inactive=3835592704, wired=2057830400)
2024-05-04 18:34:42,820:INFO:Physical Core: 8
2024-05-04 18:34:42,820:INFO:Logical Core: 8
2024-05-04 18:34:42,820:INFO:Checking libraries
2024-05-04 18:34:42,820:INFO:System:
2024-05-04 18:34:42,820:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 18:34:42,820:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 18:34:42,820:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:34:42,820:INFO:PyCaret required dependencies:
2024-05-04 18:34:42,820:INFO:                 pip: 24.0
2024-05-04 18:34:42,820:INFO:          setuptools: 69.2.0
2024-05-04 18:34:42,820:INFO:             pycaret: 3.3.2
2024-05-04 18:34:42,820:INFO:             IPython: 8.22.2
2024-05-04 18:34:42,820:INFO:          ipywidgets: 8.1.2
2024-05-04 18:34:42,820:INFO:                tqdm: 4.66.2
2024-05-04 18:34:42,820:INFO:               numpy: 1.26.4
2024-05-04 18:34:42,820:INFO:              pandas: 2.1.4
2024-05-04 18:34:42,820:INFO:              jinja2: 3.1.3
2024-05-04 18:34:42,820:INFO:               scipy: 1.11.4
2024-05-04 18:34:42,820:INFO:              joblib: 1.3.2
2024-05-04 18:34:42,820:INFO:             sklearn: 1.4.1.post1
2024-05-04 18:34:42,820:INFO:                pyod: 1.1.3
2024-05-04 18:34:42,820:INFO:            imblearn: 0.12.2
2024-05-04 18:34:42,820:INFO:   category_encoders: 2.6.3
2024-05-04 18:34:42,820:INFO:            lightgbm: 4.3.0
2024-05-04 18:34:42,820:INFO:               numba: 0.59.1
2024-05-04 18:34:42,820:INFO:            requests: 2.31.0
2024-05-04 18:34:42,820:INFO:          matplotlib: 3.7.5
2024-05-04 18:34:42,820:INFO:          scikitplot: 0.3.7
2024-05-04 18:34:42,820:INFO:         yellowbrick: 1.5
2024-05-04 18:34:42,820:INFO:              plotly: 5.19.0
2024-05-04 18:34:42,820:INFO:    plotly-resampler: Not installed
2024-05-04 18:34:42,820:INFO:             kaleido: 0.2.1
2024-05-04 18:34:42,820:INFO:           schemdraw: 0.15
2024-05-04 18:34:42,820:INFO:         statsmodels: 0.14.1
2024-05-04 18:34:42,820:INFO:              sktime: 0.26.0
2024-05-04 18:34:42,820:INFO:               tbats: 1.1.3
2024-05-04 18:34:42,820:INFO:            pmdarima: 2.0.4
2024-05-04 18:34:42,820:INFO:              psutil: 5.9.8
2024-05-04 18:34:42,820:INFO:          markupsafe: 2.1.5
2024-05-04 18:34:42,820:INFO:             pickle5: Not installed
2024-05-04 18:34:42,820:INFO:         cloudpickle: 3.0.0
2024-05-04 18:34:42,821:INFO:         deprecation: 2.1.0
2024-05-04 18:34:42,821:INFO:              xxhash: 3.4.1
2024-05-04 18:34:42,821:INFO:           wurlitzer: 3.0.3
2024-05-04 18:34:42,821:INFO:PyCaret optional dependencies:
2024-05-04 18:34:42,821:INFO:                shap: 0.44.1
2024-05-04 18:34:42,821:INFO:           interpret: 0.6.1
2024-05-04 18:34:42,821:INFO:                umap: 0.5.6
2024-05-04 18:34:42,821:INFO:     ydata_profiling: 4.7.0
2024-05-04 18:34:42,821:INFO:  explainerdashboard: 0.4.7
2024-05-04 18:34:42,821:INFO:             autoviz: Not installed
2024-05-04 18:34:42,821:INFO:           fairlearn: 0.7.0
2024-05-04 18:34:42,821:INFO:          deepchecks: Not installed
2024-05-04 18:34:42,821:INFO:             xgboost: Not installed
2024-05-04 18:34:42,821:INFO:            catboost: Not installed
2024-05-04 18:34:42,821:INFO:              kmodes: Not installed
2024-05-04 18:34:42,821:INFO:             mlxtend: 0.23.1
2024-05-04 18:34:42,821:INFO:       statsforecast: Not installed
2024-05-04 18:34:42,821:INFO:        tune_sklearn: Not installed
2024-05-04 18:34:42,821:INFO:                 ray: Not installed
2024-05-04 18:34:42,821:INFO:            hyperopt: 0.2.7
2024-05-04 18:34:42,821:INFO:              optuna: 3.6.1
2024-05-04 18:34:42,821:INFO:               skopt: 0.10.1
2024-05-04 18:34:42,821:INFO:              mlflow: 2.12.1
2024-05-04 18:34:42,821:INFO:              gradio: 4.29.0
2024-05-04 18:34:42,821:INFO:             fastapi: 0.111.0
2024-05-04 18:34:42,821:INFO:             uvicorn: 0.29.0
2024-05-04 18:34:42,821:INFO:              m2cgen: 0.10.0
2024-05-04 18:34:42,821:INFO:           evidently: 0.4.20
2024-05-04 18:34:42,821:INFO:               fugue: 0.8.7
2024-05-04 18:34:42,821:INFO:           streamlit: 1.33.0
2024-05-04 18:34:42,821:INFO:             prophet: Not installed
2024-05-04 18:34:42,821:INFO:None
2024-05-04 18:34:42,821:INFO:Set up data.
2024-05-04 18:34:42,843:INFO:Set up folding strategy.
2024-05-04 18:34:42,843:INFO:Set up train/test split.
2024-05-04 18:34:42,850:INFO:Set up index.
2024-05-04 18:34:42,850:INFO:Assigning column types.
2024-05-04 18:34:42,855:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 18:34:42,856:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,859:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,895:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,914:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:42,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:42,915:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,917:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,919:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,948:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:42,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:42,968:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 18:34:42,970:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:34:42,972:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,019:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,022:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,024:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,075:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,076:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 18:34:43,080:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,108:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,132:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,180:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 18:34:43,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,231:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,283:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 18:34:43,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,387:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 18:34:43,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,491:INFO:Preparing preprocessing pipeline...
2024-05-04 18:34:43,491:INFO:Set up iterative imputation.
2024-05-04 18:34:43,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,570:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-04 18:34:43,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:34:43,626:INFO:Set up encoding of categorical features.
2024-05-04 18:39:17,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 18:39:17,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 18:39:17,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 18:39:17,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-04 18:40:20,028:INFO:PyCaret RegressionExperiment
2024-05-04 18:40:20,028:INFO:Logging name: reg-default-name
2024-05-04 18:40:20,029:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 18:40:20,029:INFO:version 3.3.2
2024-05-04 18:40:20,029:INFO:Initializing setup()
2024-05-04 18:40:20,029:INFO:self.USI: f402
2024-05-04 18:40:20,029:INFO:self._variable_keys: {'fold_generator', 'memory', '_ml_usecase', 'transform_target_param', 'n_jobs_param', 'logging_param', 'X', 'exp_id', 'X_train', 'data', 'gpu_n_jobs_param', 'y', 'log_plots_param', 'X_test', 'idx', 'pipeline', 'y_train', 'html_param', 'exp_name_log', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'y_test', 'fold_groups_param', 'USI', 'seed', 'target_param'}
2024-05-04 18:40:20,029:INFO:Checking environment
2024-05-04 18:40:20,029:INFO:python_version: 3.11.8
2024-05-04 18:40:20,029:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 18:40:20,029:INFO:machine: arm64
2024-05-04 18:40:20,029:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:40:20,029:INFO:Memory: svmem(total=17179869184, available=4163108864, percent=75.8, used=6273859584, free=48332800, active=4128260096, inactive=4112236544, wired=2145599488)
2024-05-04 18:40:20,029:INFO:Physical Core: 8
2024-05-04 18:40:20,029:INFO:Logical Core: 8
2024-05-04 18:40:20,029:INFO:Checking libraries
2024-05-04 18:40:20,029:INFO:System:
2024-05-04 18:40:20,029:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 18:40:20,029:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 18:40:20,029:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:40:20,029:INFO:PyCaret required dependencies:
2024-05-04 18:40:20,671:INFO:                 pip: 24.0
2024-05-04 18:40:20,671:INFO:          setuptools: 69.2.0
2024-05-04 18:40:20,671:INFO:             pycaret: 3.3.2
2024-05-04 18:40:20,671:INFO:             IPython: 8.22.2
2024-05-04 18:40:20,671:INFO:          ipywidgets: 8.1.2
2024-05-04 18:40:20,671:INFO:                tqdm: 4.66.2
2024-05-04 18:40:20,671:INFO:               numpy: 1.26.4
2024-05-04 18:40:20,671:INFO:              pandas: 2.1.4
2024-05-04 18:40:20,671:INFO:              jinja2: 3.1.3
2024-05-04 18:40:20,672:INFO:               scipy: 1.11.4
2024-05-04 18:40:20,672:INFO:              joblib: 1.3.2
2024-05-04 18:40:20,672:INFO:             sklearn: 1.4.1.post1
2024-05-04 18:40:20,672:INFO:                pyod: 1.1.3
2024-05-04 18:40:20,672:INFO:            imblearn: 0.12.2
2024-05-04 18:40:20,672:INFO:   category_encoders: 2.6.3
2024-05-04 18:40:20,672:INFO:            lightgbm: 4.3.0
2024-05-04 18:40:20,672:INFO:               numba: 0.59.1
2024-05-04 18:40:20,672:INFO:            requests: 2.31.0
2024-05-04 18:40:20,672:INFO:          matplotlib: 3.7.5
2024-05-04 18:40:20,672:INFO:          scikitplot: 0.3.7
2024-05-04 18:40:20,672:INFO:         yellowbrick: 1.5
2024-05-04 18:40:20,672:INFO:              plotly: 5.19.0
2024-05-04 18:40:20,672:INFO:    plotly-resampler: Not installed
2024-05-04 18:40:20,672:INFO:             kaleido: 0.2.1
2024-05-04 18:40:20,672:INFO:           schemdraw: 0.15
2024-05-04 18:40:20,672:INFO:         statsmodels: 0.14.1
2024-05-04 18:40:20,672:INFO:              sktime: 0.26.0
2024-05-04 18:40:20,672:INFO:               tbats: 1.1.3
2024-05-04 18:40:20,672:INFO:            pmdarima: 2.0.4
2024-05-04 18:40:20,672:INFO:              psutil: 5.9.8
2024-05-04 18:40:20,672:INFO:          markupsafe: 2.1.5
2024-05-04 18:40:20,672:INFO:             pickle5: Not installed
2024-05-04 18:40:20,672:INFO:         cloudpickle: 3.0.0
2024-05-04 18:40:20,672:INFO:         deprecation: 2.1.0
2024-05-04 18:40:20,672:INFO:              xxhash: 3.4.1
2024-05-04 18:40:20,672:INFO:           wurlitzer: 3.0.3
2024-05-04 18:40:20,672:INFO:PyCaret optional dependencies:
2024-05-04 18:40:21,917:INFO:                shap: 0.44.1
2024-05-04 18:40:21,917:INFO:           interpret: 0.6.1
2024-05-04 18:40:21,917:INFO:                umap: 0.5.6
2024-05-04 18:40:21,917:INFO:     ydata_profiling: 4.7.0
2024-05-04 18:40:21,917:INFO:  explainerdashboard: 0.4.7
2024-05-04 18:40:21,917:INFO:             autoviz: Not installed
2024-05-04 18:40:21,917:INFO:           fairlearn: 0.7.0
2024-05-04 18:40:21,917:INFO:          deepchecks: Not installed
2024-05-04 18:40:21,917:INFO:             xgboost: Not installed
2024-05-04 18:40:21,917:INFO:            catboost: Not installed
2024-05-04 18:40:21,917:INFO:              kmodes: Not installed
2024-05-04 18:40:21,917:INFO:             mlxtend: 0.23.1
2024-05-04 18:40:21,917:INFO:       statsforecast: Not installed
2024-05-04 18:40:21,917:INFO:        tune_sklearn: Not installed
2024-05-04 18:40:21,917:INFO:                 ray: Not installed
2024-05-04 18:40:21,917:INFO:            hyperopt: 0.2.7
2024-05-04 18:40:21,917:INFO:              optuna: 3.6.1
2024-05-04 18:40:21,917:INFO:               skopt: 0.10.1
2024-05-04 18:40:21,917:INFO:              mlflow: 2.12.1
2024-05-04 18:40:21,917:INFO:              gradio: 4.29.0
2024-05-04 18:40:21,917:INFO:             fastapi: 0.111.0
2024-05-04 18:40:21,917:INFO:             uvicorn: 0.29.0
2024-05-04 18:40:21,917:INFO:              m2cgen: 0.10.0
2024-05-04 18:40:21,917:INFO:           evidently: 0.4.20
2024-05-04 18:40:21,917:INFO:               fugue: 0.8.7
2024-05-04 18:40:21,917:INFO:           streamlit: 1.33.0
2024-05-04 18:40:21,917:INFO:             prophet: Not installed
2024-05-04 18:40:21,917:INFO:None
2024-05-04 18:40:21,917:INFO:Set up data.
2024-05-04 18:40:21,925:INFO:Set up folding strategy.
2024-05-04 18:40:21,925:INFO:Set up train/test split.
2024-05-04 18:40:21,931:INFO:Set up index.
2024-05-04 18:40:21,931:INFO:Assigning column types.
2024-05-04 18:40:21,937:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 18:40:21,937:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:40:21,939:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:40:21,941:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:21,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:21,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:21,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:21,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:21,993:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:40:21,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:40:21,997:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,044:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 18:40:22,046:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,097:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,100:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,210:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,212:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 18:40:22,217:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,264:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,294:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,329:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,400:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,400:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 18:40:22,435:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,489:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,508:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 18:40:22,539:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,558:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,590:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:22,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,609:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 18:40:22,662:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,714:INFO:Preparing preprocessing pipeline...
2024-05-04 18:40:22,714:INFO:Set up simple imputation.
2024-05-04 18:40:22,714:INFO:Set up removing multicollinearity.
2024-05-04 18:40:22,749:INFO:Finished creating preprocessing pipeline.
2024-05-04 18:40:22,752:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group', 'I1', 'I2', 'I3', 'I5',
                                             'I6', 'I7', 'I8', 'I9', 'I10',
                                             'I11', 'I19', 'I20', 'I25', 'I29',
                                             'I30', 'I31', 'I33', 'I34', 'I35',
                                             'I36', 'I37', 'I38', 'I39', 'I40',
                                             'I41', 'I42', 'I43', 'I47', 'I53', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-04 18:40:22,752:INFO:Creating final display dataframe.
2024-05-04 18:40:22,812:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Perform
2                   Target type        Regression
3           Original data shape        (8000, 33)
4        Transformed data shape        (8000, 28)
5   Transformed train set shape        (5600, 28)
6    Transformed test set shape        (2400, 28)
7              Numeric features                32
8      Rows with missing values              1.0%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Remove multicollinearity              True
14  Multicollinearity threshold               0.9
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              f402
2024-05-04 18:40:22,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:22,924:INFO:setup() successfully completed in 2.9s...............
2024-05-04 18:40:34,041:INFO:PyCaret RegressionExperiment
2024-05-04 18:40:34,041:INFO:Logging name: reg-default-name
2024-05-04 18:40:34,041:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 18:40:34,041:INFO:version 3.3.2
2024-05-04 18:40:34,041:INFO:Initializing setup()
2024-05-04 18:40:34,041:INFO:self.USI: 1384
2024-05-04 18:40:34,041:INFO:self._variable_keys: {'fold_generator', 'memory', '_ml_usecase', 'transform_target_param', 'n_jobs_param', 'logging_param', 'X', 'exp_id', 'X_train', 'data', 'gpu_n_jobs_param', 'y', 'log_plots_param', 'X_test', 'idx', 'pipeline', 'y_train', 'html_param', 'exp_name_log', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'y_test', 'fold_groups_param', 'USI', 'seed', 'target_param'}
2024-05-04 18:40:34,041:INFO:Checking environment
2024-05-04 18:40:34,041:INFO:python_version: 3.11.8
2024-05-04 18:40:34,041:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 18:40:34,041:INFO:machine: arm64
2024-05-04 18:40:34,041:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:40:34,041:INFO:Memory: svmem(total=17179869184, available=4037672960, percent=76.5, used=6202834944, free=29212672, active=4014112768, inactive=3999727616, wired=2188722176)
2024-05-04 18:40:34,041:INFO:Physical Core: 8
2024-05-04 18:40:34,041:INFO:Logical Core: 8
2024-05-04 18:40:34,042:INFO:Checking libraries
2024-05-04 18:40:34,042:INFO:System:
2024-05-04 18:40:34,042:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 18:40:34,042:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 18:40:34,042:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:40:34,042:INFO:PyCaret required dependencies:
2024-05-04 18:40:34,042:INFO:                 pip: 24.0
2024-05-04 18:40:34,042:INFO:          setuptools: 69.2.0
2024-05-04 18:40:34,042:INFO:             pycaret: 3.3.2
2024-05-04 18:40:34,042:INFO:             IPython: 8.22.2
2024-05-04 18:40:34,042:INFO:          ipywidgets: 8.1.2
2024-05-04 18:40:34,042:INFO:                tqdm: 4.66.2
2024-05-04 18:40:34,042:INFO:               numpy: 1.26.4
2024-05-04 18:40:34,042:INFO:              pandas: 2.1.4
2024-05-04 18:40:34,042:INFO:              jinja2: 3.1.3
2024-05-04 18:40:34,042:INFO:               scipy: 1.11.4
2024-05-04 18:40:34,042:INFO:              joblib: 1.3.2
2024-05-04 18:40:34,042:INFO:             sklearn: 1.4.1.post1
2024-05-04 18:40:34,042:INFO:                pyod: 1.1.3
2024-05-04 18:40:34,042:INFO:            imblearn: 0.12.2
2024-05-04 18:40:34,042:INFO:   category_encoders: 2.6.3
2024-05-04 18:40:34,042:INFO:            lightgbm: 4.3.0
2024-05-04 18:40:34,042:INFO:               numba: 0.59.1
2024-05-04 18:40:34,042:INFO:            requests: 2.31.0
2024-05-04 18:40:34,042:INFO:          matplotlib: 3.7.5
2024-05-04 18:40:34,042:INFO:          scikitplot: 0.3.7
2024-05-04 18:40:34,042:INFO:         yellowbrick: 1.5
2024-05-04 18:40:34,042:INFO:              plotly: 5.19.0
2024-05-04 18:40:34,042:INFO:    plotly-resampler: Not installed
2024-05-04 18:40:34,042:INFO:             kaleido: 0.2.1
2024-05-04 18:40:34,042:INFO:           schemdraw: 0.15
2024-05-04 18:40:34,042:INFO:         statsmodels: 0.14.1
2024-05-04 18:40:34,042:INFO:              sktime: 0.26.0
2024-05-04 18:40:34,042:INFO:               tbats: 1.1.3
2024-05-04 18:40:34,042:INFO:            pmdarima: 2.0.4
2024-05-04 18:40:34,042:INFO:              psutil: 5.9.8
2024-05-04 18:40:34,042:INFO:          markupsafe: 2.1.5
2024-05-04 18:40:34,042:INFO:             pickle5: Not installed
2024-05-04 18:40:34,042:INFO:         cloudpickle: 3.0.0
2024-05-04 18:40:34,042:INFO:         deprecation: 2.1.0
2024-05-04 18:40:34,042:INFO:              xxhash: 3.4.1
2024-05-04 18:40:34,042:INFO:           wurlitzer: 3.0.3
2024-05-04 18:40:34,042:INFO:PyCaret optional dependencies:
2024-05-04 18:40:34,043:INFO:                shap: 0.44.1
2024-05-04 18:40:34,043:INFO:           interpret: 0.6.1
2024-05-04 18:40:34,043:INFO:                umap: 0.5.6
2024-05-04 18:40:34,043:INFO:     ydata_profiling: 4.7.0
2024-05-04 18:40:34,043:INFO:  explainerdashboard: 0.4.7
2024-05-04 18:40:34,043:INFO:             autoviz: Not installed
2024-05-04 18:40:34,043:INFO:           fairlearn: 0.7.0
2024-05-04 18:40:34,043:INFO:          deepchecks: Not installed
2024-05-04 18:40:34,043:INFO:             xgboost: Not installed
2024-05-04 18:40:34,043:INFO:            catboost: Not installed
2024-05-04 18:40:34,043:INFO:              kmodes: Not installed
2024-05-04 18:40:34,043:INFO:             mlxtend: 0.23.1
2024-05-04 18:40:34,043:INFO:       statsforecast: Not installed
2024-05-04 18:40:34,043:INFO:        tune_sklearn: Not installed
2024-05-04 18:40:34,043:INFO:                 ray: Not installed
2024-05-04 18:40:34,043:INFO:            hyperopt: 0.2.7
2024-05-04 18:40:34,043:INFO:              optuna: 3.6.1
2024-05-04 18:40:34,043:INFO:               skopt: 0.10.1
2024-05-04 18:40:34,043:INFO:              mlflow: 2.12.1
2024-05-04 18:40:34,043:INFO:              gradio: 4.29.0
2024-05-04 18:40:34,043:INFO:             fastapi: 0.111.0
2024-05-04 18:40:34,043:INFO:             uvicorn: 0.29.0
2024-05-04 18:40:34,043:INFO:              m2cgen: 0.10.0
2024-05-04 18:40:34,043:INFO:           evidently: 0.4.20
2024-05-04 18:40:34,043:INFO:               fugue: 0.8.7
2024-05-04 18:40:34,043:INFO:           streamlit: 1.33.0
2024-05-04 18:40:34,043:INFO:             prophet: Not installed
2024-05-04 18:40:34,043:INFO:None
2024-05-04 18:40:34,043:INFO:Set up data.
2024-05-04 18:40:34,051:INFO:Set up folding strategy.
2024-05-04 18:40:34,051:INFO:Set up train/test split.
2024-05-04 18:40:34,058:INFO:Set up index.
2024-05-04 18:40:34,058:INFO:Assigning column types.
2024-05-04 18:40:34,064:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 18:40:34,064:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,067:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,069:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,119:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,121:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,123:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,150:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,170:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 18:40:34,172:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,173:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,201:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,222:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,223:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,278:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,280:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 18:40:34,284:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,443:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,493:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,497:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,546:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 18:40:34,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,597:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,650:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 18:40:34,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,733:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:40:34,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,753:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 18:40:34,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,858:INFO:Preparing preprocessing pipeline...
2024-05-04 18:40:34,858:INFO:Set up simple imputation.
2024-05-04 18:40:34,881:INFO:Finished creating preprocessing pipeline.
2024-05-04 18:40:34,887:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group', 'I1', 'I2', 'I3', 'I5',
                                             'I6', 'I7', 'I8', 'I9', 'I10',
                                             'I11', 'I19', 'I20', 'I25', 'I29',
                                             'I30', 'I31', 'I33', 'I34', 'I35',
                                             'I36', 'I37', 'I38', 'I39', 'I40',
                                             'I41', 'I42', 'I43', 'I47', 'I53', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-05-04 18:40:34,887:INFO:Creating final display dataframe.
2024-05-04 18:40:34,940:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Perform
2                   Target type        Regression
3           Original data shape        (8000, 33)
4        Transformed data shape        (8000, 33)
5   Transformed train set shape        (5600, 33)
6    Transformed test set shape        (2400, 33)
7              Numeric features                32
8      Rows with missing values              1.0%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator             KFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  reg-default-name
19                          USI              1384
2024-05-04 18:40:34,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:34,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:35,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:35,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:40:35,049:INFO:setup() successfully completed in 1.01s...............
2024-05-04 18:40:37,901:INFO:Initializing compare_models()
2024-05-04 18:40:37,901:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x301855350>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-04 18:40:37,901:INFO:Checking exceptions
2024-05-04 18:40:37,906:INFO:Preparing display monitor
2024-05-04 18:40:37,956:INFO:Initializing Linear Regression
2024-05-04 18:40:37,957:INFO:Total runtime is 1.0796387990315755e-05 minutes
2024-05-04 18:40:37,960:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:37,960:INFO:Initializing create_model()
2024-05-04 18:40:37,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:37,960:INFO:Checking exceptions
2024-05-04 18:40:37,960:INFO:Importing libraries
2024-05-04 18:40:37,960:INFO:Copying training dataset
2024-05-04 18:40:37,986:INFO:Defining folds
2024-05-04 18:40:37,986:INFO:Declaring metric variables
2024-05-04 18:40:37,989:INFO:Importing untrained model
2024-05-04 18:40:37,994:INFO:Linear Regression Imported successfully
2024-05-04 18:40:38,007:INFO:Starting cross validation
2024-05-04 18:40:38,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:41,281:INFO:Calculating mean and std
2024-05-04 18:40:41,282:INFO:Creating metrics dataframe
2024-05-04 18:40:41,284:INFO:Uploading results into container
2024-05-04 18:40:41,285:INFO:Uploading model into container now
2024-05-04 18:40:41,286:INFO:_master_model_container: 1
2024-05-04 18:40:41,286:INFO:_display_container: 2
2024-05-04 18:40:41,286:INFO:LinearRegression(n_jobs=-1)
2024-05-04 18:40:41,286:INFO:create_model() successfully completed......................................
2024-05-04 18:40:41,480:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:41,480:INFO:Creating metrics dataframe
2024-05-04 18:40:41,483:INFO:Initializing Lasso Regression
2024-05-04 18:40:41,483:INFO:Total runtime is 0.05878031651178996 minutes
2024-05-04 18:40:41,484:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:41,484:INFO:Initializing create_model()
2024-05-04 18:40:41,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:41,484:INFO:Checking exceptions
2024-05-04 18:40:41,484:INFO:Importing libraries
2024-05-04 18:40:41,484:INFO:Copying training dataset
2024-05-04 18:40:41,493:INFO:Defining folds
2024-05-04 18:40:41,493:INFO:Declaring metric variables
2024-05-04 18:40:41,495:INFO:Importing untrained model
2024-05-04 18:40:41,496:INFO:Lasso Regression Imported successfully
2024-05-04 18:40:41,499:INFO:Starting cross validation
2024-05-04 18:40:41,500:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:41,588:INFO:Calculating mean and std
2024-05-04 18:40:41,588:INFO:Creating metrics dataframe
2024-05-04 18:40:41,589:INFO:Uploading results into container
2024-05-04 18:40:41,589:INFO:Uploading model into container now
2024-05-04 18:40:41,589:INFO:_master_model_container: 2
2024-05-04 18:40:41,589:INFO:_display_container: 2
2024-05-04 18:40:41,589:INFO:Lasso(random_state=123)
2024-05-04 18:40:41,589:INFO:create_model() successfully completed......................................
2024-05-04 18:40:41,697:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:41,697:INFO:Creating metrics dataframe
2024-05-04 18:40:41,700:INFO:Initializing Ridge Regression
2024-05-04 18:40:41,700:INFO:Total runtime is 0.06240354776382446 minutes
2024-05-04 18:40:41,701:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:41,702:INFO:Initializing create_model()
2024-05-04 18:40:41,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:41,702:INFO:Checking exceptions
2024-05-04 18:40:41,702:INFO:Importing libraries
2024-05-04 18:40:41,702:INFO:Copying training dataset
2024-05-04 18:40:41,709:INFO:Defining folds
2024-05-04 18:40:41,709:INFO:Declaring metric variables
2024-05-04 18:40:41,711:INFO:Importing untrained model
2024-05-04 18:40:41,712:INFO:Ridge Regression Imported successfully
2024-05-04 18:40:41,715:INFO:Starting cross validation
2024-05-04 18:40:41,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:41,810:INFO:Calculating mean and std
2024-05-04 18:40:41,810:INFO:Creating metrics dataframe
2024-05-04 18:40:41,811:INFO:Uploading results into container
2024-05-04 18:40:41,811:INFO:Uploading model into container now
2024-05-04 18:40:41,812:INFO:_master_model_container: 3
2024-05-04 18:40:41,812:INFO:_display_container: 2
2024-05-04 18:40:41,812:INFO:Ridge(random_state=123)
2024-05-04 18:40:41,812:INFO:create_model() successfully completed......................................
2024-05-04 18:40:41,916:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:41,916:INFO:Creating metrics dataframe
2024-05-04 18:40:41,920:INFO:Initializing Elastic Net
2024-05-04 18:40:41,920:INFO:Total runtime is 0.0660640796025594 minutes
2024-05-04 18:40:41,922:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:41,922:INFO:Initializing create_model()
2024-05-04 18:40:41,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:41,922:INFO:Checking exceptions
2024-05-04 18:40:41,922:INFO:Importing libraries
2024-05-04 18:40:41,922:INFO:Copying training dataset
2024-05-04 18:40:41,929:INFO:Defining folds
2024-05-04 18:40:41,929:INFO:Declaring metric variables
2024-05-04 18:40:41,931:INFO:Importing untrained model
2024-05-04 18:40:41,932:INFO:Elastic Net Imported successfully
2024-05-04 18:40:41,935:INFO:Starting cross validation
2024-05-04 18:40:41,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:42,024:INFO:Calculating mean and std
2024-05-04 18:40:42,025:INFO:Creating metrics dataframe
2024-05-04 18:40:42,025:INFO:Uploading results into container
2024-05-04 18:40:42,026:INFO:Uploading model into container now
2024-05-04 18:40:42,026:INFO:_master_model_container: 4
2024-05-04 18:40:42,026:INFO:_display_container: 2
2024-05-04 18:40:42,026:INFO:ElasticNet(random_state=123)
2024-05-04 18:40:42,026:INFO:create_model() successfully completed......................................
2024-05-04 18:40:42,130:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:42,130:INFO:Creating metrics dataframe
2024-05-04 18:40:42,133:INFO:Initializing Least Angle Regression
2024-05-04 18:40:42,133:INFO:Total runtime is 0.06962566375732421 minutes
2024-05-04 18:40:42,135:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:42,135:INFO:Initializing create_model()
2024-05-04 18:40:42,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:42,135:INFO:Checking exceptions
2024-05-04 18:40:42,135:INFO:Importing libraries
2024-05-04 18:40:42,135:INFO:Copying training dataset
2024-05-04 18:40:42,142:INFO:Defining folds
2024-05-04 18:40:42,143:INFO:Declaring metric variables
2024-05-04 18:40:42,144:INFO:Importing untrained model
2024-05-04 18:40:42,145:INFO:Least Angle Regression Imported successfully
2024-05-04 18:40:42,148:INFO:Starting cross validation
2024-05-04 18:40:42,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:42,246:INFO:Calculating mean and std
2024-05-04 18:40:42,246:INFO:Creating metrics dataframe
2024-05-04 18:40:42,247:INFO:Uploading results into container
2024-05-04 18:40:42,247:INFO:Uploading model into container now
2024-05-04 18:40:42,248:INFO:_master_model_container: 5
2024-05-04 18:40:42,248:INFO:_display_container: 2
2024-05-04 18:40:42,248:INFO:Lars(random_state=123)
2024-05-04 18:40:42,248:INFO:create_model() successfully completed......................................
2024-05-04 18:40:42,358:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:42,358:INFO:Creating metrics dataframe
2024-05-04 18:40:42,361:INFO:Initializing Lasso Least Angle Regression
2024-05-04 18:40:42,361:INFO:Total runtime is 0.07341506481170654 minutes
2024-05-04 18:40:42,362:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:42,362:INFO:Initializing create_model()
2024-05-04 18:40:42,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:42,362:INFO:Checking exceptions
2024-05-04 18:40:42,362:INFO:Importing libraries
2024-05-04 18:40:42,362:INFO:Copying training dataset
2024-05-04 18:40:42,369:INFO:Defining folds
2024-05-04 18:40:42,369:INFO:Declaring metric variables
2024-05-04 18:40:42,370:INFO:Importing untrained model
2024-05-04 18:40:42,372:INFO:Lasso Least Angle Regression Imported successfully
2024-05-04 18:40:42,375:INFO:Starting cross validation
2024-05-04 18:40:42,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:42,465:INFO:Calculating mean and std
2024-05-04 18:40:42,465:INFO:Creating metrics dataframe
2024-05-04 18:40:42,466:INFO:Uploading results into container
2024-05-04 18:40:42,466:INFO:Uploading model into container now
2024-05-04 18:40:42,466:INFO:_master_model_container: 6
2024-05-04 18:40:42,467:INFO:_display_container: 2
2024-05-04 18:40:42,467:INFO:LassoLars(random_state=123)
2024-05-04 18:40:42,467:INFO:create_model() successfully completed......................................
2024-05-04 18:40:42,571:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:42,571:INFO:Creating metrics dataframe
2024-05-04 18:40:42,574:INFO:Initializing Orthogonal Matching Pursuit
2024-05-04 18:40:42,575:INFO:Total runtime is 0.07697885036468505 minutes
2024-05-04 18:40:42,576:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:42,576:INFO:Initializing create_model()
2024-05-04 18:40:42,576:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:42,576:INFO:Checking exceptions
2024-05-04 18:40:42,576:INFO:Importing libraries
2024-05-04 18:40:42,576:INFO:Copying training dataset
2024-05-04 18:40:42,583:INFO:Defining folds
2024-05-04 18:40:42,583:INFO:Declaring metric variables
2024-05-04 18:40:42,584:INFO:Importing untrained model
2024-05-04 18:40:42,586:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-04 18:40:42,590:INFO:Starting cross validation
2024-05-04 18:40:42,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:42,681:INFO:Calculating mean and std
2024-05-04 18:40:42,681:INFO:Creating metrics dataframe
2024-05-04 18:40:42,682:INFO:Uploading results into container
2024-05-04 18:40:42,682:INFO:Uploading model into container now
2024-05-04 18:40:42,682:INFO:_master_model_container: 7
2024-05-04 18:40:42,682:INFO:_display_container: 2
2024-05-04 18:40:42,682:INFO:OrthogonalMatchingPursuit()
2024-05-04 18:40:42,682:INFO:create_model() successfully completed......................................
2024-05-04 18:40:42,786:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:42,786:INFO:Creating metrics dataframe
2024-05-04 18:40:42,789:INFO:Initializing Bayesian Ridge
2024-05-04 18:40:42,790:INFO:Total runtime is 0.08056163390477497 minutes
2024-05-04 18:40:42,791:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:42,791:INFO:Initializing create_model()
2024-05-04 18:40:42,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:42,791:INFO:Checking exceptions
2024-05-04 18:40:42,791:INFO:Importing libraries
2024-05-04 18:40:42,791:INFO:Copying training dataset
2024-05-04 18:40:42,798:INFO:Defining folds
2024-05-04 18:40:42,798:INFO:Declaring metric variables
2024-05-04 18:40:42,799:INFO:Importing untrained model
2024-05-04 18:40:42,800:INFO:Bayesian Ridge Imported successfully
2024-05-04 18:40:42,805:INFO:Starting cross validation
2024-05-04 18:40:42,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:43,029:INFO:Calculating mean and std
2024-05-04 18:40:43,029:INFO:Creating metrics dataframe
2024-05-04 18:40:43,030:INFO:Uploading results into container
2024-05-04 18:40:43,030:INFO:Uploading model into container now
2024-05-04 18:40:43,031:INFO:_master_model_container: 8
2024-05-04 18:40:43,031:INFO:_display_container: 2
2024-05-04 18:40:43,031:INFO:BayesianRidge()
2024-05-04 18:40:43,031:INFO:create_model() successfully completed......................................
2024-05-04 18:40:43,135:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:43,135:INFO:Creating metrics dataframe
2024-05-04 18:40:43,139:INFO:Initializing Passive Aggressive Regressor
2024-05-04 18:40:43,139:INFO:Total runtime is 0.08638817866643268 minutes
2024-05-04 18:40:43,141:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:43,141:INFO:Initializing create_model()
2024-05-04 18:40:43,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:43,141:INFO:Checking exceptions
2024-05-04 18:40:43,141:INFO:Importing libraries
2024-05-04 18:40:43,141:INFO:Copying training dataset
2024-05-04 18:40:43,148:INFO:Defining folds
2024-05-04 18:40:43,148:INFO:Declaring metric variables
2024-05-04 18:40:43,149:INFO:Importing untrained model
2024-05-04 18:40:43,151:INFO:Passive Aggressive Regressor Imported successfully
2024-05-04 18:40:43,153:INFO:Starting cross validation
2024-05-04 18:40:43,154:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:43,259:INFO:Calculating mean and std
2024-05-04 18:40:43,260:INFO:Creating metrics dataframe
2024-05-04 18:40:43,261:INFO:Uploading results into container
2024-05-04 18:40:43,261:INFO:Uploading model into container now
2024-05-04 18:40:43,261:INFO:_master_model_container: 9
2024-05-04 18:40:43,261:INFO:_display_container: 2
2024-05-04 18:40:43,261:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-04 18:40:43,261:INFO:create_model() successfully completed......................................
2024-05-04 18:40:43,367:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:43,367:INFO:Creating metrics dataframe
2024-05-04 18:40:43,371:INFO:Initializing Huber Regressor
2024-05-04 18:40:43,371:INFO:Total runtime is 0.09025701284408567 minutes
2024-05-04 18:40:43,373:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:43,373:INFO:Initializing create_model()
2024-05-04 18:40:43,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:43,373:INFO:Checking exceptions
2024-05-04 18:40:43,373:INFO:Importing libraries
2024-05-04 18:40:43,373:INFO:Copying training dataset
2024-05-04 18:40:43,379:INFO:Defining folds
2024-05-04 18:40:43,380:INFO:Declaring metric variables
2024-05-04 18:40:43,381:INFO:Importing untrained model
2024-05-04 18:40:43,382:INFO:Huber Regressor Imported successfully
2024-05-04 18:40:43,385:INFO:Starting cross validation
2024-05-04 18:40:43,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:43,520:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:40:43,529:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:40:43,541:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:40:43,541:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:40:43,564:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:40:43,595:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:40:43,623:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:40:43,628:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:40:43,633:INFO:Calculating mean and std
2024-05-04 18:40:43,634:INFO:Creating metrics dataframe
2024-05-04 18:40:43,634:INFO:Uploading results into container
2024-05-04 18:40:43,634:INFO:Uploading model into container now
2024-05-04 18:40:43,635:INFO:_master_model_container: 10
2024-05-04 18:40:43,635:INFO:_display_container: 2
2024-05-04 18:40:43,635:INFO:HuberRegressor()
2024-05-04 18:40:43,635:INFO:create_model() successfully completed......................................
2024-05-04 18:40:43,742:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:43,743:INFO:Creating metrics dataframe
2024-05-04 18:40:43,747:INFO:Initializing K Neighbors Regressor
2024-05-04 18:40:43,747:INFO:Total runtime is 0.09652166366577146 minutes
2024-05-04 18:40:43,749:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:43,749:INFO:Initializing create_model()
2024-05-04 18:40:43,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:43,749:INFO:Checking exceptions
2024-05-04 18:40:43,749:INFO:Importing libraries
2024-05-04 18:40:43,749:INFO:Copying training dataset
2024-05-04 18:40:43,756:INFO:Defining folds
2024-05-04 18:40:43,756:INFO:Declaring metric variables
2024-05-04 18:40:43,758:INFO:Importing untrained model
2024-05-04 18:40:43,760:INFO:K Neighbors Regressor Imported successfully
2024-05-04 18:40:43,762:INFO:Starting cross validation
2024-05-04 18:40:43,762:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:43,917:INFO:Calculating mean and std
2024-05-04 18:40:43,918:INFO:Creating metrics dataframe
2024-05-04 18:40:43,919:INFO:Uploading results into container
2024-05-04 18:40:43,919:INFO:Uploading model into container now
2024-05-04 18:40:43,920:INFO:_master_model_container: 11
2024-05-04 18:40:43,920:INFO:_display_container: 2
2024-05-04 18:40:43,920:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-04 18:40:43,920:INFO:create_model() successfully completed......................................
2024-05-04 18:40:44,024:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:44,025:INFO:Creating metrics dataframe
2024-05-04 18:40:44,028:INFO:Initializing Decision Tree Regressor
2024-05-04 18:40:44,028:INFO:Total runtime is 0.10120706558227537 minutes
2024-05-04 18:40:44,029:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:44,030:INFO:Initializing create_model()
2024-05-04 18:40:44,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:44,030:INFO:Checking exceptions
2024-05-04 18:40:44,030:INFO:Importing libraries
2024-05-04 18:40:44,030:INFO:Copying training dataset
2024-05-04 18:40:44,036:INFO:Defining folds
2024-05-04 18:40:44,037:INFO:Declaring metric variables
2024-05-04 18:40:44,038:INFO:Importing untrained model
2024-05-04 18:40:44,040:INFO:Decision Tree Regressor Imported successfully
2024-05-04 18:40:44,043:INFO:Starting cross validation
2024-05-04 18:40:44,044:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:40:44,543:INFO:Calculating mean and std
2024-05-04 18:40:44,543:INFO:Creating metrics dataframe
2024-05-04 18:40:44,544:INFO:Uploading results into container
2024-05-04 18:40:44,545:INFO:Uploading model into container now
2024-05-04 18:40:44,545:INFO:_master_model_container: 12
2024-05-04 18:40:44,545:INFO:_display_container: 2
2024-05-04 18:40:44,545:INFO:DecisionTreeRegressor(random_state=123)
2024-05-04 18:40:44,545:INFO:create_model() successfully completed......................................
2024-05-04 18:40:44,654:INFO:SubProcess create_model() end ==================================
2024-05-04 18:40:44,654:INFO:Creating metrics dataframe
2024-05-04 18:40:44,658:INFO:Initializing Random Forest Regressor
2024-05-04 18:40:44,658:INFO:Total runtime is 0.11170981327692665 minutes
2024-05-04 18:40:44,660:INFO:SubProcess create_model() called ==================================
2024-05-04 18:40:44,660:INFO:Initializing create_model()
2024-05-04 18:40:44,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:40:44,660:INFO:Checking exceptions
2024-05-04 18:40:44,660:INFO:Importing libraries
2024-05-04 18:40:44,660:INFO:Copying training dataset
2024-05-04 18:40:44,667:INFO:Defining folds
2024-05-04 18:40:44,667:INFO:Declaring metric variables
2024-05-04 18:40:44,669:INFO:Importing untrained model
2024-05-04 18:40:44,671:INFO:Random Forest Regressor Imported successfully
2024-05-04 18:40:44,674:INFO:Starting cross validation
2024-05-04 18:40:44,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:02,743:INFO:Calculating mean and std
2024-05-04 18:41:02,744:INFO:Creating metrics dataframe
2024-05-04 18:41:02,746:INFO:Uploading results into container
2024-05-04 18:41:02,747:INFO:Uploading model into container now
2024-05-04 18:41:02,747:INFO:_master_model_container: 13
2024-05-04 18:41:02,747:INFO:_display_container: 2
2024-05-04 18:41:02,748:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-04 18:41:02,748:INFO:create_model() successfully completed......................................
2024-05-04 18:41:02,940:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:02,940:INFO:Creating metrics dataframe
2024-05-04 18:41:02,945:INFO:Initializing Extra Trees Regressor
2024-05-04 18:41:02,945:INFO:Total runtime is 0.4164845466613769 minutes
2024-05-04 18:41:02,946:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:02,947:INFO:Initializing create_model()
2024-05-04 18:41:02,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:02,947:INFO:Checking exceptions
2024-05-04 18:41:02,947:INFO:Importing libraries
2024-05-04 18:41:02,947:INFO:Copying training dataset
2024-05-04 18:41:02,955:INFO:Defining folds
2024-05-04 18:41:02,956:INFO:Declaring metric variables
2024-05-04 18:41:02,959:INFO:Importing untrained model
2024-05-04 18:41:02,961:INFO:Extra Trees Regressor Imported successfully
2024-05-04 18:41:02,964:INFO:Starting cross validation
2024-05-04 18:41:02,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:07,166:INFO:Calculating mean and std
2024-05-04 18:41:07,168:INFO:Creating metrics dataframe
2024-05-04 18:41:07,170:INFO:Uploading results into container
2024-05-04 18:41:07,171:INFO:Uploading model into container now
2024-05-04 18:41:07,171:INFO:_master_model_container: 14
2024-05-04 18:41:07,171:INFO:_display_container: 2
2024-05-04 18:41:07,171:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-04 18:41:07,172:INFO:create_model() successfully completed......................................
2024-05-04 18:41:07,319:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:07,319:INFO:Creating metrics dataframe
2024-05-04 18:41:07,323:INFO:Initializing AdaBoost Regressor
2024-05-04 18:41:07,323:INFO:Total runtime is 0.48946016232172646 minutes
2024-05-04 18:41:07,325:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:07,325:INFO:Initializing create_model()
2024-05-04 18:41:07,325:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:07,325:INFO:Checking exceptions
2024-05-04 18:41:07,326:INFO:Importing libraries
2024-05-04 18:41:07,326:INFO:Copying training dataset
2024-05-04 18:41:07,332:INFO:Defining folds
2024-05-04 18:41:07,333:INFO:Declaring metric variables
2024-05-04 18:41:07,334:INFO:Importing untrained model
2024-05-04 18:41:07,335:INFO:AdaBoost Regressor Imported successfully
2024-05-04 18:41:07,338:INFO:Starting cross validation
2024-05-04 18:41:07,338:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:09,293:INFO:Calculating mean and std
2024-05-04 18:41:09,294:INFO:Creating metrics dataframe
2024-05-04 18:41:09,295:INFO:Uploading results into container
2024-05-04 18:41:09,295:INFO:Uploading model into container now
2024-05-04 18:41:09,295:INFO:_master_model_container: 15
2024-05-04 18:41:09,295:INFO:_display_container: 2
2024-05-04 18:41:09,295:INFO:AdaBoostRegressor(random_state=123)
2024-05-04 18:41:09,295:INFO:create_model() successfully completed......................................
2024-05-04 18:41:09,399:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:09,399:INFO:Creating metrics dataframe
2024-05-04 18:41:09,404:INFO:Initializing Gradient Boosting Regressor
2024-05-04 18:41:09,404:INFO:Total runtime is 0.5241362293561299 minutes
2024-05-04 18:41:09,406:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:09,406:INFO:Initializing create_model()
2024-05-04 18:41:09,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:09,406:INFO:Checking exceptions
2024-05-04 18:41:09,406:INFO:Importing libraries
2024-05-04 18:41:09,406:INFO:Copying training dataset
2024-05-04 18:41:09,414:INFO:Defining folds
2024-05-04 18:41:09,414:INFO:Declaring metric variables
2024-05-04 18:41:09,416:INFO:Importing untrained model
2024-05-04 18:41:09,418:INFO:Gradient Boosting Regressor Imported successfully
2024-05-04 18:41:09,420:INFO:Starting cross validation
2024-05-04 18:41:09,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:18,218:INFO:Calculating mean and std
2024-05-04 18:41:18,220:INFO:Creating metrics dataframe
2024-05-04 18:41:18,221:INFO:Uploading results into container
2024-05-04 18:41:18,221:INFO:Uploading model into container now
2024-05-04 18:41:18,221:INFO:_master_model_container: 16
2024-05-04 18:41:18,221:INFO:_display_container: 2
2024-05-04 18:41:18,221:INFO:GradientBoostingRegressor(random_state=123)
2024-05-04 18:41:18,221:INFO:create_model() successfully completed......................................
2024-05-04 18:41:18,326:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:18,326:INFO:Creating metrics dataframe
2024-05-04 18:41:18,331:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 18:41:18,331:INFO:Total runtime is 0.6729135990142822 minutes
2024-05-04 18:41:18,332:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:18,332:INFO:Initializing create_model()
2024-05-04 18:41:18,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:18,332:INFO:Checking exceptions
2024-05-04 18:41:18,332:INFO:Importing libraries
2024-05-04 18:41:18,332:INFO:Copying training dataset
2024-05-04 18:41:18,340:INFO:Defining folds
2024-05-04 18:41:18,340:INFO:Declaring metric variables
2024-05-04 18:41:18,342:INFO:Importing untrained model
2024-05-04 18:41:18,344:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 18:41:18,347:INFO:Starting cross validation
2024-05-04 18:41:18,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:19,261:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 18:41:19,267:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 18:41:19,268:INFO:Initializing create_model()
2024-05-04 18:41:19,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:19,268:INFO:Checking exceptions
2024-05-04 18:41:19,268:INFO:Importing libraries
2024-05-04 18:41:19,268:INFO:Copying training dataset
2024-05-04 18:41:19,274:INFO:Defining folds
2024-05-04 18:41:19,274:INFO:Declaring metric variables
2024-05-04 18:41:19,276:INFO:Importing untrained model
2024-05-04 18:41:19,277:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 18:41:19,280:INFO:Starting cross validation
2024-05-04 18:41:19,281:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:23,028:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 18:41:23,030:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 18:41:23,030:INFO:Initializing Dummy Regressor
2024-05-04 18:41:23,030:INFO:Total runtime is 0.7512319127718607 minutes
2024-05-04 18:41:23,034:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:23,035:INFO:Initializing create_model()
2024-05-04 18:41:23,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x306754710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:23,035:INFO:Checking exceptions
2024-05-04 18:41:23,035:INFO:Importing libraries
2024-05-04 18:41:23,035:INFO:Copying training dataset
2024-05-04 18:41:23,044:INFO:Defining folds
2024-05-04 18:41:23,044:INFO:Declaring metric variables
2024-05-04 18:41:23,046:INFO:Importing untrained model
2024-05-04 18:41:23,047:INFO:Dummy Regressor Imported successfully
2024-05-04 18:41:23,050:INFO:Starting cross validation
2024-05-04 18:41:23,051:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:25,440:INFO:Calculating mean and std
2024-05-04 18:41:25,442:INFO:Creating metrics dataframe
2024-05-04 18:41:25,444:INFO:Uploading results into container
2024-05-04 18:41:25,445:INFO:Uploading model into container now
2024-05-04 18:41:25,445:INFO:_master_model_container: 17
2024-05-04 18:41:25,446:INFO:_display_container: 2
2024-05-04 18:41:25,446:INFO:DummyRegressor()
2024-05-04 18:41:25,446:INFO:create_model() successfully completed......................................
2024-05-04 18:41:25,638:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:25,638:INFO:Creating metrics dataframe
2024-05-04 18:41:25,644:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 18:41:25,648:INFO:Initializing create_model()
2024-05-04 18:41:25,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:25,648:INFO:Checking exceptions
2024-05-04 18:41:25,649:INFO:Importing libraries
2024-05-04 18:41:25,649:INFO:Copying training dataset
2024-05-04 18:41:25,656:INFO:Defining folds
2024-05-04 18:41:25,657:INFO:Declaring metric variables
2024-05-04 18:41:25,657:INFO:Importing untrained model
2024-05-04 18:41:25,657:INFO:Declaring custom model
2024-05-04 18:41:25,657:INFO:Bayesian Ridge Imported successfully
2024-05-04 18:41:25,657:INFO:Cross validation set to False
2024-05-04 18:41:25,657:INFO:Fitting Model
2024-05-04 18:41:25,688:INFO:BayesianRidge()
2024-05-04 18:41:25,688:INFO:create_model() successfully completed......................................
2024-05-04 18:41:25,896:INFO:_master_model_container: 17
2024-05-04 18:41:25,897:INFO:_display_container: 2
2024-05-04 18:41:25,897:INFO:BayesianRidge()
2024-05-04 18:41:25,897:INFO:compare_models() successfully completed......................................
2024-05-04 18:41:57,339:INFO:Initializing compare_models()
2024-05-04 18:41:57,340:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-04 18:41:57,341:INFO:Checking exceptions
2024-05-04 18:41:57,349:INFO:Preparing display monitor
2024-05-04 18:41:57,365:INFO:Initializing Linear Regression
2024-05-04 18:41:57,365:INFO:Total runtime is 2.133846282958984e-06 minutes
2024-05-04 18:41:57,367:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:57,367:INFO:Initializing create_model()
2024-05-04 18:41:57,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:57,367:INFO:Checking exceptions
2024-05-04 18:41:57,368:INFO:Importing libraries
2024-05-04 18:41:57,368:INFO:Copying training dataset
2024-05-04 18:41:57,387:INFO:Defining folds
2024-05-04 18:41:57,387:INFO:Declaring metric variables
2024-05-04 18:41:57,388:INFO:Importing untrained model
2024-05-04 18:41:57,391:INFO:Linear Regression Imported successfully
2024-05-04 18:41:57,396:INFO:Starting cross validation
2024-05-04 18:41:57,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:57,530:INFO:Calculating mean and std
2024-05-04 18:41:57,530:INFO:Creating metrics dataframe
2024-05-04 18:41:57,531:INFO:Uploading results into container
2024-05-04 18:41:57,531:INFO:Uploading model into container now
2024-05-04 18:41:57,532:INFO:_master_model_container: 1
2024-05-04 18:41:57,532:INFO:_display_container: 2
2024-05-04 18:41:57,532:INFO:LinearRegression(n_jobs=-1)
2024-05-04 18:41:57,532:INFO:create_model() successfully completed......................................
2024-05-04 18:41:57,713:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:57,713:INFO:Creating metrics dataframe
2024-05-04 18:41:57,716:INFO:Initializing Lasso Regression
2024-05-04 18:41:57,716:INFO:Total runtime is 0.00586326519648234 minutes
2024-05-04 18:41:57,718:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:57,718:INFO:Initializing create_model()
2024-05-04 18:41:57,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:57,721:INFO:Checking exceptions
2024-05-04 18:41:57,721:INFO:Importing libraries
2024-05-04 18:41:57,721:INFO:Copying training dataset
2024-05-04 18:41:57,728:INFO:Defining folds
2024-05-04 18:41:57,728:INFO:Declaring metric variables
2024-05-04 18:41:57,729:INFO:Importing untrained model
2024-05-04 18:41:57,731:INFO:Lasso Regression Imported successfully
2024-05-04 18:41:57,733:INFO:Starting cross validation
2024-05-04 18:41:57,734:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:57,805:INFO:Calculating mean and std
2024-05-04 18:41:57,806:INFO:Creating metrics dataframe
2024-05-04 18:41:57,806:INFO:Uploading results into container
2024-05-04 18:41:57,807:INFO:Uploading model into container now
2024-05-04 18:41:57,807:INFO:_master_model_container: 2
2024-05-04 18:41:57,807:INFO:_display_container: 2
2024-05-04 18:41:57,807:INFO:Lasso(random_state=123)
2024-05-04 18:41:57,807:INFO:create_model() successfully completed......................................
2024-05-04 18:41:57,912:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:57,912:INFO:Creating metrics dataframe
2024-05-04 18:41:57,916:INFO:Initializing Ridge Regression
2024-05-04 18:41:57,916:INFO:Total runtime is 0.009186935424804688 minutes
2024-05-04 18:41:57,917:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:57,917:INFO:Initializing create_model()
2024-05-04 18:41:57,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:57,918:INFO:Checking exceptions
2024-05-04 18:41:57,918:INFO:Importing libraries
2024-05-04 18:41:57,918:INFO:Copying training dataset
2024-05-04 18:41:57,924:INFO:Defining folds
2024-05-04 18:41:57,925:INFO:Declaring metric variables
2024-05-04 18:41:57,926:INFO:Importing untrained model
2024-05-04 18:41:57,928:INFO:Ridge Regression Imported successfully
2024-05-04 18:41:57,930:INFO:Starting cross validation
2024-05-04 18:41:57,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:58,006:INFO:Calculating mean and std
2024-05-04 18:41:58,007:INFO:Creating metrics dataframe
2024-05-04 18:41:58,008:INFO:Uploading results into container
2024-05-04 18:41:58,008:INFO:Uploading model into container now
2024-05-04 18:41:58,008:INFO:_master_model_container: 3
2024-05-04 18:41:58,008:INFO:_display_container: 2
2024-05-04 18:41:58,008:INFO:Ridge(random_state=123)
2024-05-04 18:41:58,008:INFO:create_model() successfully completed......................................
2024-05-04 18:41:58,139:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:58,139:INFO:Creating metrics dataframe
2024-05-04 18:41:58,143:INFO:Initializing Elastic Net
2024-05-04 18:41:58,143:INFO:Total runtime is 0.012968568007151286 minutes
2024-05-04 18:41:58,144:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:58,145:INFO:Initializing create_model()
2024-05-04 18:41:58,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:58,145:INFO:Checking exceptions
2024-05-04 18:41:58,145:INFO:Importing libraries
2024-05-04 18:41:58,145:INFO:Copying training dataset
2024-05-04 18:41:58,152:INFO:Defining folds
2024-05-04 18:41:58,152:INFO:Declaring metric variables
2024-05-04 18:41:58,153:INFO:Importing untrained model
2024-05-04 18:41:58,155:INFO:Elastic Net Imported successfully
2024-05-04 18:41:58,157:INFO:Starting cross validation
2024-05-04 18:41:58,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:58,234:INFO:Calculating mean and std
2024-05-04 18:41:58,235:INFO:Creating metrics dataframe
2024-05-04 18:41:58,236:INFO:Uploading results into container
2024-05-04 18:41:58,236:INFO:Uploading model into container now
2024-05-04 18:41:58,236:INFO:_master_model_container: 4
2024-05-04 18:41:58,236:INFO:_display_container: 2
2024-05-04 18:41:58,236:INFO:ElasticNet(random_state=123)
2024-05-04 18:41:58,236:INFO:create_model() successfully completed......................................
2024-05-04 18:41:58,357:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:58,357:INFO:Creating metrics dataframe
2024-05-04 18:41:58,361:INFO:Initializing Least Angle Regression
2024-05-04 18:41:58,362:INFO:Total runtime is 0.016615430514017742 minutes
2024-05-04 18:41:58,364:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:58,364:INFO:Initializing create_model()
2024-05-04 18:41:58,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:58,364:INFO:Checking exceptions
2024-05-04 18:41:58,364:INFO:Importing libraries
2024-05-04 18:41:58,364:INFO:Copying training dataset
2024-05-04 18:41:58,372:INFO:Defining folds
2024-05-04 18:41:58,372:INFO:Declaring metric variables
2024-05-04 18:41:58,373:INFO:Importing untrained model
2024-05-04 18:41:58,376:INFO:Least Angle Regression Imported successfully
2024-05-04 18:41:58,380:INFO:Starting cross validation
2024-05-04 18:41:58,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:58,488:INFO:Calculating mean and std
2024-05-04 18:41:58,489:INFO:Creating metrics dataframe
2024-05-04 18:41:58,490:INFO:Uploading results into container
2024-05-04 18:41:58,490:INFO:Uploading model into container now
2024-05-04 18:41:58,491:INFO:_master_model_container: 5
2024-05-04 18:41:58,491:INFO:_display_container: 2
2024-05-04 18:41:58,491:INFO:Lars(random_state=123)
2024-05-04 18:41:58,491:INFO:create_model() successfully completed......................................
2024-05-04 18:41:58,603:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:58,603:INFO:Creating metrics dataframe
2024-05-04 18:41:58,607:INFO:Initializing Lasso Least Angle Regression
2024-05-04 18:41:58,607:INFO:Total runtime is 0.020708930492401124 minutes
2024-05-04 18:41:58,609:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:58,609:INFO:Initializing create_model()
2024-05-04 18:41:58,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:58,609:INFO:Checking exceptions
2024-05-04 18:41:58,609:INFO:Importing libraries
2024-05-04 18:41:58,609:INFO:Copying training dataset
2024-05-04 18:41:58,617:INFO:Defining folds
2024-05-04 18:41:58,617:INFO:Declaring metric variables
2024-05-04 18:41:58,619:INFO:Importing untrained model
2024-05-04 18:41:58,621:INFO:Lasso Least Angle Regression Imported successfully
2024-05-04 18:41:58,624:INFO:Starting cross validation
2024-05-04 18:41:58,625:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:58,708:INFO:Calculating mean and std
2024-05-04 18:41:58,708:INFO:Creating metrics dataframe
2024-05-04 18:41:58,709:INFO:Uploading results into container
2024-05-04 18:41:58,709:INFO:Uploading model into container now
2024-05-04 18:41:58,710:INFO:_master_model_container: 6
2024-05-04 18:41:58,710:INFO:_display_container: 2
2024-05-04 18:41:58,710:INFO:LassoLars(random_state=123)
2024-05-04 18:41:58,710:INFO:create_model() successfully completed......................................
2024-05-04 18:41:58,818:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:58,818:INFO:Creating metrics dataframe
2024-05-04 18:41:58,822:INFO:Initializing Orthogonal Matching Pursuit
2024-05-04 18:41:58,822:INFO:Total runtime is 0.024291698137919107 minutes
2024-05-04 18:41:58,824:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:58,824:INFO:Initializing create_model()
2024-05-04 18:41:58,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:58,824:INFO:Checking exceptions
2024-05-04 18:41:58,824:INFO:Importing libraries
2024-05-04 18:41:58,824:INFO:Copying training dataset
2024-05-04 18:41:58,831:INFO:Defining folds
2024-05-04 18:41:58,831:INFO:Declaring metric variables
2024-05-04 18:41:58,833:INFO:Importing untrained model
2024-05-04 18:41:58,834:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-04 18:41:58,837:INFO:Starting cross validation
2024-05-04 18:41:58,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:58,965:INFO:Calculating mean and std
2024-05-04 18:41:58,965:INFO:Creating metrics dataframe
2024-05-04 18:41:58,967:INFO:Uploading results into container
2024-05-04 18:41:58,967:INFO:Uploading model into container now
2024-05-04 18:41:58,967:INFO:_master_model_container: 7
2024-05-04 18:41:58,967:INFO:_display_container: 2
2024-05-04 18:41:58,967:INFO:OrthogonalMatchingPursuit()
2024-05-04 18:41:58,967:INFO:create_model() successfully completed......................................
2024-05-04 18:41:59,079:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:59,079:INFO:Creating metrics dataframe
2024-05-04 18:41:59,083:INFO:Initializing Bayesian Ridge
2024-05-04 18:41:59,083:INFO:Total runtime is 0.028639002641042074 minutes
2024-05-04 18:41:59,084:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:59,085:INFO:Initializing create_model()
2024-05-04 18:41:59,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:59,085:INFO:Checking exceptions
2024-05-04 18:41:59,085:INFO:Importing libraries
2024-05-04 18:41:59,085:INFO:Copying training dataset
2024-05-04 18:41:59,091:INFO:Defining folds
2024-05-04 18:41:59,092:INFO:Declaring metric variables
2024-05-04 18:41:59,093:INFO:Importing untrained model
2024-05-04 18:41:59,095:INFO:Bayesian Ridge Imported successfully
2024-05-04 18:41:59,097:INFO:Starting cross validation
2024-05-04 18:41:59,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:59,222:INFO:Calculating mean and std
2024-05-04 18:41:59,222:INFO:Creating metrics dataframe
2024-05-04 18:41:59,223:INFO:Uploading results into container
2024-05-04 18:41:59,223:INFO:Uploading model into container now
2024-05-04 18:41:59,224:INFO:_master_model_container: 8
2024-05-04 18:41:59,224:INFO:_display_container: 2
2024-05-04 18:41:59,224:INFO:BayesianRidge()
2024-05-04 18:41:59,224:INFO:create_model() successfully completed......................................
2024-05-04 18:41:59,337:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:59,337:INFO:Creating metrics dataframe
2024-05-04 18:41:59,341:INFO:Initializing Passive Aggressive Regressor
2024-05-04 18:41:59,341:INFO:Total runtime is 0.03294543425242106 minutes
2024-05-04 18:41:59,343:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:59,343:INFO:Initializing create_model()
2024-05-04 18:41:59,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:59,343:INFO:Checking exceptions
2024-05-04 18:41:59,343:INFO:Importing libraries
2024-05-04 18:41:59,343:INFO:Copying training dataset
2024-05-04 18:41:59,351:INFO:Defining folds
2024-05-04 18:41:59,351:INFO:Declaring metric variables
2024-05-04 18:41:59,352:INFO:Importing untrained model
2024-05-04 18:41:59,353:INFO:Passive Aggressive Regressor Imported successfully
2024-05-04 18:41:59,356:INFO:Starting cross validation
2024-05-04 18:41:59,356:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:59,421:INFO:Calculating mean and std
2024-05-04 18:41:59,421:INFO:Creating metrics dataframe
2024-05-04 18:41:59,422:INFO:Uploading results into container
2024-05-04 18:41:59,422:INFO:Uploading model into container now
2024-05-04 18:41:59,422:INFO:_master_model_container: 9
2024-05-04 18:41:59,422:INFO:_display_container: 2
2024-05-04 18:41:59,423:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-04 18:41:59,423:INFO:create_model() successfully completed......................................
2024-05-04 18:41:59,531:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:59,531:INFO:Creating metrics dataframe
2024-05-04 18:41:59,535:INFO:Initializing Huber Regressor
2024-05-04 18:41:59,535:INFO:Total runtime is 0.03616936604181925 minutes
2024-05-04 18:41:59,536:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:59,536:INFO:Initializing create_model()
2024-05-04 18:41:59,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:59,536:INFO:Checking exceptions
2024-05-04 18:41:59,536:INFO:Importing libraries
2024-05-04 18:41:59,536:INFO:Copying training dataset
2024-05-04 18:41:59,544:INFO:Defining folds
2024-05-04 18:41:59,544:INFO:Declaring metric variables
2024-05-04 18:41:59,545:INFO:Importing untrained model
2024-05-04 18:41:59,547:INFO:Huber Regressor Imported successfully
2024-05-04 18:41:59,549:INFO:Starting cross validation
2024-05-04 18:41:59,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:41:59,672:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,702:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,704:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,709:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,715:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,725:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,741:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,752:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,788:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,790:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-04 18:41:59,805:INFO:Calculating mean and std
2024-05-04 18:41:59,805:INFO:Creating metrics dataframe
2024-05-04 18:41:59,806:INFO:Uploading results into container
2024-05-04 18:41:59,806:INFO:Uploading model into container now
2024-05-04 18:41:59,807:INFO:_master_model_container: 10
2024-05-04 18:41:59,807:INFO:_display_container: 2
2024-05-04 18:41:59,807:INFO:HuberRegressor()
2024-05-04 18:41:59,807:INFO:create_model() successfully completed......................................
2024-05-04 18:41:59,914:INFO:SubProcess create_model() end ==================================
2024-05-04 18:41:59,915:INFO:Creating metrics dataframe
2024-05-04 18:41:59,919:INFO:Initializing K Neighbors Regressor
2024-05-04 18:41:59,919:INFO:Total runtime is 0.042571496963500974 minutes
2024-05-04 18:41:59,921:INFO:SubProcess create_model() called ==================================
2024-05-04 18:41:59,921:INFO:Initializing create_model()
2024-05-04 18:41:59,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:41:59,921:INFO:Checking exceptions
2024-05-04 18:41:59,921:INFO:Importing libraries
2024-05-04 18:41:59,921:INFO:Copying training dataset
2024-05-04 18:41:59,928:INFO:Defining folds
2024-05-04 18:41:59,928:INFO:Declaring metric variables
2024-05-04 18:41:59,930:INFO:Importing untrained model
2024-05-04 18:41:59,931:INFO:K Neighbors Regressor Imported successfully
2024-05-04 18:41:59,934:INFO:Starting cross validation
2024-05-04 18:41:59,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:42:00,053:INFO:Calculating mean and std
2024-05-04 18:42:00,054:INFO:Creating metrics dataframe
2024-05-04 18:42:00,055:INFO:Uploading results into container
2024-05-04 18:42:00,055:INFO:Uploading model into container now
2024-05-04 18:42:00,055:INFO:_master_model_container: 11
2024-05-04 18:42:00,055:INFO:_display_container: 2
2024-05-04 18:42:00,055:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-04 18:42:00,055:INFO:create_model() successfully completed......................................
2024-05-04 18:42:00,162:INFO:SubProcess create_model() end ==================================
2024-05-04 18:42:00,162:INFO:Creating metrics dataframe
2024-05-04 18:42:00,166:INFO:Initializing Decision Tree Regressor
2024-05-04 18:42:00,167:INFO:Total runtime is 0.046698979536692296 minutes
2024-05-04 18:42:00,168:INFO:SubProcess create_model() called ==================================
2024-05-04 18:42:00,168:INFO:Initializing create_model()
2024-05-04 18:42:00,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:42:00,168:INFO:Checking exceptions
2024-05-04 18:42:00,169:INFO:Importing libraries
2024-05-04 18:42:00,169:INFO:Copying training dataset
2024-05-04 18:42:00,176:INFO:Defining folds
2024-05-04 18:42:00,176:INFO:Declaring metric variables
2024-05-04 18:42:00,178:INFO:Importing untrained model
2024-05-04 18:42:00,180:INFO:Decision Tree Regressor Imported successfully
2024-05-04 18:42:00,182:INFO:Starting cross validation
2024-05-04 18:42:00,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:42:00,724:INFO:Calculating mean and std
2024-05-04 18:42:00,725:INFO:Creating metrics dataframe
2024-05-04 18:42:00,727:INFO:Uploading results into container
2024-05-04 18:42:00,728:INFO:Uploading model into container now
2024-05-04 18:42:00,728:INFO:_master_model_container: 12
2024-05-04 18:42:00,728:INFO:_display_container: 2
2024-05-04 18:42:00,728:INFO:DecisionTreeRegressor(random_state=123)
2024-05-04 18:42:00,728:INFO:create_model() successfully completed......................................
2024-05-04 18:42:00,842:INFO:SubProcess create_model() end ==================================
2024-05-04 18:42:00,843:INFO:Creating metrics dataframe
2024-05-04 18:42:00,847:INFO:Initializing Random Forest Regressor
2024-05-04 18:42:00,847:INFO:Total runtime is 0.05804003477096557 minutes
2024-05-04 18:42:00,848:INFO:SubProcess create_model() called ==================================
2024-05-04 18:42:00,849:INFO:Initializing create_model()
2024-05-04 18:42:00,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:42:00,849:INFO:Checking exceptions
2024-05-04 18:42:00,849:INFO:Importing libraries
2024-05-04 18:42:00,849:INFO:Copying training dataset
2024-05-04 18:42:00,856:INFO:Defining folds
2024-05-04 18:42:00,857:INFO:Declaring metric variables
2024-05-04 18:42:00,858:INFO:Importing untrained model
2024-05-04 18:42:00,861:INFO:Random Forest Regressor Imported successfully
2024-05-04 18:42:00,864:INFO:Starting cross validation
2024-05-04 18:42:00,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:42:22,321:INFO:Calculating mean and std
2024-05-04 18:42:22,322:INFO:Creating metrics dataframe
2024-05-04 18:42:22,324:INFO:Uploading results into container
2024-05-04 18:42:22,324:INFO:Uploading model into container now
2024-05-04 18:42:22,325:INFO:_master_model_container: 13
2024-05-04 18:42:22,325:INFO:_display_container: 2
2024-05-04 18:42:22,326:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-04 18:42:22,326:INFO:create_model() successfully completed......................................
2024-05-04 18:42:22,512:INFO:SubProcess create_model() end ==================================
2024-05-04 18:42:22,513:INFO:Creating metrics dataframe
2024-05-04 18:42:22,517:INFO:Initializing Extra Trees Regressor
2024-05-04 18:42:22,517:INFO:Total runtime is 0.4192031184832255 minutes
2024-05-04 18:42:22,518:INFO:SubProcess create_model() called ==================================
2024-05-04 18:42:22,518:INFO:Initializing create_model()
2024-05-04 18:42:22,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:42:22,518:INFO:Checking exceptions
2024-05-04 18:42:22,518:INFO:Importing libraries
2024-05-04 18:42:22,518:INFO:Copying training dataset
2024-05-04 18:42:22,527:INFO:Defining folds
2024-05-04 18:42:22,527:INFO:Declaring metric variables
2024-05-04 18:42:22,529:INFO:Importing untrained model
2024-05-04 18:42:22,530:INFO:Extra Trees Regressor Imported successfully
2024-05-04 18:42:22,533:INFO:Starting cross validation
2024-05-04 18:42:22,534:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:42:27,293:INFO:Calculating mean and std
2024-05-04 18:42:27,293:INFO:Creating metrics dataframe
2024-05-04 18:42:27,294:INFO:Uploading results into container
2024-05-04 18:42:27,295:INFO:Uploading model into container now
2024-05-04 18:42:27,295:INFO:_master_model_container: 14
2024-05-04 18:42:27,295:INFO:_display_container: 2
2024-05-04 18:42:27,295:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-04 18:42:27,295:INFO:create_model() successfully completed......................................
2024-05-04 18:42:27,410:INFO:SubProcess create_model() end ==================================
2024-05-04 18:42:27,410:INFO:Creating metrics dataframe
2024-05-04 18:42:27,415:INFO:Initializing AdaBoost Regressor
2024-05-04 18:42:27,415:INFO:Total runtime is 0.5008355140686035 minutes
2024-05-04 18:42:27,416:INFO:SubProcess create_model() called ==================================
2024-05-04 18:42:27,416:INFO:Initializing create_model()
2024-05-04 18:42:27,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:42:27,416:INFO:Checking exceptions
2024-05-04 18:42:27,417:INFO:Importing libraries
2024-05-04 18:42:27,417:INFO:Copying training dataset
2024-05-04 18:42:27,424:INFO:Defining folds
2024-05-04 18:42:27,425:INFO:Declaring metric variables
2024-05-04 18:42:27,426:INFO:Importing untrained model
2024-05-04 18:42:27,428:INFO:AdaBoost Regressor Imported successfully
2024-05-04 18:42:27,431:INFO:Starting cross validation
2024-05-04 18:42:27,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:42:29,223:INFO:Calculating mean and std
2024-05-04 18:42:29,224:INFO:Creating metrics dataframe
2024-05-04 18:42:29,225:INFO:Uploading results into container
2024-05-04 18:42:29,226:INFO:Uploading model into container now
2024-05-04 18:42:29,226:INFO:_master_model_container: 15
2024-05-04 18:42:29,226:INFO:_display_container: 2
2024-05-04 18:42:29,226:INFO:AdaBoostRegressor(random_state=123)
2024-05-04 18:42:29,226:INFO:create_model() successfully completed......................................
2024-05-04 18:42:29,363:INFO:SubProcess create_model() end ==================================
2024-05-04 18:42:29,364:INFO:Creating metrics dataframe
2024-05-04 18:42:29,369:INFO:Initializing Gradient Boosting Regressor
2024-05-04 18:42:29,369:INFO:Total runtime is 0.5334080179532369 minutes
2024-05-04 18:42:29,371:INFO:SubProcess create_model() called ==================================
2024-05-04 18:42:29,371:INFO:Initializing create_model()
2024-05-04 18:42:29,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:42:29,371:INFO:Checking exceptions
2024-05-04 18:42:29,371:INFO:Importing libraries
2024-05-04 18:42:29,371:INFO:Copying training dataset
2024-05-04 18:42:29,379:INFO:Defining folds
2024-05-04 18:42:29,379:INFO:Declaring metric variables
2024-05-04 18:42:29,381:INFO:Importing untrained model
2024-05-04 18:42:29,383:INFO:Gradient Boosting Regressor Imported successfully
2024-05-04 18:42:29,386:INFO:Starting cross validation
2024-05-04 18:42:29,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:42:40,056:INFO:Calculating mean and std
2024-05-04 18:42:40,059:INFO:Creating metrics dataframe
2024-05-04 18:42:40,061:INFO:Uploading results into container
2024-05-04 18:42:40,062:INFO:Uploading model into container now
2024-05-04 18:42:40,063:INFO:_master_model_container: 16
2024-05-04 18:42:40,063:INFO:_display_container: 2
2024-05-04 18:42:40,063:INFO:GradientBoostingRegressor(random_state=123)
2024-05-04 18:42:40,063:INFO:create_model() successfully completed......................................
2024-05-04 18:42:40,261:INFO:SubProcess create_model() end ==================================
2024-05-04 18:42:40,261:INFO:Creating metrics dataframe
2024-05-04 18:42:40,266:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 18:42:40,266:INFO:Total runtime is 0.7150189518928528 minutes
2024-05-04 18:42:40,267:INFO:SubProcess create_model() called ==================================
2024-05-04 18:42:40,267:INFO:Initializing create_model()
2024-05-04 18:42:40,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:42:40,267:INFO:Checking exceptions
2024-05-04 18:42:40,267:INFO:Importing libraries
2024-05-04 18:42:40,267:INFO:Copying training dataset
2024-05-04 18:42:40,276:INFO:Defining folds
2024-05-04 18:42:40,276:INFO:Declaring metric variables
2024-05-04 18:42:40,278:INFO:Importing untrained model
2024-05-04 18:42:40,280:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 18:42:40,283:INFO:Starting cross validation
2024-05-04 18:42:40,283:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:42:41,182:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 18:42:41,184:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 18:42:41,184:INFO:Initializing create_model()
2024-05-04 18:42:41,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:42:41,184:INFO:Checking exceptions
2024-05-04 18:42:41,184:INFO:Importing libraries
2024-05-04 18:42:41,184:INFO:Copying training dataset
2024-05-04 18:42:41,191:INFO:Defining folds
2024-05-04 18:42:41,191:INFO:Declaring metric variables
2024-05-04 18:42:41,193:INFO:Importing untrained model
2024-05-04 18:42:41,195:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 18:42:41,198:INFO:Starting cross validation
2024-05-04 18:42:41,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:42:45,147:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 18:42:45,149:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 18:42:45,149:INFO:Initializing Dummy Regressor
2024-05-04 18:42:45,150:INFO:Total runtime is 0.7964152018229167 minutes
2024-05-04 18:42:45,154:INFO:SubProcess create_model() called ==================================
2024-05-04 18:42:45,155:INFO:Initializing create_model()
2024-05-04 18:42:45,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3074d1cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:42:45,155:INFO:Checking exceptions
2024-05-04 18:42:45,155:INFO:Importing libraries
2024-05-04 18:42:45,155:INFO:Copying training dataset
2024-05-04 18:42:45,164:INFO:Defining folds
2024-05-04 18:42:45,164:INFO:Declaring metric variables
2024-05-04 18:42:45,166:INFO:Importing untrained model
2024-05-04 18:42:45,167:INFO:Dummy Regressor Imported successfully
2024-05-04 18:42:45,170:INFO:Starting cross validation
2024-05-04 18:42:45,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:42:48,057:INFO:Calculating mean and std
2024-05-04 18:42:48,058:INFO:Creating metrics dataframe
2024-05-04 18:42:48,060:INFO:Uploading results into container
2024-05-04 18:42:48,060:INFO:Uploading model into container now
2024-05-04 18:42:48,061:INFO:_master_model_container: 17
2024-05-04 18:42:48,061:INFO:_display_container: 2
2024-05-04 18:42:48,062:INFO:DummyRegressor()
2024-05-04 18:42:48,062:INFO:create_model() successfully completed......................................
2024-05-04 18:42:48,255:INFO:SubProcess create_model() end ==================================
2024-05-04 18:42:48,255:INFO:Creating metrics dataframe
2024-05-04 18:42:48,261:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 18:42:48,265:INFO:Initializing create_model()
2024-05-04 18:42:48,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x175c4b410>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:42:48,265:INFO:Checking exceptions
2024-05-04 18:42:48,265:INFO:Importing libraries
2024-05-04 18:42:48,266:INFO:Copying training dataset
2024-05-04 18:42:48,274:INFO:Defining folds
2024-05-04 18:42:48,274:INFO:Declaring metric variables
2024-05-04 18:42:48,274:INFO:Importing untrained model
2024-05-04 18:42:48,274:INFO:Declaring custom model
2024-05-04 18:42:48,274:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-04 18:42:48,274:INFO:Cross validation set to False
2024-05-04 18:42:48,274:INFO:Fitting Model
2024-05-04 18:42:48,282:INFO:OrthogonalMatchingPursuit()
2024-05-04 18:42:48,282:INFO:create_model() successfully completed......................................
2024-05-04 18:42:48,414:INFO:_master_model_container: 17
2024-05-04 18:42:48,414:INFO:_display_container: 2
2024-05-04 18:42:48,415:INFO:OrthogonalMatchingPursuit()
2024-05-04 18:42:48,415:INFO:compare_models() successfully completed......................................
2024-05-04 18:42:56,069:INFO:Initializing plot_model()
2024-05-04 18:42:56,070:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=BayesianRidge(), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 18:42:56,070:INFO:Checking exceptions
2024-05-04 18:42:56,079:INFO:Preloading libraries
2024-05-04 18:42:56,079:INFO:Copying training dataset
2024-05-04 18:42:56,079:INFO:Plot type: residuals
2024-05-04 18:42:56,204:INFO:Fitting Model
2024-05-04 18:42:56,208:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2024-05-04 18:42:56,223:INFO:Scoring test/hold-out set
2024-05-04 18:42:56,440:INFO:Visual Rendered Successfully
2024-05-04 18:42:56,574:INFO:plot_model() successfully completed......................................
2024-05-04 18:43:00,771:INFO:Initializing plot_model()
2024-05-04 18:43:00,772:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x301855350>, estimator=BayesianRidge(), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-04 18:43:00,772:INFO:Checking exceptions
2024-05-04 18:43:00,777:INFO:Preloading libraries
2024-05-04 18:43:00,777:INFO:Copying training dataset
2024-05-04 18:43:00,777:INFO:Plot type: error
2024-05-04 18:43:00,849:INFO:Fitting Model
2024-05-04 18:43:00,850:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2024-05-04 18:43:00,850:INFO:Scoring test/hold-out set
2024-05-04 18:43:00,946:INFO:Visual Rendered Successfully
2024-05-04 18:43:01,056:INFO:plot_model() successfully completed......................................
2024-05-04 18:43:43,429:INFO:PyCaret RegressionExperiment
2024-05-04 18:43:43,430:INFO:Logging name: reg-default-name
2024-05-04 18:43:43,430:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 18:43:43,430:INFO:version 3.3.2
2024-05-04 18:43:43,430:INFO:Initializing setup()
2024-05-04 18:43:43,430:INFO:self.USI: 58f3
2024-05-04 18:43:43,430:INFO:self._variable_keys: {'fold_generator', 'memory', '_ml_usecase', 'transform_target_param', 'n_jobs_param', 'logging_param', 'X', 'exp_id', 'X_train', 'data', 'gpu_n_jobs_param', 'y', 'log_plots_param', 'X_test', 'idx', 'pipeline', 'y_train', 'html_param', 'exp_name_log', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'y_test', 'fold_groups_param', 'USI', 'seed', 'target_param'}
2024-05-04 18:43:43,430:INFO:Checking environment
2024-05-04 18:43:43,430:INFO:python_version: 3.11.8
2024-05-04 18:43:43,430:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 18:43:43,430:INFO:machine: arm64
2024-05-04 18:43:43,430:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:43:43,430:INFO:Memory: svmem(total=17179869184, available=3198320640, percent=81.4, used=5381931008, free=55001088, active=3154034688, inactive=3140157440, wired=2227896320)
2024-05-04 18:43:43,430:INFO:Physical Core: 8
2024-05-04 18:43:43,430:INFO:Logical Core: 8
2024-05-04 18:43:43,430:INFO:Checking libraries
2024-05-04 18:43:43,430:INFO:System:
2024-05-04 18:43:43,430:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 18:43:43,430:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 18:43:43,430:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:43:43,430:INFO:PyCaret required dependencies:
2024-05-04 18:43:43,431:INFO:                 pip: 24.0
2024-05-04 18:43:43,431:INFO:          setuptools: 69.2.0
2024-05-04 18:43:43,431:INFO:             pycaret: 3.3.2
2024-05-04 18:43:43,431:INFO:             IPython: 8.22.2
2024-05-04 18:43:43,431:INFO:          ipywidgets: 8.1.2
2024-05-04 18:43:43,431:INFO:                tqdm: 4.66.2
2024-05-04 18:43:43,431:INFO:               numpy: 1.26.4
2024-05-04 18:43:43,431:INFO:              pandas: 2.1.4
2024-05-04 18:43:43,431:INFO:              jinja2: 3.1.3
2024-05-04 18:43:43,431:INFO:               scipy: 1.11.4
2024-05-04 18:43:43,431:INFO:              joblib: 1.3.2
2024-05-04 18:43:43,431:INFO:             sklearn: 1.4.1.post1
2024-05-04 18:43:43,431:INFO:                pyod: 1.1.3
2024-05-04 18:43:43,431:INFO:            imblearn: 0.12.2
2024-05-04 18:43:43,431:INFO:   category_encoders: 2.6.3
2024-05-04 18:43:43,431:INFO:            lightgbm: 4.3.0
2024-05-04 18:43:43,431:INFO:               numba: 0.59.1
2024-05-04 18:43:43,431:INFO:            requests: 2.31.0
2024-05-04 18:43:43,431:INFO:          matplotlib: 3.7.5
2024-05-04 18:43:43,431:INFO:          scikitplot: 0.3.7
2024-05-04 18:43:43,431:INFO:         yellowbrick: 1.5
2024-05-04 18:43:43,431:INFO:              plotly: 5.19.0
2024-05-04 18:43:43,431:INFO:    plotly-resampler: Not installed
2024-05-04 18:43:43,431:INFO:             kaleido: 0.2.1
2024-05-04 18:43:43,431:INFO:           schemdraw: 0.15
2024-05-04 18:43:43,431:INFO:         statsmodels: 0.14.1
2024-05-04 18:43:43,431:INFO:              sktime: 0.26.0
2024-05-04 18:43:43,431:INFO:               tbats: 1.1.3
2024-05-04 18:43:43,431:INFO:            pmdarima: 2.0.4
2024-05-04 18:43:43,431:INFO:              psutil: 5.9.8
2024-05-04 18:43:43,431:INFO:          markupsafe: 2.1.5
2024-05-04 18:43:43,431:INFO:             pickle5: Not installed
2024-05-04 18:43:43,431:INFO:         cloudpickle: 3.0.0
2024-05-04 18:43:43,431:INFO:         deprecation: 2.1.0
2024-05-04 18:43:43,431:INFO:              xxhash: 3.4.1
2024-05-04 18:43:43,431:INFO:           wurlitzer: 3.0.3
2024-05-04 18:43:43,431:INFO:PyCaret optional dependencies:
2024-05-04 18:43:43,431:INFO:                shap: 0.44.1
2024-05-04 18:43:43,431:INFO:           interpret: 0.6.1
2024-05-04 18:43:43,431:INFO:                umap: 0.5.6
2024-05-04 18:43:43,431:INFO:     ydata_profiling: 4.7.0
2024-05-04 18:43:43,431:INFO:  explainerdashboard: 0.4.7
2024-05-04 18:43:43,431:INFO:             autoviz: Not installed
2024-05-04 18:43:43,431:INFO:           fairlearn: 0.7.0
2024-05-04 18:43:43,431:INFO:          deepchecks: Not installed
2024-05-04 18:43:43,431:INFO:             xgboost: Not installed
2024-05-04 18:43:43,431:INFO:            catboost: Not installed
2024-05-04 18:43:43,431:INFO:              kmodes: Not installed
2024-05-04 18:43:43,431:INFO:             mlxtend: 0.23.1
2024-05-04 18:43:43,431:INFO:       statsforecast: Not installed
2024-05-04 18:43:43,431:INFO:        tune_sklearn: Not installed
2024-05-04 18:43:43,431:INFO:                 ray: Not installed
2024-05-04 18:43:43,432:INFO:            hyperopt: 0.2.7
2024-05-04 18:43:43,432:INFO:              optuna: 3.6.1
2024-05-04 18:43:43,432:INFO:               skopt: 0.10.1
2024-05-04 18:43:43,432:INFO:              mlflow: 2.12.1
2024-05-04 18:43:43,432:INFO:              gradio: 4.29.0
2024-05-04 18:43:43,432:INFO:             fastapi: 0.111.0
2024-05-04 18:43:43,432:INFO:             uvicorn: 0.29.0
2024-05-04 18:43:43,432:INFO:              m2cgen: 0.10.0
2024-05-04 18:43:43,432:INFO:           evidently: 0.4.20
2024-05-04 18:43:43,432:INFO:               fugue: 0.8.7
2024-05-04 18:43:43,432:INFO:           streamlit: 1.33.0
2024-05-04 18:43:43,432:INFO:             prophet: Not installed
2024-05-04 18:43:43,432:INFO:None
2024-05-04 18:43:43,432:INFO:Set up data.
2024-05-04 18:43:43,436:INFO:Set up folding strategy.
2024-05-04 18:43:43,436:INFO:Set up train/test split.
2024-05-04 18:43:43,439:INFO:Set up index.
2024-05-04 18:43:43,439:INFO:Assigning column types.
2024-05-04 18:43:43,440:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 18:43:43,441:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,443:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,446:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,496:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,498:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,501:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,544:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 18:43:43,546:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,548:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,572:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,594:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,596:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,639:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 18:43:43,643:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,687:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,736:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 18:43:43,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,784:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,812:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,831:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,831:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 18:43:43,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,933:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:43,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:43,956:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 18:43:44,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:44,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:44,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:44,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:44,055:INFO:Preparing preprocessing pipeline...
2024-05-04 18:43:44,055:INFO:Set up simple imputation.
2024-05-04 18:43:44,056:INFO:Set up removing multicollinearity.
2024-05-04 18:43:44,068:INFO:Finished creating preprocessing pipeline.
2024-05-04 18:43:44,070:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group', 'I1'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-04 18:43:44,070:INFO:Creating final display dataframe.
2024-05-04 18:43:44,099:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Perform
2                   Target type        Regression
3           Original data shape         (8000, 3)
4        Transformed data shape         (8000, 3)
5   Transformed train set shape         (5600, 3)
6    Transformed test set shape         (2400, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              58f3
2024-05-04 18:43:44,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:44,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:44,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:44,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:44,206:INFO:setup() successfully completed in 0.79s...............
2024-05-04 18:43:59,904:INFO:PyCaret RegressionExperiment
2024-05-04 18:43:59,904:INFO:Logging name: reg-default-name
2024-05-04 18:43:59,904:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-04 18:43:59,904:INFO:version 3.3.2
2024-05-04 18:43:59,904:INFO:Initializing setup()
2024-05-04 18:43:59,904:INFO:self.USI: 60dd
2024-05-04 18:43:59,904:INFO:self._variable_keys: {'fold_generator', 'memory', '_ml_usecase', 'transform_target_param', 'n_jobs_param', 'logging_param', 'X', 'exp_id', 'X_train', 'data', 'gpu_n_jobs_param', 'y', 'log_plots_param', 'X_test', 'idx', 'pipeline', 'y_train', 'html_param', 'exp_name_log', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'y_test', 'fold_groups_param', 'USI', 'seed', 'target_param'}
2024-05-04 18:43:59,904:INFO:Checking environment
2024-05-04 18:43:59,904:INFO:python_version: 3.11.8
2024-05-04 18:43:59,904:INFO:python_build: ('main', 'Feb 16 2024 20:49:36')
2024-05-04 18:43:59,904:INFO:machine: arm64
2024-05-04 18:43:59,904:INFO:platform: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:43:59,904:INFO:Memory: svmem(total=17179869184, available=3396485120, percent=80.2, used=5335318528, free=110395392, active=3295199232, inactive=3282419712, wired=2040119296)
2024-05-04 18:43:59,904:INFO:Physical Core: 8
2024-05-04 18:43:59,904:INFO:Logical Core: 8
2024-05-04 18:43:59,904:INFO:Checking libraries
2024-05-04 18:43:59,904:INFO:System:
2024-05-04 18:43:59,904:INFO:    python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]
2024-05-04 18:43:59,904:INFO:executable: /Users/huytrq/miniconda3/envs/py11/bin/python
2024-05-04 18:43:59,904:INFO:   machine: macOS-14.4.1-arm64-arm-64bit
2024-05-04 18:43:59,905:INFO:PyCaret required dependencies:
2024-05-04 18:43:59,905:INFO:                 pip: 24.0
2024-05-04 18:43:59,905:INFO:          setuptools: 69.2.0
2024-05-04 18:43:59,905:INFO:             pycaret: 3.3.2
2024-05-04 18:43:59,905:INFO:             IPython: 8.22.2
2024-05-04 18:43:59,905:INFO:          ipywidgets: 8.1.2
2024-05-04 18:43:59,905:INFO:                tqdm: 4.66.2
2024-05-04 18:43:59,905:INFO:               numpy: 1.26.4
2024-05-04 18:43:59,905:INFO:              pandas: 2.1.4
2024-05-04 18:43:59,905:INFO:              jinja2: 3.1.3
2024-05-04 18:43:59,905:INFO:               scipy: 1.11.4
2024-05-04 18:43:59,905:INFO:              joblib: 1.3.2
2024-05-04 18:43:59,905:INFO:             sklearn: 1.4.1.post1
2024-05-04 18:43:59,905:INFO:                pyod: 1.1.3
2024-05-04 18:43:59,905:INFO:            imblearn: 0.12.2
2024-05-04 18:43:59,905:INFO:   category_encoders: 2.6.3
2024-05-04 18:43:59,905:INFO:            lightgbm: 4.3.0
2024-05-04 18:43:59,905:INFO:               numba: 0.59.1
2024-05-04 18:43:59,905:INFO:            requests: 2.31.0
2024-05-04 18:43:59,905:INFO:          matplotlib: 3.7.5
2024-05-04 18:43:59,905:INFO:          scikitplot: 0.3.7
2024-05-04 18:43:59,905:INFO:         yellowbrick: 1.5
2024-05-04 18:43:59,905:INFO:              plotly: 5.19.0
2024-05-04 18:43:59,905:INFO:    plotly-resampler: Not installed
2024-05-04 18:43:59,905:INFO:             kaleido: 0.2.1
2024-05-04 18:43:59,905:INFO:           schemdraw: 0.15
2024-05-04 18:43:59,905:INFO:         statsmodels: 0.14.1
2024-05-04 18:43:59,905:INFO:              sktime: 0.26.0
2024-05-04 18:43:59,905:INFO:               tbats: 1.1.3
2024-05-04 18:43:59,905:INFO:            pmdarima: 2.0.4
2024-05-04 18:43:59,905:INFO:              psutil: 5.9.8
2024-05-04 18:43:59,905:INFO:          markupsafe: 2.1.5
2024-05-04 18:43:59,905:INFO:             pickle5: Not installed
2024-05-04 18:43:59,905:INFO:         cloudpickle: 3.0.0
2024-05-04 18:43:59,905:INFO:         deprecation: 2.1.0
2024-05-04 18:43:59,905:INFO:              xxhash: 3.4.1
2024-05-04 18:43:59,905:INFO:           wurlitzer: 3.0.3
2024-05-04 18:43:59,905:INFO:PyCaret optional dependencies:
2024-05-04 18:43:59,905:INFO:                shap: 0.44.1
2024-05-04 18:43:59,905:INFO:           interpret: 0.6.1
2024-05-04 18:43:59,905:INFO:                umap: 0.5.6
2024-05-04 18:43:59,905:INFO:     ydata_profiling: 4.7.0
2024-05-04 18:43:59,905:INFO:  explainerdashboard: 0.4.7
2024-05-04 18:43:59,905:INFO:             autoviz: Not installed
2024-05-04 18:43:59,905:INFO:           fairlearn: 0.7.0
2024-05-04 18:43:59,905:INFO:          deepchecks: Not installed
2024-05-04 18:43:59,905:INFO:             xgboost: Not installed
2024-05-04 18:43:59,905:INFO:            catboost: Not installed
2024-05-04 18:43:59,905:INFO:              kmodes: Not installed
2024-05-04 18:43:59,905:INFO:             mlxtend: 0.23.1
2024-05-04 18:43:59,905:INFO:       statsforecast: Not installed
2024-05-04 18:43:59,905:INFO:        tune_sklearn: Not installed
2024-05-04 18:43:59,905:INFO:                 ray: Not installed
2024-05-04 18:43:59,905:INFO:            hyperopt: 0.2.7
2024-05-04 18:43:59,905:INFO:              optuna: 3.6.1
2024-05-04 18:43:59,905:INFO:               skopt: 0.10.1
2024-05-04 18:43:59,905:INFO:              mlflow: 2.12.1
2024-05-04 18:43:59,906:INFO:              gradio: 4.29.0
2024-05-04 18:43:59,906:INFO:             fastapi: 0.111.0
2024-05-04 18:43:59,906:INFO:             uvicorn: 0.29.0
2024-05-04 18:43:59,906:INFO:              m2cgen: 0.10.0
2024-05-04 18:43:59,906:INFO:           evidently: 0.4.20
2024-05-04 18:43:59,906:INFO:               fugue: 0.8.7
2024-05-04 18:43:59,906:INFO:           streamlit: 1.33.0
2024-05-04 18:43:59,906:INFO:             prophet: Not installed
2024-05-04 18:43:59,906:INFO:None
2024-05-04 18:43:59,906:INFO:Set up data.
2024-05-04 18:43:59,911:INFO:Set up folding strategy.
2024-05-04 18:43:59,911:INFO:Set up train/test split.
2024-05-04 18:43:59,914:INFO:Set up index.
2024-05-04 18:43:59,914:INFO:Assigning column types.
2024-05-04 18:43:59,916:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-04 18:43:59,916:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:43:59,918:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:43:59,920:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:43:59,947:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:43:59,966:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:43:59,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:59,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:43:59,967:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-04 18:43:59,969:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:43:59,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:43:59,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,015:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-04 18:44:00,017:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,019:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,065:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,067:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,112:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-04 18:44:00,116:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,159:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,164:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,188:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,207:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,208:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-04 18:44:00,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,304:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-04 18:44:00,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,390:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-04 18:44:00,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,409:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-04 18:44:00,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,507:INFO:Preparing preprocessing pipeline...
2024-05-04 18:44:00,507:INFO:Set up simple imputation.
2024-05-04 18:44:00,517:INFO:Finished creating preprocessing pipeline.
2024-05-04 18:44:00,518:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/rg/2t9xl9h93wjdygv93x4f6s4r0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Group', 'I1'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-05-04 18:44:00,518:INFO:Creating final display dataframe.
2024-05-04 18:44:00,539:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Perform
2                   Target type        Regression
3           Original data shape         (8000, 3)
4        Transformed data shape         (8000, 3)
5   Transformed train set shape         (5600, 3)
6    Transformed test set shape         (2400, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              60dd
2024-05-04 18:44:00,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-04 18:44:00,648:INFO:setup() successfully completed in 0.75s...............
2024-05-04 18:44:03,749:INFO:Initializing compare_models()
2024-05-04 18:44:03,750:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-05-04 18:44:03,750:INFO:Checking exceptions
2024-05-04 18:44:03,751:INFO:Preparing display monitor
2024-05-04 18:44:03,766:INFO:Initializing Linear Regression
2024-05-04 18:44:03,766:INFO:Total runtime is 3.4848848978678387e-06 minutes
2024-05-04 18:44:03,768:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:03,768:INFO:Initializing create_model()
2024-05-04 18:44:03,768:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:03,768:INFO:Checking exceptions
2024-05-04 18:44:03,769:INFO:Importing libraries
2024-05-04 18:44:03,769:INFO:Copying training dataset
2024-05-04 18:44:03,773:INFO:Defining folds
2024-05-04 18:44:03,773:INFO:Declaring metric variables
2024-05-04 18:44:03,775:INFO:Importing untrained model
2024-05-04 18:44:03,777:INFO:Linear Regression Imported successfully
2024-05-04 18:44:03,781:INFO:Starting cross validation
2024-05-04 18:44:03,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:03,923:INFO:Calculating mean and std
2024-05-04 18:44:03,923:INFO:Creating metrics dataframe
2024-05-04 18:44:03,927:INFO:Uploading results into container
2024-05-04 18:44:03,927:INFO:Uploading model into container now
2024-05-04 18:44:03,927:INFO:_master_model_container: 1
2024-05-04 18:44:03,927:INFO:_display_container: 2
2024-05-04 18:44:03,927:INFO:LinearRegression(n_jobs=-1)
2024-05-04 18:44:03,927:INFO:create_model() successfully completed......................................
2024-05-04 18:44:04,130:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:04,130:INFO:Creating metrics dataframe
2024-05-04 18:44:04,134:INFO:Initializing Lasso Regression
2024-05-04 18:44:04,134:INFO:Total runtime is 0.006133782863616943 minutes
2024-05-04 18:44:04,135:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:04,135:INFO:Initializing create_model()
2024-05-04 18:44:04,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:04,135:INFO:Checking exceptions
2024-05-04 18:44:04,136:INFO:Importing libraries
2024-05-04 18:44:04,136:INFO:Copying training dataset
2024-05-04 18:44:04,137:INFO:Defining folds
2024-05-04 18:44:04,137:INFO:Declaring metric variables
2024-05-04 18:44:04,139:INFO:Importing untrained model
2024-05-04 18:44:04,141:INFO:Lasso Regression Imported successfully
2024-05-04 18:44:04,144:INFO:Starting cross validation
2024-05-04 18:44:04,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:04,211:INFO:Calculating mean and std
2024-05-04 18:44:04,211:INFO:Creating metrics dataframe
2024-05-04 18:44:04,212:INFO:Uploading results into container
2024-05-04 18:44:04,213:INFO:Uploading model into container now
2024-05-04 18:44:04,213:INFO:_master_model_container: 2
2024-05-04 18:44:04,213:INFO:_display_container: 2
2024-05-04 18:44:04,213:INFO:Lasso(random_state=123)
2024-05-04 18:44:04,213:INFO:create_model() successfully completed......................................
2024-05-04 18:44:04,326:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:04,326:INFO:Creating metrics dataframe
2024-05-04 18:44:04,329:INFO:Initializing Ridge Regression
2024-05-04 18:44:04,329:INFO:Total runtime is 0.009393016497294107 minutes
2024-05-04 18:44:04,331:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:04,331:INFO:Initializing create_model()
2024-05-04 18:44:04,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:04,331:INFO:Checking exceptions
2024-05-04 18:44:04,331:INFO:Importing libraries
2024-05-04 18:44:04,331:INFO:Copying training dataset
2024-05-04 18:44:04,334:INFO:Defining folds
2024-05-04 18:44:04,334:INFO:Declaring metric variables
2024-05-04 18:44:04,335:INFO:Importing untrained model
2024-05-04 18:44:04,336:INFO:Ridge Regression Imported successfully
2024-05-04 18:44:04,339:INFO:Starting cross validation
2024-05-04 18:44:04,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:04,482:INFO:Calculating mean and std
2024-05-04 18:44:04,482:INFO:Creating metrics dataframe
2024-05-04 18:44:04,483:INFO:Uploading results into container
2024-05-04 18:44:04,483:INFO:Uploading model into container now
2024-05-04 18:44:04,483:INFO:_master_model_container: 3
2024-05-04 18:44:04,483:INFO:_display_container: 2
2024-05-04 18:44:04,483:INFO:Ridge(random_state=123)
2024-05-04 18:44:04,484:INFO:create_model() successfully completed......................................
2024-05-04 18:44:04,606:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:04,606:INFO:Creating metrics dataframe
2024-05-04 18:44:04,609:INFO:Initializing Elastic Net
2024-05-04 18:44:04,610:INFO:Total runtime is 0.014066251118977864 minutes
2024-05-04 18:44:04,613:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:04,613:INFO:Initializing create_model()
2024-05-04 18:44:04,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:04,613:INFO:Checking exceptions
2024-05-04 18:44:04,613:INFO:Importing libraries
2024-05-04 18:44:04,613:INFO:Copying training dataset
2024-05-04 18:44:04,614:INFO:Defining folds
2024-05-04 18:44:04,614:INFO:Declaring metric variables
2024-05-04 18:44:04,617:INFO:Importing untrained model
2024-05-04 18:44:04,619:INFO:Elastic Net Imported successfully
2024-05-04 18:44:04,623:INFO:Starting cross validation
2024-05-04 18:44:04,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:04,754:INFO:Calculating mean and std
2024-05-04 18:44:04,754:INFO:Creating metrics dataframe
2024-05-04 18:44:04,755:INFO:Uploading results into container
2024-05-04 18:44:04,755:INFO:Uploading model into container now
2024-05-04 18:44:04,756:INFO:_master_model_container: 4
2024-05-04 18:44:04,756:INFO:_display_container: 2
2024-05-04 18:44:04,756:INFO:ElasticNet(random_state=123)
2024-05-04 18:44:04,756:INFO:create_model() successfully completed......................................
2024-05-04 18:44:04,895:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:04,895:INFO:Creating metrics dataframe
2024-05-04 18:44:04,899:INFO:Initializing Least Angle Regression
2024-05-04 18:44:04,899:INFO:Total runtime is 0.01888449986775716 minutes
2024-05-04 18:44:04,900:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:04,900:INFO:Initializing create_model()
2024-05-04 18:44:04,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:04,901:INFO:Checking exceptions
2024-05-04 18:44:04,901:INFO:Importing libraries
2024-05-04 18:44:04,901:INFO:Copying training dataset
2024-05-04 18:44:04,903:INFO:Defining folds
2024-05-04 18:44:04,903:INFO:Declaring metric variables
2024-05-04 18:44:04,905:INFO:Importing untrained model
2024-05-04 18:44:04,907:INFO:Least Angle Regression Imported successfully
2024-05-04 18:44:04,912:INFO:Starting cross validation
2024-05-04 18:44:04,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:04,959:INFO:Calculating mean and std
2024-05-04 18:44:04,959:INFO:Creating metrics dataframe
2024-05-04 18:44:04,960:INFO:Uploading results into container
2024-05-04 18:44:04,960:INFO:Uploading model into container now
2024-05-04 18:44:04,960:INFO:_master_model_container: 5
2024-05-04 18:44:04,960:INFO:_display_container: 2
2024-05-04 18:44:04,961:INFO:Lars(random_state=123)
2024-05-04 18:44:04,961:INFO:create_model() successfully completed......................................
2024-05-04 18:44:05,069:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:05,069:INFO:Creating metrics dataframe
2024-05-04 18:44:05,073:INFO:Initializing Lasso Least Angle Regression
2024-05-04 18:44:05,073:INFO:Total runtime is 0.02178390026092529 minutes
2024-05-04 18:44:05,074:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:05,074:INFO:Initializing create_model()
2024-05-04 18:44:05,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:05,075:INFO:Checking exceptions
2024-05-04 18:44:05,075:INFO:Importing libraries
2024-05-04 18:44:05,076:INFO:Copying training dataset
2024-05-04 18:44:05,077:INFO:Defining folds
2024-05-04 18:44:05,078:INFO:Declaring metric variables
2024-05-04 18:44:05,079:INFO:Importing untrained model
2024-05-04 18:44:05,081:INFO:Lasso Least Angle Regression Imported successfully
2024-05-04 18:44:05,084:INFO:Starting cross validation
2024-05-04 18:44:05,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:05,128:INFO:Calculating mean and std
2024-05-04 18:44:05,128:INFO:Creating metrics dataframe
2024-05-04 18:44:05,129:INFO:Uploading results into container
2024-05-04 18:44:05,129:INFO:Uploading model into container now
2024-05-04 18:44:05,129:INFO:_master_model_container: 6
2024-05-04 18:44:05,129:INFO:_display_container: 2
2024-05-04 18:44:05,130:INFO:LassoLars(random_state=123)
2024-05-04 18:44:05,130:INFO:create_model() successfully completed......................................
2024-05-04 18:44:05,237:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:05,237:INFO:Creating metrics dataframe
2024-05-04 18:44:05,240:INFO:Initializing Orthogonal Matching Pursuit
2024-05-04 18:44:05,240:INFO:Total runtime is 0.02458161910374959 minutes
2024-05-04 18:44:05,242:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:05,242:INFO:Initializing create_model()
2024-05-04 18:44:05,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:05,242:INFO:Checking exceptions
2024-05-04 18:44:05,242:INFO:Importing libraries
2024-05-04 18:44:05,242:INFO:Copying training dataset
2024-05-04 18:44:05,245:INFO:Defining folds
2024-05-04 18:44:05,245:INFO:Declaring metric variables
2024-05-04 18:44:05,246:INFO:Importing untrained model
2024-05-04 18:44:05,248:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-04 18:44:05,254:INFO:Starting cross validation
2024-05-04 18:44:05,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:05,376:INFO:Calculating mean and std
2024-05-04 18:44:05,377:INFO:Creating metrics dataframe
2024-05-04 18:44:05,378:INFO:Uploading results into container
2024-05-04 18:44:05,379:INFO:Uploading model into container now
2024-05-04 18:44:05,379:INFO:_master_model_container: 7
2024-05-04 18:44:05,379:INFO:_display_container: 2
2024-05-04 18:44:05,379:INFO:OrthogonalMatchingPursuit()
2024-05-04 18:44:05,379:INFO:create_model() successfully completed......................................
2024-05-04 18:44:05,486:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:05,486:INFO:Creating metrics dataframe
2024-05-04 18:44:05,490:INFO:Initializing Bayesian Ridge
2024-05-04 18:44:05,490:INFO:Total runtime is 0.02874081532160441 minutes
2024-05-04 18:44:05,492:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:05,492:INFO:Initializing create_model()
2024-05-04 18:44:05,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:05,492:INFO:Checking exceptions
2024-05-04 18:44:05,492:INFO:Importing libraries
2024-05-04 18:44:05,492:INFO:Copying training dataset
2024-05-04 18:44:05,494:INFO:Defining folds
2024-05-04 18:44:05,494:INFO:Declaring metric variables
2024-05-04 18:44:05,495:INFO:Importing untrained model
2024-05-04 18:44:05,497:INFO:Bayesian Ridge Imported successfully
2024-05-04 18:44:05,499:INFO:Starting cross validation
2024-05-04 18:44:05,500:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:05,544:INFO:Calculating mean and std
2024-05-04 18:44:05,545:INFO:Creating metrics dataframe
2024-05-04 18:44:05,546:INFO:Uploading results into container
2024-05-04 18:44:05,546:INFO:Uploading model into container now
2024-05-04 18:44:05,546:INFO:_master_model_container: 8
2024-05-04 18:44:05,546:INFO:_display_container: 2
2024-05-04 18:44:05,547:INFO:BayesianRidge()
2024-05-04 18:44:05,547:INFO:create_model() successfully completed......................................
2024-05-04 18:44:05,654:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:05,654:INFO:Creating metrics dataframe
2024-05-04 18:44:05,657:INFO:Initializing Passive Aggressive Regressor
2024-05-04 18:44:05,658:INFO:Total runtime is 0.031532033284505205 minutes
2024-05-04 18:44:05,659:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:05,659:INFO:Initializing create_model()
2024-05-04 18:44:05,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:05,660:INFO:Checking exceptions
2024-05-04 18:44:05,660:INFO:Importing libraries
2024-05-04 18:44:05,660:INFO:Copying training dataset
2024-05-04 18:44:05,661:INFO:Defining folds
2024-05-04 18:44:05,661:INFO:Declaring metric variables
2024-05-04 18:44:05,663:INFO:Importing untrained model
2024-05-04 18:44:05,664:INFO:Passive Aggressive Regressor Imported successfully
2024-05-04 18:44:05,667:INFO:Starting cross validation
2024-05-04 18:44:05,668:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:05,721:INFO:Calculating mean and std
2024-05-04 18:44:05,721:INFO:Creating metrics dataframe
2024-05-04 18:44:05,722:INFO:Uploading results into container
2024-05-04 18:44:05,722:INFO:Uploading model into container now
2024-05-04 18:44:05,722:INFO:_master_model_container: 9
2024-05-04 18:44:05,722:INFO:_display_container: 2
2024-05-04 18:44:05,722:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-04 18:44:05,722:INFO:create_model() successfully completed......................................
2024-05-04 18:44:05,832:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:05,832:INFO:Creating metrics dataframe
2024-05-04 18:44:05,835:INFO:Initializing Huber Regressor
2024-05-04 18:44:05,835:INFO:Total runtime is 0.03449613650639852 minutes
2024-05-04 18:44:05,837:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:05,837:INFO:Initializing create_model()
2024-05-04 18:44:05,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:05,837:INFO:Checking exceptions
2024-05-04 18:44:05,837:INFO:Importing libraries
2024-05-04 18:44:05,837:INFO:Copying training dataset
2024-05-04 18:44:05,839:INFO:Defining folds
2024-05-04 18:44:05,839:INFO:Declaring metric variables
2024-05-04 18:44:05,841:INFO:Importing untrained model
2024-05-04 18:44:05,843:INFO:Huber Regressor Imported successfully
2024-05-04 18:44:05,846:INFO:Starting cross validation
2024-05-04 18:44:05,846:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:05,912:INFO:Calculating mean and std
2024-05-04 18:44:05,913:INFO:Creating metrics dataframe
2024-05-04 18:44:05,914:INFO:Uploading results into container
2024-05-04 18:44:05,914:INFO:Uploading model into container now
2024-05-04 18:44:05,914:INFO:_master_model_container: 10
2024-05-04 18:44:05,914:INFO:_display_container: 2
2024-05-04 18:44:05,914:INFO:HuberRegressor()
2024-05-04 18:44:05,914:INFO:create_model() successfully completed......................................
2024-05-04 18:44:06,021:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:06,021:INFO:Creating metrics dataframe
2024-05-04 18:44:06,025:INFO:Initializing K Neighbors Regressor
2024-05-04 18:44:06,026:INFO:Total runtime is 0.037666130065917965 minutes
2024-05-04 18:44:06,027:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:06,027:INFO:Initializing create_model()
2024-05-04 18:44:06,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:06,027:INFO:Checking exceptions
2024-05-04 18:44:06,027:INFO:Importing libraries
2024-05-04 18:44:06,027:INFO:Copying training dataset
2024-05-04 18:44:06,030:INFO:Defining folds
2024-05-04 18:44:06,030:INFO:Declaring metric variables
2024-05-04 18:44:06,031:INFO:Importing untrained model
2024-05-04 18:44:06,032:INFO:K Neighbors Regressor Imported successfully
2024-05-04 18:44:06,035:INFO:Starting cross validation
2024-05-04 18:44:06,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:06,136:INFO:Calculating mean and std
2024-05-04 18:44:06,137:INFO:Creating metrics dataframe
2024-05-04 18:44:06,138:INFO:Uploading results into container
2024-05-04 18:44:06,138:INFO:Uploading model into container now
2024-05-04 18:44:06,139:INFO:_master_model_container: 11
2024-05-04 18:44:06,139:INFO:_display_container: 2
2024-05-04 18:44:06,139:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-04 18:44:06,139:INFO:create_model() successfully completed......................................
2024-05-04 18:44:06,246:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:06,246:INFO:Creating metrics dataframe
2024-05-04 18:44:06,251:INFO:Initializing Decision Tree Regressor
2024-05-04 18:44:06,251:INFO:Total runtime is 0.041416251659393305 minutes
2024-05-04 18:44:06,252:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:06,252:INFO:Initializing create_model()
2024-05-04 18:44:06,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:06,252:INFO:Checking exceptions
2024-05-04 18:44:06,252:INFO:Importing libraries
2024-05-04 18:44:06,252:INFO:Copying training dataset
2024-05-04 18:44:06,254:INFO:Defining folds
2024-05-04 18:44:06,254:INFO:Declaring metric variables
2024-05-04 18:44:06,255:INFO:Importing untrained model
2024-05-04 18:44:06,257:INFO:Decision Tree Regressor Imported successfully
2024-05-04 18:44:06,260:INFO:Starting cross validation
2024-05-04 18:44:06,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:06,342:INFO:Calculating mean and std
2024-05-04 18:44:06,343:INFO:Creating metrics dataframe
2024-05-04 18:44:06,346:INFO:Uploading results into container
2024-05-04 18:44:06,346:INFO:Uploading model into container now
2024-05-04 18:44:06,347:INFO:_master_model_container: 12
2024-05-04 18:44:06,347:INFO:_display_container: 2
2024-05-04 18:44:06,347:INFO:DecisionTreeRegressor(random_state=123)
2024-05-04 18:44:06,347:INFO:create_model() successfully completed......................................
2024-05-04 18:44:06,471:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:06,471:INFO:Creating metrics dataframe
2024-05-04 18:44:06,476:INFO:Initializing Random Forest Regressor
2024-05-04 18:44:06,477:INFO:Total runtime is 0.04518243074417114 minutes
2024-05-04 18:44:06,478:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:06,478:INFO:Initializing create_model()
2024-05-04 18:44:06,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:06,479:INFO:Checking exceptions
2024-05-04 18:44:06,479:INFO:Importing libraries
2024-05-04 18:44:06,479:INFO:Copying training dataset
2024-05-04 18:44:06,481:INFO:Defining folds
2024-05-04 18:44:06,481:INFO:Declaring metric variables
2024-05-04 18:44:06,482:INFO:Importing untrained model
2024-05-04 18:44:06,484:INFO:Random Forest Regressor Imported successfully
2024-05-04 18:44:06,488:INFO:Starting cross validation
2024-05-04 18:44:06,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:07,950:INFO:Calculating mean and std
2024-05-04 18:44:07,951:INFO:Creating metrics dataframe
2024-05-04 18:44:07,952:INFO:Uploading results into container
2024-05-04 18:44:07,952:INFO:Uploading model into container now
2024-05-04 18:44:07,952:INFO:_master_model_container: 13
2024-05-04 18:44:07,952:INFO:_display_container: 2
2024-05-04 18:44:07,952:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-04 18:44:07,952:INFO:create_model() successfully completed......................................
2024-05-04 18:44:08,060:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:08,060:INFO:Creating metrics dataframe
2024-05-04 18:44:08,064:INFO:Initializing Extra Trees Regressor
2024-05-04 18:44:08,064:INFO:Total runtime is 0.07164366642634074 minutes
2024-05-04 18:44:08,066:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:08,066:INFO:Initializing create_model()
2024-05-04 18:44:08,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:08,066:INFO:Checking exceptions
2024-05-04 18:44:08,066:INFO:Importing libraries
2024-05-04 18:44:08,066:INFO:Copying training dataset
2024-05-04 18:44:08,068:INFO:Defining folds
2024-05-04 18:44:08,068:INFO:Declaring metric variables
2024-05-04 18:44:08,069:INFO:Importing untrained model
2024-05-04 18:44:08,071:INFO:Extra Trees Regressor Imported successfully
2024-05-04 18:44:08,075:INFO:Starting cross validation
2024-05-04 18:44:08,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:08,768:INFO:Calculating mean and std
2024-05-04 18:44:08,769:INFO:Creating metrics dataframe
2024-05-04 18:44:08,770:INFO:Uploading results into container
2024-05-04 18:44:08,770:INFO:Uploading model into container now
2024-05-04 18:44:08,771:INFO:_master_model_container: 14
2024-05-04 18:44:08,771:INFO:_display_container: 2
2024-05-04 18:44:08,771:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-04 18:44:08,771:INFO:create_model() successfully completed......................................
2024-05-04 18:44:08,944:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:08,944:INFO:Creating metrics dataframe
2024-05-04 18:44:08,949:INFO:Initializing AdaBoost Regressor
2024-05-04 18:44:08,949:INFO:Total runtime is 0.08638431231180826 minutes
2024-05-04 18:44:08,950:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:08,950:INFO:Initializing create_model()
2024-05-04 18:44:08,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:08,951:INFO:Checking exceptions
2024-05-04 18:44:08,951:INFO:Importing libraries
2024-05-04 18:44:08,951:INFO:Copying training dataset
2024-05-04 18:44:08,953:INFO:Defining folds
2024-05-04 18:44:08,953:INFO:Declaring metric variables
2024-05-04 18:44:08,954:INFO:Importing untrained model
2024-05-04 18:44:08,956:INFO:AdaBoost Regressor Imported successfully
2024-05-04 18:44:08,959:INFO:Starting cross validation
2024-05-04 18:44:08,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:09,130:INFO:Calculating mean and std
2024-05-04 18:44:09,131:INFO:Creating metrics dataframe
2024-05-04 18:44:09,132:INFO:Uploading results into container
2024-05-04 18:44:09,132:INFO:Uploading model into container now
2024-05-04 18:44:09,132:INFO:_master_model_container: 15
2024-05-04 18:44:09,133:INFO:_display_container: 2
2024-05-04 18:44:09,133:INFO:AdaBoostRegressor(random_state=123)
2024-05-04 18:44:09,133:INFO:create_model() successfully completed......................................
2024-05-04 18:44:09,242:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:09,242:INFO:Creating metrics dataframe
2024-05-04 18:44:09,246:INFO:Initializing Gradient Boosting Regressor
2024-05-04 18:44:09,246:INFO:Total runtime is 0.09134371678034464 minutes
2024-05-04 18:44:09,248:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:09,248:INFO:Initializing create_model()
2024-05-04 18:44:09,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:09,248:INFO:Checking exceptions
2024-05-04 18:44:09,248:INFO:Importing libraries
2024-05-04 18:44:09,248:INFO:Copying training dataset
2024-05-04 18:44:09,251:INFO:Defining folds
2024-05-04 18:44:09,251:INFO:Declaring metric variables
2024-05-04 18:44:09,252:INFO:Importing untrained model
2024-05-04 18:44:09,253:INFO:Gradient Boosting Regressor Imported successfully
2024-05-04 18:44:09,256:INFO:Starting cross validation
2024-05-04 18:44:09,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:09,789:INFO:Calculating mean and std
2024-05-04 18:44:09,790:INFO:Creating metrics dataframe
2024-05-04 18:44:09,790:INFO:Uploading results into container
2024-05-04 18:44:09,791:INFO:Uploading model into container now
2024-05-04 18:44:09,791:INFO:_master_model_container: 16
2024-05-04 18:44:09,791:INFO:_display_container: 2
2024-05-04 18:44:09,791:INFO:GradientBoostingRegressor(random_state=123)
2024-05-04 18:44:09,791:INFO:create_model() successfully completed......................................
2024-05-04 18:44:09,898:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:09,898:INFO:Creating metrics dataframe
2024-05-04 18:44:09,903:INFO:Initializing Light Gradient Boosting Machine
2024-05-04 18:44:09,903:INFO:Total runtime is 0.10228963295618693 minutes
2024-05-04 18:44:09,904:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:09,905:INFO:Initializing create_model()
2024-05-04 18:44:09,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:09,905:INFO:Checking exceptions
2024-05-04 18:44:09,905:INFO:Importing libraries
2024-05-04 18:44:09,905:INFO:Copying training dataset
2024-05-04 18:44:09,907:INFO:Defining folds
2024-05-04 18:44:09,908:INFO:Declaring metric variables
2024-05-04 18:44:09,910:INFO:Importing untrained model
2024-05-04 18:44:09,911:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 18:44:09,914:INFO:Starting cross validation
2024-05-04 18:44:09,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:10,806:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-04 18:44:10,807:WARNING:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

2024-05-04 18:44:10,808:INFO:Initializing create_model()
2024-05-04 18:44:10,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:10,808:INFO:Checking exceptions
2024-05-04 18:44:10,808:INFO:Importing libraries
2024-05-04 18:44:10,808:INFO:Copying training dataset
2024-05-04 18:44:10,810:INFO:Defining folds
2024-05-04 18:44:10,810:INFO:Declaring metric variables
2024-05-04 18:44:10,811:INFO:Importing untrained model
2024-05-04 18:44:10,813:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-04 18:44:10,816:INFO:Starting cross validation
2024-05-04 18:44:10,816:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:13,660:WARNING:OMP: Error #179: Function pthread_mutex_init failed:
2024-05-04 18:44:13,660:WARNING:OMP: System error #22: Invalid argument
2024-05-04 18:44:13,661:WARNING:OMP: Error #179: Function pthread_mutex_init failed:
2024-05-04 18:44:13,661:WARNING:OMP: System error #22: Invalid argument
2024-05-04 18:44:13,661:WARNING:OMP: Error #179: Function pthread_mutex_init failed:
2024-05-04 18:44:13,661:WARNING:OMP: System error #22: Invalid argument
2024-05-04 18:44:14,536:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2024-05-04 18:44:14,537:ERROR:Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGSEGV(-11)}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGABRT(-6)}

2024-05-04 18:44:14,537:INFO:Initializing Dummy Regressor
2024-05-04 18:44:14,537:INFO:Total runtime is 0.17953064839045207 minutes
2024-05-04 18:44:14,540:INFO:SubProcess create_model() called ==================================
2024-05-04 18:44:14,541:INFO:Initializing create_model()
2024-05-04 18:44:14,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30757f2d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:14,541:INFO:Checking exceptions
2024-05-04 18:44:14,541:INFO:Importing libraries
2024-05-04 18:44:14,541:INFO:Copying training dataset
2024-05-04 18:44:14,544:INFO:Defining folds
2024-05-04 18:44:14,544:INFO:Declaring metric variables
2024-05-04 18:44:14,546:INFO:Importing untrained model
2024-05-04 18:44:14,547:INFO:Dummy Regressor Imported successfully
2024-05-04 18:44:14,550:INFO:Starting cross validation
2024-05-04 18:44:14,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-04 18:44:17,694:INFO:Calculating mean and std
2024-05-04 18:44:17,698:INFO:Creating metrics dataframe
2024-05-04 18:44:17,703:INFO:Uploading results into container
2024-05-04 18:44:17,704:INFO:Uploading model into container now
2024-05-04 18:44:17,705:INFO:_master_model_container: 17
2024-05-04 18:44:17,705:INFO:_display_container: 2
2024-05-04 18:44:17,705:INFO:DummyRegressor()
2024-05-04 18:44:17,705:INFO:create_model() successfully completed......................................
2024-05-04 18:44:17,862:INFO:SubProcess create_model() end ==================================
2024-05-04 18:44:17,862:INFO:Creating metrics dataframe
2024-05-04 18:44:17,869:WARNING:/Users/huytrq/miniconda3/envs/py11/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-04 18:44:17,874:INFO:Initializing create_model()
2024-05-04 18:44:17,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x325a2b150>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-04 18:44:17,874:INFO:Checking exceptions
2024-05-04 18:44:17,875:INFO:Importing libraries
2024-05-04 18:44:17,875:INFO:Copying training dataset
2024-05-04 18:44:17,879:INFO:Defining folds
2024-05-04 18:44:17,879:INFO:Declaring metric variables
2024-05-04 18:44:17,879:INFO:Importing untrained model
2024-05-04 18:44:17,879:INFO:Declaring custom model
2024-05-04 18:44:17,880:INFO:Linear Regression Imported successfully
2024-05-04 18:44:17,880:INFO:Cross validation set to False
2024-05-04 18:44:17,880:INFO:Fitting Model
2024-05-04 18:44:17,893:INFO:LinearRegression(n_jobs=-1)
2024-05-04 18:44:17,893:INFO:create_model() successfully completed......................................
2024-05-04 18:44:18,053:INFO:_master_model_container: 17
2024-05-04 18:44:18,053:INFO:_display_container: 2
2024-05-04 18:44:18,053:INFO:LinearRegression(n_jobs=-1)
2024-05-04 18:44:18,053:INFO:compare_models() successfully completed......................................
