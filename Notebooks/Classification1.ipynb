{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def filter_outliers(data):\n",
    "    \"\"\"Filter out the outliers using IQR method.\n",
    "    \"\"\"  \n",
    "    for column in data:\n",
    "        if data[column].dtype in ['int64', 'float64']:\n",
    "            Q1 = data[column].quantile(0.25)\n",
    "            Q3 = data[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outliers = data[(data[column] < (Q1 - 1.5 * IQR)) | (data[column] > (Q3 + 1.5 * IQR))]\n",
    "            # Filter out the outliers\n",
    "            data = data[(data[column] >= (Q1 - 1.5 * IQR)) & (data[column] <= (Q3 + 1.5 * IQR))]\n",
    "    return data\n",
    "\n",
    "def filter_outliers_by_group(data):\n",
    "    filter_data = None\n",
    "    groups = data['Group'].unique()\n",
    "    for group in groups:\n",
    "        group_data = data[data['Group'] == group]\n",
    "        group_data = filter_outliers(group_data)\n",
    "        if filter_data is None:\n",
    "            filter_data = group_data\n",
    "        else:\n",
    "            filter_data = pd.concat([filter_data, group_data])\n",
    "    return filter_data\n",
    "\n",
    "def load_csv(file_path, remove_outliners=False, filter_by_group=False):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "    # Replace commas in numeric columns and convert them to floats\n",
    "    data = data.replace(',', '.', regex=True).apply(pd.to_numeric, errors='ignore')\n",
    "    # if 'Perform' in data.columns:\n",
    "    #     data.drop('Perform', axis=1, inplace=True)\n",
    "    if filter_by_group:\n",
    "        data = filter_outliers_by_group(data)\n",
    "    elif remove_outliners:\n",
    "        data = filter_outliers(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_with_excessive_nans(dataframe, threshold=200):\n",
    "    \"\"\"Drop columns from a DataFrame where the number of NaN values exceeds the specified threshold.\"\"\"\n",
    "    nan_counts = dataframe.isna().sum()\n",
    "    columns_to_drop = nan_counts[nan_counts > threshold].index\n",
    "    return dataframe.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cost_matrix = np.array([[0, 1, 2],\n",
    "                        [1, 0, 1],\n",
    "                        [2, 1, 0]])\n",
    "def calculate_custom_error(preds, gt, cost_matrix=cost_matrix):\n",
    "    \"\"\"\n",
    "    Calculate a custom error metric based on a confusion matrix and a cost matrix.\n",
    "\n",
    "    Args:\n",
    "    preds (array-like): Predicted labels.\n",
    "    gt (array-like): Ground truth (actual) labels.\n",
    "    cost_matrix (numpy.ndarray): A matrix of costs associated with misclassifications.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated error metric.\n",
    "    \"\"\"\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(gt, preds)\n",
    "    \n",
    "    # Validate dimensions of cost_matrix\n",
    "    if cm.shape != cost_matrix.shape:\n",
    "        raise ValueError(\"Cost matrix dimensions must match the confusion matrix dimensions.\")\n",
    "    \n",
    "    # Calculate weighted confusion matrix\n",
    "    weighted_cm = cm * cost_matrix\n",
    "    \n",
    "    # Calculate the custom error\n",
    "    total_samples = len(gt)\n",
    "    if total_samples == 0:\n",
    "        raise ValueError(\"The length of ground truth cannot be zero.\")\n",
    "    \n",
    "    error = np.sum(weighted_cm) / total_samples\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transformations(X):\n",
    "    # Log transformation\n",
    "    X = X.drop(columns=['Group'], axis=1)\n",
    "    df_log_transformed = X.apply(lambda x: np.log(x + 1))  # x+1 to avoid log(0)\n",
    "\n",
    "    # # Box-Cox or Yeo-Johnson transformation\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=True)  # Box-Cox requires strictly positive values\n",
    "    X = pd.DataFrame(pt.fit_transform(X), columns=X.columns)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_wise_knn_imputation(df, group_column, n_neighbors=5):\n",
    "    # Initialize an empty DataFrame to collect the imputed groups\n",
    "    try:\n",
    "        df_copy = df.drop(columns=['I21', 'I48', 'I50', 'dI21', 'dI48', 'dI50'], axis=1)\n",
    "    except:\n",
    "        df_copy = df\n",
    "\n",
    "    # We will collect the group imputed dataframes here and concatenate them at the end\n",
    "    imputed_dfs = []\n",
    "\n",
    "    # Iterate over each group\n",
    "    for group_name, group_data in df_copy.groupby(group_column):\n",
    "        # Create an imputer object\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "        # Select numeric columns for imputation\n",
    "        numeric_cols = group_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        # Perform imputation\n",
    "        group_data.loc[:, numeric_cols] = imputer.fit_transform(group_data[numeric_cols])\n",
    "\n",
    "        # Append the imputed group data\n",
    "        imputed_dfs.append(group_data)\n",
    "\n",
    "    # Concatenate all the imputed group dataframes\n",
    "    df_imputed = pd.concat(imputed_dfs, ignore_index=False)\n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_wise_imputation(X, group_column):\n",
    "    # Iterate over each group defined by the 'group_column'\n",
    "    for group, group_data in X.groupby(group_column):\n",
    "        # Select only numeric columns for imputation, excluding the group column explicitly\n",
    "        numeric_cols = group_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if group_column in numeric_cols:\n",
    "            numeric_cols.remove(group_column)  # Ensure the group column is not in the list\n",
    "\n",
    "        for column in numeric_cols:\n",
    "            upper_quartile = group_data[column].quantile(0.75)\n",
    "            lower_quartile = group_data[column].quantile(0.25)\n",
    "            IQR = upper_quartile - lower_quartile\n",
    "            upper_whisker = upper_quartile + 1.5 * IQR\n",
    "            lower_whisker = lower_quartile - 1.5 * IQR\n",
    "            \n",
    "            # Impute outliers with the median of the group\n",
    "            median_value = group_data[column].median()\n",
    "            group_data[column] = np.where((group_data[column] > upper_whisker) | \n",
    "                                        (group_data[column] < lower_whisker), \n",
    "                                        median_value, group_data[column])\n",
    "        \n",
    "        # Assign the corrected group data back to the main DataFrame\n",
    "        X.loc[group_data.index, group_data.columns] = group_data\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_csv('../data/training_data.csv')\n",
    "# train_data.loc[(train_data['Perform'] < 0.1) & (train_data['Perform'] > -0.1), 'Class'] = 0\n",
    "# train_data.loc[(train_data['Perform'] < 0.1) & (train_data['Perform'] > -0.1), 'Perform'] = 0\n",
    "train_data = drop_columns_with_excessive_nans(train_data, 200)\n",
    "\n",
    "# Handle categorical variables - encoding the 'Group' column\n",
    "le = LabelEncoder()\n",
    "train_data['Group'] = le.fit_transform(train_data['Group'])\n",
    "# cols = train_data.columns.tolist()\n",
    "# cols = cols[1:] + cols[0:1]\n",
    "# train_data = train_data[cols]\n",
    "\n",
    "#### Filling misisng values\n",
    "# train_data = train_data.interpolate()\n",
    "# Replace NaN values with 0\n",
    "# train_data = train_data.fillna(0)\n",
    "# train_data = train_data.fillna(method='ffill')\n",
    "# Fill NaN values with the mean of each column\n",
    "# train_data = train_data.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "# Assume 'Class' is the target variable\n",
    "X = train_data.drop('Class', axis=1)  # Features\n",
    "y = train_data['Class'] # Target variable\n",
    "\n",
    "# X = feature_transformations(X)\n",
    "# X = group_wise_imputation(X, 'Group')\n",
    "# X = group_wise_knn_imputation(X, 'Group', n_neighbors=5)\n",
    "X = X.drop(columns=['Perform'], axis=1)\n",
    "# X = X[feature_importances[feature_importances > 0.001].dropna()[0].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]), array([1239,  454, 1507]))"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=state, stratify=y)\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28933"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nan_counts = X.isna().sum().sum()\n",
    "nan_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = SVC(class_weight='balanced', kernel='linear')\n",
    "selector = RFE(estimator, n_features_to_select=50, step=1, verbose=3)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Selected features\n",
    "selected_features = selector.get_support(indices=True)\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the train and test sets to keep only selected features\n",
    "X_train = X_train.loc[:, selector.support_]\n",
    "X_test = X_test.loc[:, selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = model.feature_importances_\n",
    "\n",
    "# final_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances})\n",
    "# final_df.set_index('Importance')\n",
    "\n",
    "# final_df = final_df.sort_values('Importance')\n",
    "\n",
    "# # ax, fig = plt.subplots(figsize=(10, 10))\n",
    "# final_df.plot(kind='barh', x='Feature', y='Importance', color='blue', edgecolor='black', figsize=(20, 20))\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "importances = mutual_info_classif(X_train, y_train)\n",
    "feature_importances = pd.Series(importances, index=X_train.columns)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "feature_importances.plot(kind='barh', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "\n",
    "efs = ExhaustiveFeatureSelector(estimator=RandomForestClassifier(n_estimators=100,\n",
    "                                                                n_jobs=-1),\n",
    "                                min_features=1,\n",
    "                                max_features=100,\n",
    "                                scoring='accuracy',\n",
    "                                cv=2)\n",
    "efs = efs.fit(X_train, y_train)\n",
    "selected_features = X_train.columns[list(efs.best_idx_)]\n",
    "print(selected_features)\n",
    "\n",
    "\n",
    "print(efs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "model = RandomForestClassifier(random_state=state, n_estimators=100, class_weight='balanced', verbose=1)\n",
    "\n",
    "selector = RFE(model, n_features_to_select=50, step=1)  # Select 5 features at a time\n",
    "selector = selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = selector.transform(X_train)\n",
    "X_test = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: [2477  909 3014]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Display original class distribution\n",
    "print(\"Original class distribution:\", np.bincount(y_train + 1))\n",
    "\n",
    "# Separate majority and minority classes\n",
    "X_train_minority = X_train[y_train == 0]\n",
    "y_train_minority = y_train[y_train == 0]\n",
    "\n",
    "X_train_majority = X_train[y_train != 0]\n",
    "y_train_majority = y_train[y_train != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New class distribution: [2477 5491 3014]\n"
     ]
    }
   ],
   "source": [
    "# Upsample minority class\n",
    "X_upsampled, y_upsampled = resample(X_train_minority,\n",
    "                                    y_train_minority,\n",
    "                                    replace=True,  # sample with replacement\n",
    "                                    n_samples=X_train_majority.shape[0],  # to match majority class\n",
    "                                    random_state=123)  # reproducible results\n",
    "\n",
    "# Combine the upsampled minority class with the majority class\n",
    "X_train_balanced = np.vstack((X_train_majority, X_upsampled))\n",
    "y_train_balanced = np.hstack((y_train_majority, y_upsampled))\n",
    "\n",
    "# Shuffle the dataset to mix up minority and majority samples\n",
    "indices = np.arange(X_train_balanced.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_train_balanced = X_train_balanced[indices]\n",
    "y_train_balanced = y_train_balanced[indices]\n",
    "\n",
    "\n",
    "# Display new class distribution\n",
    "print(\"New class distribution:\", np.bincount(y_train_balanced + 1))\n",
    "X_train = X_train_balanced\n",
    "y_train = y_train_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New class distribution: [400 909 509]\n"
     ]
    }
   ],
   "source": [
    "# Downsample majority class\n",
    "X_majority_downsampled, y_majority_downsampled = resample(X_train_majority,\n",
    "                                                          y_train_majority,\n",
    "                                                          replace=False,  # sample without replacement\n",
    "                                                          n_samples=len(y_train_minority),  # match minority class\n",
    "                                                          random_state=123)  # reproducible results\n",
    "\n",
    "# Combine the downsampled majority class with the minority class\n",
    "X_train_balanced = np.vstack((X_majority_downsampled, X_train_minority))\n",
    "y_train_balanced = np.hstack((y_majority_downsampled, y_train_minority))\n",
    "\n",
    "# Shuffle the dataset to mix up minority and majority samples\n",
    "indices = np.arange(X_train_balanced.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_train_balanced = X_train_balanced[indices]\n",
    "y_train_balanced = y_train_balanced[indices]\n",
    "\n",
    "# Display new class distribution\n",
    "print(\"New class distribution:\", np.bincount(y_train_balanced + 1))\n",
    "\n",
    "# X_train = X_train_balanced\n",
    "# y_train = y_train_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=state, n_estimators=100, class_weight='balanced', verbose=1)\n",
    "# model = SVC(random_state=state, class_weight='balanced')\n",
    "# model = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "# model = DecisionTreeClassifier(random_state=42)\n",
    "# model = GaussianNB()\n",
    "\n",
    "# Initialize search\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47020833333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.39      0.42      1857\n",
      "           0       0.19      0.02      0.03       682\n",
      "           1       0.49      0.67      0.57      2261\n",
      "\n",
      "    accuracy                           0.47      4800\n",
      "   macro avg       0.37      0.36      0.34      4800\n",
      "weighted avg       0.43      0.47      0.43      4800\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 727   22 1108]\n",
      " [ 207   13  462]\n",
      " [ 710   34 1517]]\n",
      "Custom Error: 0.9085416666666667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Custom Error:\", calculate_custom_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data = load_csv('../data/test_data_no_target.csv')\n",
    "test_data = test_data[X.columns]\n",
    "# test_data = drop_columns_with_excessive_nans(test_data, 50)\n",
    "le = LabelEncoder()\n",
    "test_data['Group'] = le.fit_transform(test_data['Group'])\n",
    "\n",
    "\n",
    "# Replace NaN values with 0\n",
    "test_data = test_data.fillna(0) \n",
    "# test_data = test_data.interpolate()\n",
    "# test_data = feature_transformations(test_data)\n",
    "# scaler = StandardScaler()\n",
    "# test_data = scaler.fit_transform(test_data)\n",
    "\n",
    "\n",
    "predicts = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predictions_prob_threshold_0.5.txt', np.array(results), fmt='%d', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predicts_RF_margin.txt', np.array(predicts), fmt='%d', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
